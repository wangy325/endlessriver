[{"content":"使用idm下载y2b视频导致服务器内存溢出，内核强制关闭了服务进程。\n通过系统日志定位原因，并探讨了服务器维护的几个相关命令。\n1 日志 系统服务日志地址： /var/log/messages\nFeb 19 16:02:12 vultr kernel: oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=/,mems_allowed=0,global_oom,task_memcg=/,task=firewalld,pid=1626,uid=0 Feb 19 16:02:12 vultr kernel: Out of memory: Killed process 1626 (firewalld) total-vm:358420kB, anon-rss:22096kB, file-rss:4kB, shmem-rss:0kB Feb 19 16:02:12 vultr kernel: oom_reaper: reaped process 1626 (firewalld), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB Feb 19 16:02:12 vultr systemd: firewalld.service: main process exited, code=killed, status=9/KILL Feb 19 16:02:12 vultr systemd: Unit firewalld.service entered failed state. Feb 19 16:02:12 vultr systemd: firewalld.service failed. 日志说明的很清楚了，内存溢出，系统杀掉了部分进程。\n 至于是否网络请求占用了太多的系统资源，还需要进一步认证\n 2 设置服务器时区 tzselect 由于并非使用国内的服务器，也一直懒于管理，导致服务器的时区并非GMT+8，日志看起来非常的别扭，因此，将服务器时区顺道进行一番设置。\n 设置时区的多种方法其中一种\n参考：https://www.cnblogs.com/dead-trap-ramble/p/3462448.html\n 服务器时区为+0，需要将其改为+8，这样系统日志的时间能够对应上。\n使用date -R命令查看当前系统时间/时区信息\n使用tzselect命令选择时区，中国大陆根据命令提示选择Asia/China/Beijing即可。\n命令执行完毕之后，还会提醒你将TZ='Asia/Shanghai'; export TZ写入到profile中，一般为根目录下的.bash_profile文件：\necho \u0026quot;TZ='Asia/Shanghai'; export TZ\u0026quot; \u0026gt;\u0026gt; .bash_profile 随即使用\nsource .bash_profile 命令刷新配置文件，再使用date -R命令查看日期，已经和中国大陆时间同步。\n另外，为了防止服务器重启之后，配置失效[^没有实测]，可以覆盖系统的配置文件：\ncp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 这条命令会有一条警告信息，覆盖即可。\n3 查看并设置系统自启动服务 使用命令systemctl list-unit-files | grep enabled可以查看当前系统开机启动的服务信息。\n实际上，再centOS中，使用chkconfig --list命令也可以获取使用systemctl...命令的提示：\n# chkconfg --list Note: This output shows SysV services only and does not include native systemd services. SysV configuration data might be overridden by native systemd configuration. If you want to list systemd services use 'systemctl list-unit-files'. To see services enabled on particular target use 'systemctl list-dependencies [target]'. denyhosts 0:off 1:off 2:on 3:on 4:on 5:on 6:off netconsole 0:off 1:off 2:off 3:off 4:off 5:off 6:off network 0:off 1:off 2:on 3:on 4:on 5:on 6:off 可以简单的通过systemctl enable nginx将nginx服务加入到自启动服务列表里面去。\nlinux确实是通过配置文件控制服务的启动，此处尚且不展开这部分内容，更详细的内容可以参考：\n Linux中设置服务自启动的三种方式 linux开机启动服务的修改与查看  4 top命令是一个交互命令 控制台输入top可以查看当前系统的一些信息，并且这些信息是动态刷新的。\ntop命令是一个可交互的命令，可以通过快捷键指令进行交互，有一些常见的快捷指令：\n M：按照内存占用排序进程 m：切换内存占用的显示方式 P：按照cpu占用排序进程  更多的快捷指令可以参考：https://man.linuxde.net/top\n除了top之外，还有一个ps命令：http://c.biancheng.net/view/1062.html，\n记住ps aux | grep xxx就行了^_^。\n","description":"","id":4,"section":"posts","tags":[""],"title":"一次服务器OOM故障","uri":"http://wangy325.top/zh/posts/server/2021-02-20_%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%85%E9%9A%9C/"},{"content":" 几个说明：\n properties配置文件中，spring.messages.basename必须要加classpath前缀。如 spring.messages.basename=classpath:i18n/messages； 必须要手动配置MessageSource，springboot不会自动配置之； 如果使用MessageSource.getMessage()方法，第一个参数的引用形式为\u0026quot;code\u0026quot;，而不是\u0026quot;{code}\u0026quot;或者\u0026quot;${code}\u0026quot;。如messageSource.getMessage(\u0026ldquo;test.msg\u0026rdquo;, null, Locale.getDefault())； 在配置LocalValidatorFactoryBean之后，才可以在javax.validation.constraints包下的注解（@Size，@NotNull\u0026hellip;）下的message属性中使用\u0026quot;{code}\u0026quot;的形式声明校验提示信息。如\n@NotNull(message = \u0026quot;{leftTime.not.null}\u0026quot;)； springMVC的locale配置和JVM的locale配置不一样，在application.properties中配置的spring.mvc.locale=zh_CN实际上配置的是WebMvcProperties，在获取消息时，locale信息应该使用webMvcProperties.getLocale()1获取而不是使用Locale.getDefault()获取。   1 概览 MessageSource is a powerful feature available in Spring applications. This helps application developers handle various complex scenarios with writing much extra code, such as environment-specific configuration, internationalization or configurable values.\nOne more scenario could be modifying the default validation messages to more user-friendly/custom messages.\nIn this tutorial, we\u0026rsquo;ll see how to configure and manage custom validation MessageSource in the application using Spring Boot.\n2 引入Maven依赖 Let\u0026rsquo;s start with adding the necessary Maven dependencies:\n1 2 3 4 5 6 7 8  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-validation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;   You can find the latest versions of these libraries over on Maven Central.\n3 自定义校验信息示例 Let\u0026rsquo;s consider a scenario where we have to develop an application that supports multiple languages. If the user doesn\u0026rsquo;t provide the correct details as input, we\u0026rsquo;d like to show error messages according to the user\u0026rsquo;s locale.\nLet\u0026rsquo;s take an example of a Login form bean:\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class LoginForm { // 注意此处的语法，为\u0026#34;{}\u0026#34;形式，在spring项目中，是无法通过ctrl+鼠标左键定位到配置文件的  // 若去除大括号，则可以通过ctrl+鼠标左键定位到配置的值  @NotEmpty(message = \u0026#34;{email.notempty}\u0026#34;) @Email private String email; @NotNull private String password; // standard getter and setters }   Here we\u0026rsquo;ve added validation constraints that verify if an email is not provided at all, or provided, but not following the standard email address style.\nTo show custom and locale-specific message, we can provide a placeholder as mentioned for the @NotEmpty annotation.\nThe email.notemptyproperty will be resolved from a properties files by the MessageSource configuration.\n4 配置MessageSource An application context delegates the message resolution to a bean with the exact name messageSource.\nReloadableResourceBundleMessageSource is the most common MessageSource implementation that resolves messages from resource bundles for different locales:\n1 2 3 4 5 6 7 8 9 10  @Bean public MessageSource messageSource() { ReloadableResourceBundleMessageSource messageSource = new ReloadableResourceBundleMessageSource(); // 如果使用ReloadableResourceBundleMessageSource，classpath前缀必不可少  // classpath前缀告诉ReloadableResourceBundleMessageSource从classpath中获取配置  messageSource.setBasename(\u0026#34;classpath:messages\u0026#34;); messageSource.setDefaultEncoding(\u0026#34;UTF-8\u0026#34;); return messageSource; }   Here, it\u0026rsquo;s important to provide the basename as locale-specific file names will be resolved based on the name provided.\n4.1 关于MessageSource的自动配置 实际上，Spring Boot可以自动配置MessageSourece，不过，想要成功配置，有2个条件：\n Spring Boot自动配置实际上使用的是ResourceBundleMessageSourece，不同于ReloadableResourceBundleMessageSource 你无需再配置别名为\u0026quot;messageSource\u0026quot;的Bean，也就是说上述的配置必须忽略掉  不妨看看MessageSource自动配置相关的类，具体内容在org.springframework.boot.autoconfig.context.MessageSourceAutoConfiguration.java类中：\n1 2 3 4 5 6 7 8 9  @Configuration(proxyBeanMethods = false) @ConditionalOnMissingBean(name = AbstractApplicationContext.MESSAGE_SOURCE_BEAN_NAME, search = SearchStrategy.CURRENT) @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE) @Conditional(ResourceBundleCondition.class) @EnableConfigurationProperties public class MessageSourceAutoConfiguration { //... }   注意该自动配置类上的2个注解：\n  @ConditionalOnMissingBean(name = AbstractApplicationContext.MESSAGE_SOURCE_BEAN_NAME, search = SearchStrategy.CURRENT)\n这个注解说明的就是，如果你没有配置messageSource，那么SpringBoot（可能）会自动为你配置\n  @Conditional(ResourceBundleCondition.class)\n这是一个条件化注入，条件在ResourceBundleCondition.class中定义。通过名字就知道，Spring Boot自动配置使用的是ResourceBundleMessageSourece\n  ResourceBundleCondition.class是MessageSourceAutoConfiguration.class的内部类，以下是其内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  @Override public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) { String basename = context.getEnvironment().getProperty(\u0026#34;spring.messages.basename\u0026#34;, \u0026#34;messages\u0026#34;); ConditionOutcome outcome = cache.get(basename); if (outcome == null) { outcome = getMatchOutcomeForBasename(context, basename); cache.put(basename, outcome); } return outcome; } private ConditionOutcome getMatchOutcomeForBasename(ConditionContext context, String basename) { ConditionMessage.Builder message = ConditionMessage.forCondition(\u0026#34;ResourceBundle\u0026#34;); for (String name : StringUtils.commaDelimitedListToStringArray(StringUtils.trimAllWhitespace(basename))) { for (Resource resource : getResources(context.getClassLoader(), name)) { if (resource.exists()) { return ConditionOutcome.match(message.found(\u0026#34;bundle\u0026#34;).items(resource)); } } } return ConditionOutcome.noMatch(message.didNotFind(\u0026#34;bundle with basename \u0026#34; + basename).atAll()); } // basename不需要classpath前缀，它总是从classpath中获取资源 private Resource[] getResources(ClassLoader classLoader, String name) { String target = name.replace(\u0026#39;.\u0026#39;, \u0026#39;/\u0026#39;); try { return new PathMatchingResourcePatternResolver(classLoader) .getResources(\u0026#34;classpath*:\u0026#34; + target + \u0026#34;.properties\u0026#34;); } catch (Exception ex) { return NO_RESOURCES; } }   我们只需要关注getResources方法，可以看到，其自动补全了classpath前缀，因此，ResourceBundleMessageSourece总是从classpath中获取资源的。\n如果这两个条件都满足，那么SpringBoot会自动使用ResourceBundleMessageSourece配置MessageSource。\n4.2 RBMS和RRBMS  RBMS: ResourceBundleMessageSource RRBMS: ReloadableResourceBundleMessageSource  在本文的文首，标注了几个实践时需要注意的点，现在看来，前2点都是错误的表述，因为当时实践时使用的是ReloadableResourceBundleMessageSourece，并且没有搞清楚Spring Boot自动配置MessageSource的条件。\n关于这2个“MessageSource”的区别，github上有一个经典的issue，描述的问题是如果不使用classpath前缀，前者可以读取消息，后者不能读取消息。spring开发人员的回复一针见血：\n I assume your resource bundle files live in the classpath? There is an important difference between ResourceBundleMessageSource and ReloadableResourceBundleMessageSource: The former always loads resource bundles from the classpath (since that is all that standard java.util.ResourceBundle is capable of), whereas the latter loads resource bundle files through the ApplicationContext\u0026rsquo;s ResourceLoader. If your context is a ClassPathXmlApplicationContext, you won\u0026rsquo;t notice a difference - but if it is a WebApplicationContext, it will try to find the files in the WAR directory structure when not using a prefix. So it would simply not find your files because it is looking in the wrong location.\nIf my assumption is correct, the following quick fix will allow your messages to be found in their existing location when switching to ReloadableResourceBundleMessageSource:\n\u0026lt;property name=\u0026quot;basename\u0026quot; value=\u0026quot;classpath:messages\u0026quot;\u0026gt;\nHowever, since classpath resources will be cached by the ClassLoader, ReloadableResourceBundleMessageSource\u0026rsquo;s refreshing is likely to not actually work in that case. So I\u0026rsquo;d rather recommend specifying something like the following, operating against an expanded WAR directory structure where WEB-INF resources can be refreshed from the file system:\n\u0026lt;property name=\u0026quot;basename\u0026quot; value=\u0026quot;WEB-INF/messages\u0026quot;/\u0026gt;\n 回复指出了ResourceBundleMessageSourece和ReloadableResourceBundleMessageSourece最重要的区别：\n ResourceBundleMessageSourece总是从classpath中加载资源 ReloadableResourceBundleMessageSourece 则从ApplicationContext\u0026rsquo;s ResourceLoader中加载资源  除此之外，二者还有一些其他的区别：\n ResourceBundleMessageSourece只能读取properties配置文件，而ReloadableResourceBundleMessageSourece还可以读取xml配置文件 ReloadableResourceBundleMessageSourece可以从任意位置2读取配置文件 从名字来看，Reloadable是可以动态加载配置文件的，事实上也确实如此，它有一个属性cacheSeconds，用来设置缓存配置文件的时间间隔：  默认值是 -1，意味着不动态加载配置文件 如果配置值为0，那么每次获取消息时就会检查配置文件的改动，这个配置值要慎用 如果配置为其他正整数，则会在固定间隔后检查配置文件改动    5 配置LocalValidatorFactoryBean  为了在javax.validation.constraints包下注解（@NotEmpty、@NotNull等）的校验中使用messageResource，还需要配置LocalValidatorFactoryBean\n To use custom name messages in a properties file like we need to define a LocalValidatorFactoryBean and register the messageSource:\n1 2 3 4 5 6  @Bean public LocalValidatorFactoryBean getValidator() { LocalValidatorFactoryBean bean = new LocalValidatorFactoryBean(); bean.setValidationMessageSource(messageSource()); return bean; }   However, note that if we had already extended the WebMvcConfigurerAdapter, to avoid having the custom validator ignored, we\u0026rsquo;d have to set the validator by overriding the getValidator() method from the parent class.\nNow we can define a property message like:\n“email.notempty=\u0026lt;Custom_Message\u0026gt;”  instead of\n“javax.validation.constraints.NotEmpty.message=\u0026lt;Custom_message\u0026gt;”  6 国际化properties文件 The final step is to create a properties file in the src/main/resources directory with the name provided in the basename in step 4:\n6.1 messages.properties email.notempty=Please provide valid email id. Here we can take advantage of internationalization along with this. Let\u0026rsquo;s say we want to show messages for a French user in their language.\nIn this case, we have to add one more property file with the name the messages_fr.properties in the same location (No code changes required at all):\n6.2 messages_fr.properties email.notempty=Veuillez fournir un identifiant de messagerie valide. 7 结论 In this article, we covered how the default validation messages can be changed without modifying the code if the configuration is done properly beforehand.\nWe can also leverage the support of internationalization along with this to make the application more user-friendly.\n8 使用并解析message 前文介绍了如何使用MessageResource进行参数校验时的国际化信息展现，最后补充如何在其他部分展现国际化的信息，最显著的一个使用场景就是错误消息的展现。\n配置好messages.properties文件之后，我们可以定义一个错误信息的枚举类：\n# messages.properties satisfied.resource.not.found=要处理的资源不存在 unknown.error=未知错误 # other promote messages no.specific.id.resource=对应id的资源不存在 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Getter public enum ReqState { RESPONSE_ADVICE_ERROR(500_08, \u0026#34;response.advice.error\u0026#34;), SATISFIED_RESOURCE_NOT_FOUND(500_09,\u0026#34;satisfied.resource.not.found\u0026#34;), UNKNOWN_ERROR(600_00, \u0026#34;unknown.error\u0026#34;); private int code; private String message; ReqState(int code, String message) { this.code = code; this.message = message; } }   和在@NotEmpty注解中使用方式不一样，这里只需要以字符串的形式直接引用即可。当然，这个消息还需要解析（实际上消息是以key-value的形式配置的，以key的形式引用，而要以value的形式呈现，在多语言的环境，可以实现\u0026quot;一次引用，多种呈现”的目的），解析的方式也很简单：\n1 2 3 4  @Autowired MessageResource messageSource; messageSource.getMessage(\u0026#34;unknown.error\u0026#34;, null, LocaleContextHolder.getLocale()))    如果此处像文章开头说的那样，使用webMvcProperties.getLocale()的话，在获取HTTP Header设置的Loacle时有些问题。此处使用了LocaleContextHolder.getLocale()，LocaleContextHolder可以灵活地获取每一次Servlet请求的Locale信息。\n 我们不妨看看WebMvcProperties类的Locale域：\n1 2 3 4  /** * Locale to use. By default, this locale is overridden by the \u0026#34;Accept-Language\u0026#34; header. */ private Locale locale;   注意到，可以通过设置HTTP请求头的方式来设置Locale信息。\n实际上，测试发现，通过设置Accept-Language请求头，配合使用LocaleContextHolder.getLocale()获取Locale信息，可以实现国际化效果，而使用webMvcProperties.getLocale()无法总是正确获取请求头设置的Locale信息。\n还有一点就是，LocaleContextHolder是通过静态方法获取的Locale信息，相较于webMvcProperties的实例方法，免去了注入WebMvcProperties的麻烦。\n8.1 LocaleContextHolder和Accept-Language 现在我们知道，可以通过LocaleContextHolder和设置Accept-Language头动态获取请求的Locale信息，那么我们可以在控制器中这样使用Locale信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @Controller public class WifeController { @Autowired private MessageSource msgSrc; @RequestMapping(value = \u0026#34;/wife/mood\u0026#34;) public String readWife(Model model, @RequestParam(\u0026#34;whatImDoing\u0026#34;) String iAm) { // 获取Locale信息  Locale loc = LocaleContextHolder.getLocale(); if(iAm.equals(\u0026#34;playingXbox\u0026#34;)) { model.addAttribute( \u0026#34;statusTitle\u0026#34;, msgSrc.getMessage(\u0026#34;mood.angry\u0026#34;, null, loc) ); model.addAttribute( \u0026#34;statusDetail\u0026#34;, msgSrc.getMessage(\u0026#34;mood.angry.xboxdiatribe\u0026#34;, null, loc) ); } return \u0026#34;moodResult\u0026#34;; } }   不过，在每个控制器里都需要获取一次Loacle信息，这样的方式似乎有点繁琐。那么是否可以简单一点呢？显然是可以的。\nspringMvc v3.2.x doc 17.3.3中定义了控制器方法支持的参数：\n \u0026hellip;\njava.util.Locale for the current request locale, determined by the most specific locale resolver available, in effect, the configured LocaleResolver in a Servlet environment.\n\u0026hellip;\n 也就是说，Locale可以直接作为参数被HTTP请求传递进来。因此，可以这样改造上述控制器：\n1 2 3 4 5 6 7 8  @RequestMapping(value = \u0026#34;/wife/mood\u0026#34;) public String readWife(Model model, @RequestParam(\u0026#34;whatImDoing\u0026#34;) String iAm, Locale loc) { if(iAm.equals(\u0026#34;playingXbox\u0026#34;)) { model.addAttribute( \u0026#34;statusTitle\u0026#34;, msgSrc.getMessage(\u0026#34;mood.angry\u0026#34;, null, loc) ); model.addAttribute( \u0026#34;statusDetail\u0026#34;, msgSrc.getMessage(\u0026#34;mood.angry.xboxdiatribe\u0026#34;, null, loc) ); } return \u0026#34;moodResult\u0026#34;; }   这样简洁多了，SpringMvc简直太聪明了！等等，通过spring.mvc.locale=zh_CN或通过Accept-Language: en;q=0.7,zh-TW;q=0.8,zh-CN;q=0.7这样的形式配置MVC context的Locale信息还是有点麻烦，并且这样的话，前端每次请求都需要手动设置（校验）请求头，麻烦！\n 默认情况下，浏览器发起请求的Accept-Language是根据用户语言设置的。\n 文章到此，我们已经可以通过配置WebMvcProperties和设置Accept-Language请求头来设置Spring MVC Context的Locale信息；并且通过LocaleContextHolder.getLocale()方法或者直接在控制器中传递Locale参数的形式获取Locale信息。\n8.2 Locale Resolver 这样看来，国际化的配置还是不够灵活，配置文件的加载以及请求头的设置这两种方法都略显笨重。\n去找找文档看看其他的思路吧：\n (旧版本)springMvc-3.2.x-17.8 spring webMvc doc  当请求进入到控制器时，DispatcherServlet会寻找locale resolver，并使用其设置Locale。使用RequestContext.getLocale()方法总是可以获取到Locale信息：\n1 2 3 4 5 6 7  @GetMapping(\u0026#34;/resolver/locale\u0026#34;) public ReqResult\u0026lt;?\u0026gt; locale(HttpServletRequest request) { // 构建RequestContext  RequestContext rc = new RequestContext(request); log.info(\u0026#34;locale: {}\u0026#34;, rc.getLocale()); return ReqResult.ok(rc.getMessage(\u0026#34;http.ok\u0026#34;), rc.getLocale()); }   这个控制器可能的返回结果为：\n1 2 3 4 5 6 7 8 9 10  { \u0026#34;code\u0026#34;: 20000, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;en\u0026#34; } { \u0026#34;code\u0026#34;: 20000, \u0026#34;msg\u0026#34;: \u0026#34;成功\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;zh_CN\u0026#34; }    RequestContext可以很方便的获取请求中包含的信息，可能的参数绑定（校验）错误等，还能直接获取Spring Message，很强大。\n注意到，ServletRequest也有一个getLocale()方法，那么，我们直接从Request中获取Locale不是很方便么？就像这样：\n 1 2 3 4 5  @GetMapping(\u0026#34;/request/locale\u0026#34;) public ReqResult\u0026lt;?\u0026gt; locale(HttpServletRequest request, HttpServletResponse response){ // TODO why this method always return client default locale?  return ReqResult.ok(request.getLocale()); }    哈哈。似乎一切都完美。不过，注意看ServletRequest.getLocale()的文档你就会发现问题:\n Returns the preferred Locale that the client will accept content in, based on the Accept-Language header. If the client request doesn\u0026rsquo;t provide an Accept-Language header, this method returns the default locale for the server.\n 也就是说，从request中获取的并不是获取的Spring MVC Context当前使用的Locale信息。这一点在使用了LocaleChangeInterceptor之后，更能够得到证明。\n 除了RequestContext的方式之外，还可以通过配置拦截器、通过特定的条件（比如请求参数）来更改Locale。\n文档提到了几种不同的LocaleResolver：\n  AcceptHeaderLocaleResolver\n这个locale resolver已经在前文讨论过了，通过设置HTTP Header的Accept-Language请求头可以设置SpringMvc Context的Locale信息。这个resolver在前文就已经试验过了。\n  CookieLocaleResolver\n这个locale resolver检查cookie中是否声明了Locale信息，如果有，则使用之。\n  SessionLocaleResolver\n这个locale resolver可以从当前请求的HttpSession中获取Locale和TimeZone信息。由于和Session相关，故在切换Locale时没有cookie灵活，只有session关闭之后Locale配置才能重新设置。\n  LocaleChangeInterceptor\n这是推荐使用的方式，通过拦截器+请求参数实现国际化。\n  8.3 通过LocaleChangeInterceptor实现国际化 以下两篇文章分别使用xml和java Bean的方式配置了LocaleChangeInterceptor，通过地址栏参数展现国际化信息：\n [基于xml的配置]Spring MVC Internationalization (i18n) and Localization (i10n) Example [基于java bean的配置]LOCALE AND INTERNATIONALIZATION IN SPRING MVC  参考配置地址：\n https://github.com/wangy325/mybatis-plus-starter/blob/master/web-security-demo/src/main/java/com/wangy/config/MessageSourceConfig.java https://github.com/wangy325/mybatis-plus-starter/blob/master/web-security-demo/src/main/java/com/wangy/config/WebConfig.java  不妨看看LocaleChangeInterceptor是如何工作的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws ServletException { // 从请求路径中获取Locale参数  String newLocale = request.getParameter(getParamName()); if (newLocale != null) { if (checkHttpMethod(request.getMethod())) { // locale resovler  LocaleResolver localeResolver = RequestContextUtils.getLocaleResolver(request); if (localeResolver == null) { throw new IllegalStateException( \u0026#34;No LocaleResolver found: not in a DispatcherServlet request?\u0026#34;); } try { // 设置Locale信息  localeResolver.setLocale(request, response, parseLocaleValue(newLocale)); } catch (IllegalArgumentException ex) { if (isIgnoreInvalidLocale()) { if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Ignoring invalid locale value [\u0026#34; + newLocale + \u0026#34;]: \u0026#34; + ex.getMessage()); } } else { throw ex; } } } } // Proceed in any case.  return true; }   可以看到，LocaleChangeInterceptor的工作方式比较简单：\n 从路径参数中获取Locale参数配置 获取LocaleResolver 利用LocaleResolver重新设置步骤1中获取的Locale配置  这里有一个重点：LocaleResolver。如果不在项目中显示的配置LocaleResolver，那么此拦截器获取到的实例是AcceptHeaderLocaleResolver，这很致命：\n1 2 3 4 5 6  // AcceptHeaderLocaleResolver.java @Override public void setLocale(HttpServletRequest request, @Nullable HttpServletResponse response, @Nullable Locale locale) { throw new UnsupportedOperationException( \u0026#34;Cannot change HTTP accept header - use a different locale resolution strategy\u0026#34;); }   因为AcceptHeaderLocaleResolver的setLocale()方法直接抛出异常，导致Locale信息无法被设置。\n所以，如果使用LocaleChangeInterceptor，那么必须要显式配置一个LocalResolver，可以是SessionLocaleResolver或者CookieLocaleResolver：\n1 2 3 4 5 6 7  @Bean public SessionLocaleResolver localeResolver() { SessionLocaleResolver sessionLocaleResolver = new SessionLocaleResolver(); // 配置默认Locale  sessionLocaleResolver.setDefaultLocale(locale); return sessionLocaleResolver; }   这样，保证即使不传递路径国际化参数，也能使用默认的Locale配置。\n现在，我们再回头看看从HttpServletRequest中获取当前MVC Context 的Locale信息失败的原因：\n LocaleChangeInterceptor不与AcceptHeaderLocaleResolver兼容 HttpServletRequest从Accept-Language中获取Locale配置，否则返回服务器默认Locale信息  这应该比较好理解了，即使设置了Accept-language，这个设置也不能被配置了LocaleChangeInterceptor的mvc容器采纳。\n9 参考  原文地址： https://www.baeldung.com/spring-custom-validation-message-source 简单使用MessageSource [stackoverflow] MessageSource配置异常 [stackoverflow] 2个MessageSource的区别1 [github issue] 2个MessageSource的区别2 如何设置HTTP请求头Accept-Language 官方文档：使用messageSource进行国际化 官方文档：Spring MVC locale resovler HttpServletRequest并不能直接获取spring MVC Context当前的Locale信息   LocaleContextHolder是它的完美替代。 \u0026#x21a9;\u0026#xfe0e;\n 从文档和一些其他的资料来看，RRBMS是可以从任意位置读取配置文件的，不过笔者并没有实践这一说法。 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"介绍了在SpringBoot项目中通过MessageSource展现国际化信息的基本操作。","id":5,"section":"posts","tags":["MessageSource","i18n"],"title":"在SpringBoot中使用MessageSource","uri":"http://wangy325.top/zh/posts/java/spring/use-springboot-messagesource/"},{"content":"使用Logback记录日志 1 概览 Logback是Java应用中使用最广的日志框架之一，它是其前辈框架Log4j的替代者。相比Log4j，Logback在日志处理速度、配置多样性、对旧日志文件的处理灵活性上均要优于Log4j。\n这篇文章将介绍Logback的主要组成结构并指导你使用Logback构建更好的程序。\n2 Logback的组成结构 Logback的主要组成结构有3部分：Logger、Appender、Layout。\nLogger指示日志信息的上下文背景（context）。Java应用会根据Logger去记录日志文件。\nAppender将日志文件保存到指定的位置。一个Logger可以配置多个Appender。我们一般认为Appender的功能就是将日志写成文本文件里，但是Logback能做的可不止这些。\nLayout决定日志的格式化信息。Logback的日志格式信息配置非常丰富，此外，Logback还支持自定义日志格式信息。\n3 配置Logback 3.1 引入Maven依赖 Logback使用SLF4j（Simple Logging Facade for Java）作为其原生接口。在开始之前，我们需要在pom.xml引入Logback和Slf4j的依赖。\n 可能你的项目中已经引入了这两个依赖，因为spring/其他第三方jar很可能就使用Logback记录日志。\n 1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.30\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;   在Maven中央仓库中很容易找到这最新依赖：\n logback-core： slf4j-api：  3.2 类路径 除了上述的logback-core和slf4j之外，Logback运行时还还需要在类路径中依赖logback-classic.jar\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   4 基础配置示例 我们先从一个快速开始开始吧。\n首先，我们需要一个配置文件。创建一个配置文件logback.xml并将其放在classpath resource中，并在配置文件中作如下简单配置：\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;configuration\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt;   接下来，我们写一个简单的测试类：\n1 2 3 4 5 6 7 8 9  public class Example { private static final Logger logger = LoggerFactory.getLogger(Example.class); public static void main(String[] args) { logger.info(\u0026#34;Example log from {}\u0026#34;, Example.class.getSimpleName()); } }   类Example创建了一个Logger，并且在main方法中调用了info()方法，以此来生成日志。\n当运行Example时，可以在控制台看到日志信息：\n20:34:22.136 [main] INFO Example - Example log from Example 你看，不到几分钟，Logback的使用就搞定了，知道Logback为什么这么流行了吧（笑）。\n别高兴，我们还是回头看看log.xml这个配置文件干了些啥吧：\n 我们定义了一个Appender：STDOUT，引用的类是ConsoleAppender。 我们定义了日志信息输出格式模版。 Examlple类创建了一个Logger，我们通过info()方法将日志信息传递给它处理。  5 Logger上下文 5.1 创建Logger 为了使用Logback记录日志，首先使用SLF4J创建一个Logger实例：\n1 2  private static final Logger logger = LoggerFactory.getLogger(Example.class);   随即我们就可以这样使用它：\n1  logger.info(\u0026#34;Example log from {}\u0026#34;, Example.class.getSimpleName());   上例中我们创建的Logger就是日志上下文。通过传递当前类对象给LoggerFactory的静态方法getLogger(Example.class)，即可获得当前类的日志上下文对象logger。当然，除了使用class作为参数之外，还可以使用字符串作为参数。\n日志上下文有等级（继承）关系，这点和Java的对象的继承关系很像：\n 当一个Logger的名字后面跟随有点(.)时，其是一个祖Logger，点和其后的名字组成了子Logger。 当一个Logger没有既没有父Logger也没有Logger时，它自己就是一个就是一个父Logger。  例如在包com.baeldung.logback包中有一个类Example，其子包com.baeldung.logback.appenders中，有一个类ExampleAppender，那么ExampleAppender的Logger就是Example的子Logger。\n所有的Logger都是系统预定义的root Logger的子Logger。\nLogger拥有日志级别level，日志级别可以通过配置文件配置，也可以通过代码Logger.setLevel配置。在代码中的配置会覆盖配置文件中的配置。\n一般来说，日志级别按照优先级从低到高依次为：TRACE，DEBUG，INFO，WARN和ERROR。每个级别都有对应的处理日志的方法。\n如果一个Logger没有显式地配置日志级别，它从其最近的父Logger中继承日志级别。root Logger的默认级别是DEBUG。下文将展示如何配置并使用日志上下文。\n5.2 如何使用日志上下文 下面的示例展示了日志上下文的等级关系：\n1 2 3 4 5 6 7 8 9 10 11 12  ch.qos.logback.classic.Logger parentLogger = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(\u0026#34;com.baeldung.logback\u0026#34;); parentLogger.setLevel(Level.INFO); Logger childlogger = (ch.qos.logback.classic.Logger)LoggerFactory.getLogger(\u0026#34;com.baeldung.logback.tests\u0026#34;); parentLogger.warn(\u0026#34;This message is logged because WARN \u0026gt; INFO.\u0026#34;); parentLogger.debug(\u0026#34;This message is not logged because DEBUG \u0026lt; INFO.\u0026#34;); childlogger.info(\u0026#34;INFO == INFO\u0026#34;); childlogger.debug(\u0026#34;DEBUG \u0026lt; INFO\u0026#34;);   运行程序，我们看到如下输出：\n20:31:29.586 [main] WARN com.baeldung.logback - This message is logged because WARN \u0026gt; INFO. 20:31:29.594 [main] INFO com.baeldung.logback.tests - INFO == INFO 首先我们创建一个名为com.baeldung.logback的parentLogger，并将其类型转换为ch.qos.logback.classic.Logger。\n日志上下文创建之后就要设置其日志级别，由于SLF4j的抽象Logger没有实现setLevel()方法，这也是我们在创建时候进行类型转换的原因。\n将日志上下文的日志级别设置为INFO，接下来创建一个名为com.baeldung.logback.tests的childLogger，由上面的表述可知，这个Logger是名为com.baeldung.logback的子Logger。\n每个Logger上下文都输出2个日志信息，Logback过滤了DEBUG日志，打印了WARN和INFO级别的日志。\n接下来，我们看看root logger的行为：\n1 2 3 4 5 6 7 8 9 10 11 12  ch.qos.logback.classic.Logger logger = (ch.qos.logback.classic.Logger)LoggerFactory.getLogger(\u0026#34;com.baeldung.logback\u0026#34;); logger.debug(\u0026#34;Hi there!\u0026#34;); Logger rootLogger = (ch.qos.logback.classic.Logger)LoggerFactory.getLogger(org.slf4j.Logger.ROOT_LOGGER_NAME); logger.debug(\u0026#34;This message is logged because DEBUG == DEBUG.\u0026#34;); rootLogger.setLevel(Level.ERROR); logger.warn(\u0026#34;This message is not logged because WARN \u0026lt; ERROR.\u0026#34;); logger.error(\u0026#34;This is logged.\u0026#34;);   运行程序，我们看到如下输出：\n20:44:44.241 [main] DEBUG com.baeldung.logback - Hi there! 20:44:44.243 [main] DEBUG com.baeldung.logback - This message is logged because DEBUG == DEBUG. 20:44:44.243 [main] ERROR com.baeldung.logback - This is logged. 首先我们使用com.baeldung.logback的Logger输出DEBUG日志（其继承自root Logger的日志级别）。\n然后，我们通过静态域直接获取root Logger，并且将root Logger的日志级别改为ERROR。\n最后，我们看到Logback过滤了任何级别低于ERROR的日志。\n5.3 参数化日志输出 和上述使用的简单示例不同，大多数日志框架在打印日志信息时，都需要进行字符串拼接或者对象序列化操作，，这些操作都需要进行内存分配，和（可能的）垃圾回收操作。\n考虑下面的示例：\n1  log.debug(\u0026#34;Current count is \u0026#34; + count);   这个示例增加了拼接信息的开销——无论这个消息是否被Logback过滤，都需要先进行消息拼接。\nLogback通过参数化消息提供了一个替代方案：\n1  log.debug(\u0026#34;Current count is {}\u0026#34;, count);   大括号{}接收任何对象（Object），并且在确认这个消息会被使用后，才调用其toString()方法构建消息。\nLogback还支持其他形式的参数输出：\n1 2 3 4 5 6 7 8 9 10  String message = \u0026#34;This is a String\u0026#34;; Integer zero = 0; try { logger.debug(\u0026#34;Logging message: {}\u0026#34;, message); logger.debug(\u0026#34;Going to divide {} by {}\u0026#34;, 42, zero); int result = 42 / zero; } catch (Exception e) { logger.error(\u0026#34;Error dividing {} by {} \u0026#34;, 42, zero, e); }   以上片段将输出：\n21:32:10.311 [main] DEBUG com.baeldung.logback.LogbackTests - Logging message: This is a String 21:32:10.316 [main] DEBUG com.baeldung.logback.LogbackTests - Going to divide 42 by 0 21:32:10.316 [main] ERROR com.baeldung.logback.LogbackTests - Error dividing 42 by 0 java.lang.ArithmeticException: / by zero at com.baeldung.logback.LogbackTests.givenParameters_ValuesLogged(LogbackTests.java:64) ... 上面的示例展示了使用字符串，整型（int/Integer）作为日志输出参数。\n此外，当向日志方法传递Exception实例时，Logback将会打印异常的堆栈信息。\n6 Logback详细配置 在第4节中，Logback仅仅使用了11行的基础配置，即可完成工作。这是Logback的默认行为，如果Logback没有发现配置文件，它将配置一个ConsoleAppender并将其和root logger关联。\n6.1 定位配置文件 Logback的配置文件可以放置在classpath中，并且以logback.xml或者logback-test.xml命名。\nLogback发现配置文件的步骤如下：\n 按序依次在classpath中在查找logback-test.xml,logback.groovy,logback.xml; 若没有发现上述文件，Logback将使用Java ServiceLoader加载com.qos.logback.classic.spi.Configurator的实现； 配置Logback的控制台日志输出  当前Logback版本不支持Groovy配置。？？  6.2 基础配置 我们不妨重新看看第4节中的基础配置：\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;configuration\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt;   所有Logback配置都置于\u0026lt;configuration\u0026gt;标签中。\n注意\u0026lt;appender\u0026gt;标签，我们将其指定为ConsoleAppender，并将其命名为STDOUT。其内部有一个\u0026lt;encoder\u0026gt;标签，该标签内部定义了\u0026lt;pattern\u0026gt;\u0026ndash;这是日志的输出格式。\n接下来是一个\u0026lt;root\u0026gt;标签，这个标签设置root logger的日志级别为DEBUG，并且将其输出与appender STDOUT相关联。\n6.3 配置文件主动捉虫 Logback的配置文件有时候会相当复杂，因此Logback集成了一些机制来进行问题检测。\n如果想查看Logback处理日志时的debug信息，可以开启debug logging:\n1 2 3  \u0026lt;configuration debug=\u0026#34;true\u0026#34;\u0026gt; ... \u0026lt;/configuration\u0026gt;   如此做，Logback会在控制台打印加载配置文件时的状态信息：\n23:54:23,040 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Found resource [logback-test.xml] at [file:/Users/egoebelbecker/ideaProjects/logback-guide/out/test/resources/logback-test.xml] 23:54:23,230 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender] 23:54:23,236 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [STDOUT] 23:54:23,247 |-INFO in ch.qos.logback.core.joran.action.NestedComplexPropertyIA - Assuming default type [ch.qos.logback.classic.encoder.PatternLayoutEncoder] for [encoder] property 23:54:23,308 |-INFO in ch.qos.logback.classic.joran.action.RootLoggerAction - Setting level of ROOT logger to DEBUG 23:54:23,309 |-INFO in ch.qos.logback.core.joran.action.AppenderRefAction - Attaching appender named [STDOUT] to Logger[ROOT] 23:54:23,310 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - End of configuration. 23:54:23,313 |-INFO in ch.qos.logback.classic.joran.JoranConfigurator@5afa04c - Registering current configuration as safe fallback point 若读取配置文件时出现警告或错误信息，Logback会将其状态信息输出到控制台。\n除了debug logging之外，还有另一种方式可以打印Logback的状态信息：\n1 2 3 4  \u0026lt;configuration\u0026gt; \u0026lt;statusListener class=\u0026#34;ch.qos.logback.core.status.OnConsoleStatusListener\u0026#34; /\u0026gt; ... \u0026lt;/configuration\u0026gt;   StatusListener在Logback进行配置和程序运行时拦截状态信息，并将其输出。\n所有配置文件的状态信息都将输出，这样就很容易定位问题。\n6.4 自动重载配置文件 应用程序运行时自动重新加载配置文件往往能有助于定位程序bug。Logback通过scan参数来配置自动加载配置文件：\n1 2 3  \u0026lt;configuration scan=\u0026#34;true\u0026#34;\u0026gt; ... \u0026lt;/configuration\u0026gt;   默认情况下，Logback每60s扫描一次配置文件，通过scanPeriod参数改变这一配置：\n1 2 3  \u0026lt;configuration scan=\u0026#34;true\u0026#34; scanPeriod=\u0026#34;15 seconds\u0026#34;\u0026gt; ... \u0026lt;/configuration\u0026gt;   注意scanPeriod的赋值，其带有一个指示时间单位的字符串，其值可以是 milliseconds，seconds， minutes和hours。\n6.5 配置Loggers 在之前的简单配置中，我们配置了root logger的日志级别，并将其与STDOUT（console Appender）相关联。\n实际上，我们可以设置任意多个logger:\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;configuration\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;com.baeldung.logback\u0026#34; level=\u0026#34;INFO\u0026#34; /\u0026gt; \u0026lt;logger name=\u0026#34;com.baeldung.logback.tests\u0026#34; level=\u0026#34;WARN\u0026#34; /\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt;   使用如下代码片段测试此配置：\n1 2 3 4 5 6 7 8 9 10 11 12  Logger foobar = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(\u0026#34;com.baeldung.foobar\u0026#34;); Logger logger = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(\u0026#34;com.baeldung.logback\u0026#34;); Logger testslogger = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(\u0026#34;com.baeldung.logback.tests\u0026#34;); foobar.debug(\u0026#34;This is logged from foobar\u0026#34;); logger.debug(\u0026#34;This is not logged from logger\u0026#34;); logger.info(\u0026#34;This is logged from logger\u0026#34;); testslogger.info(\u0026#34;This is not logged from tests\u0026#34;); testslogger.warn(\u0026#34;This is logged from tests\u0026#34;);   输出的结果很容易预测，如果你没有猜中，那么有必要回头看看第5节Logger相关的内容。\n此测试的输出为：\n00:29:51.787 [main] DEBUG com.baeldung.foobar - This is logged from foobar 00:29:51.789 [main] INFO com.baeldung.logback - This is logged from logger 00:29:51.789 [main] WARN com.baeldung.logback.tests - This is logged from tests 若没有显式地配置logger，就像上例中的foobar一样，配置文件会自动配置它们，com.baeldung.foobar实际上继承了root logger的DEBUG日志级别。\nloggers还可以从root logger继承appender-ref，我们在接下来的配置中能够看到这点。\n6.6 定义属性变量 Logback的配置文件支持配置变量，变量可以配置在\u0026lt;configuration\u0026gt;标签内的的任何地方。\n下例配置FileAppender时用到了变量：\n1 2 3 4 5 6 7 8  \u0026lt;property name=\u0026#34;LOG_DIR\u0026#34; value=\u0026#34;/var/log/application\u0026#34; /\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${LOG_DIR}/tests.log\u0026lt;/file\u0026gt; \u0026lt;append\u0026gt;true\u0026lt;/append\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt;   在配置appender之前，我们定义了一个属性变量LOG_DIR，接下来，在配置appender的文件地址时用到了这个变量。\n变量除了配置在\u0026lt;property\u0026gt;标签内部，还可以从外部源中获取\u0026ndash;例如从系统属性（system properties）中。如果忽略上面示例中的\u0026lt;property\u0026gt;标签配置，我们还可以这样使用它：\n1  $ java -DLOG_DIR=/var/log/application com.baeldung.logback.LogbackTests   通过系统属性指定变量键值对，在Logback配置文件中通过${propertyName}的方式即可获取变量的值。\n7 Appenders loggers传递日志事件（logging events）给appenders。日志输出（记录）工作实际上是由appender完成的。通常我们认为“日志”就是在控制台或者日志文件中呈现一些内容，但是Logback能做的更多。Logback-core提供了几个有用的appender。\n7.1 控制台日志 此文到这里，ConsoleAppender相信你已经不再陌生了。ConsoleAppender主要用来向System.out或System.err追加信息。\n它使用OutputStreamWriter来缓冲I/O[^so directing it to System.err does not result in unbuffered writing]。\n7.2 文件日志 FileAppender将日志信息追加到系统文件。它的配置相对复杂，让我们先试试在之前的配置文件中增加一个FileAppender配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;configuration debug=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;!-- encoders are assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;tests.log\u0026lt;/file\u0026gt; \u0026lt;append\u0026gt;true\u0026lt;/append\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;com.baeldung.logback\u0026#34; level=\u0026#34;INFO\u0026#34; /\u0026gt; \u0026lt;logger name=\u0026#34;com.baeldung.logback.tests\u0026#34; level=\u0026#34;WARN\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34; /\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt;   FilesAppender通过\u0026lt;file\u0026gt;标签来配置日志文件地址。\n\u0026lt;append\u0026gt;标签配置布尔值true，意味着追加日志信息到文件，而不是抹掉之前的信息。若我们多次运行，会发现日志文件记录了所有的运行日志。\n注意logger com.baeldung.logback.tests的配置：上例中将其日志级别设置为WARN，并且将其和FILE appender关联，这意味着此logger WARN级别以上的日志将会在日志文件test.log中记录。同时，由于其本身继承自root logger，所以控制台会输出其DEBUG级别的日志，如此，便记录了重复的日志。\nLogback可以改变子logger的行为，使其和root logger独立工作：\n1 2 3 4 5 6 7  \u0026lt;logger name=\u0026#34;com.baeldung.logback.tests\u0026#34; level=\u0026#34;WARN\u0026#34; additivity=\u0026#34;false\u0026#34; \u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34; /\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt;   通过将additivity属性设置为false，可以改变logger的默认行为，logger com.baeldung.logback.tests及其导出logger的日志将不再显示在控制台。\n7.3 滚动文件日志 多数时候，将日志文件记录到一个文件中并不是我们期待的（可能会记录一个达几个G的文本文件）。我们常希望日志文件能够基于日期、文件大小、或二者联合配置来“滚动”记录。\n因此，Logback提供了RollingFileAppender：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;property name=\u0026#34;LOG_FILE\u0026#34; value=\u0026#34;LogFile\u0026#34; /\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${LOG_FILE}.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;!-- daily rollover --\u0026gt; \u0026lt;fileNamePattern\u0026gt;${LOG_FILE}.%d{yyyy-MM-dd}.gz\u0026lt;/fileNamePattern\u0026gt; \u0026lt;!-- keep 30 days\u0026#39; worth of history capped at 3GB total size --\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;totalSizeCap\u0026gt;3GB\u0026lt;/totalSizeCap\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt;   RollingFileAppender需要配置滚动策略（rolling policy），上面的示例配置中，我们配置了TimeBasedRollingPolicy。\n和FileAppender类似，RollingFileAppender首先需要配置文件名，上例使用了占位符变量填充的方式配置文件名，这种方式前文已经说过了。\n让我看看\u0026lt;rollingPolicy\u0026gt;标签的配置，\u0026lt;fileNamePattern\u0026gt;的配置值不仅仅定义了日志文件的名字，还定义了其滚动策略。TimeBasedRollingPolicy检查fileNamePattern并且按照友好的方式滚动日志文件。\n例如：\n1 2 3 4 5 6 7 8 9  \u0026lt;property name=\u0026#34;LOG_FILE\u0026#34; value=\u0026#34;LogFile\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;LOG_DIR\u0026#34; value=\u0026#34;/var/logs/application\u0026#34; /\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${LOG_DIR}/${LOG_FILE}.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;${LOG_DIR}/%d{yyyy/MM}/${LOG_FILE}.gz\u0026lt;/fileNamePattern\u0026gt; \u0026lt;totalSizeCap\u0026gt;3GB\u0026lt;/totalSizeCap\u0026gt; \u0026lt;/rollingPolicy\u0026gt; ...   上述配置中，当前活动的配置文件是/var/logs/application/LogFile，这个文件在每月开始即滚动至\n/Current Year/Current Month/LogFile.gz，之后，RollingFileAppender会再创建一个新的活动日志文件LogFile。\n当所有日志文件大小达到3GB之后，RollingFileAppender会删除最早的日志文件。\n滚动周期的设置很灵活，可以是月，周，日，时，分，秒，甚至毫秒。\nRollingFileAppender还支持日志文件压缩，上例中，由于使用了.gz的文件后缀，滚动日志文件将被压缩。\n需要说明的是，TimeBasedRollingPolicy并不是滚动日志的唯一选择，Logback同时还提供了SizeAndTimeBasedRollingPolicy，它能够同时根据当前日志文件大小和时间来决定日志的滚动策略。此外，Logback还提供FixedWindowRollingPolicy，其在每次日志系统启动的时候滚动日志。\n此外，Logback还支持自定义日志滚动策略，具体细节可以参考：https://logback.qos.ch/manual/appenders.html#onRollingPolicies\n7.4 自定义Appender 通过继承Logback的任一基础appender类，就可以自定义我们自己的appender了，这里有一个示例。\n8 日志输出格式 虽然日志输出格式能够自定义，不过，由于可选参数组合太多，往往花费时间反而得不到想要的效果。实际上，默认的输出格式能够满足大多数应用的需求。\n目前示例中使用的输出格式是：\n1 2 3  \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt;   这段配置脚本配置了PatternLayoutEncoder，通过向Appender传递Encoder，Encoder中配置的pattern将会应用到日志输出格式上。\n输出模式（PatternLayout）通过大量转换以及格式修饰符来决定日志输出的格式。\n我们不妨拆解一下上面的pattern，Logback PatternLayout通过%前缀来识别转换符，所以上述配置中的转换符有：\n %d{HH:mm:ss.SSS}，包含时分秒、毫秒的时间戳； [%thread]，使用方括号包括的生成日志的线程名； %-5level，日志级别，padded to 5 characters； %logger{36}，logger名字，压缩至36个字符内； %msg%n，日志信息+系统换行符  如此配置之后，我们可以看到类似这样的日志输出：\n1  21:32:10.311 [main] DEBUG com.baeldung.logback.LogbackTests - Logging message: This is a String   完整的转换以及格式修饰符可以查看这里的官方文档。\n9 总结 这篇教程总结了Logback的基础用法。\n文章介绍了Logback架构中的3个主要构件：loggers，appenders和layout。Logback配置文件功能丰富强大，通过其可以控制日志的过滤以及格式化规则。此外，本文还介绍了2个经常使用的appender，通过appender配置，Logback可以按照需求进行日志的创建、滚动、组织和压缩。\n原文地址: https://www.baeldung.com/logback\n","description":"","id":6,"section":"posts","tags":[""],"title":"使用Logback记录日志","uri":"http://wangy325.top/zh/posts/java/trans/guide-to-logback-cn/"},{"content":"现在流行在项目中使用swagger对接口进行测试，这确实很方便、直观。\n但是MockMvc作为spring-test包中指定的测试框架，在没有使用swagger的项目中，使用其进行测试是很好的选择。\n本文简单介绍在springboot项目中使用Mockito和MockMvc对控制器进行测试。\n1 了解Mockito 简单来说，Mockito是一个模拟创建对象的框架，利用它提供的API，可以简化单元测试工作。Mockito的API易读性是很好的，并且错误信息也很简明。spring-boot-starter-test模块中引入了mockito依赖，如果你使用springboot，那么就可以直接使用Mockito进行单元测试。\n我们从Mockito官方API文档的的引例开始，看看Mockito是如何工作的。\n1.1 mock一个对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14  // 学会使用静态导入，代码会更简洁  import static org.mockito.Mockito.*; // mock List接口对象  List mockedList = mock(List.class); // 使用Mock的List对象  mockedList.add(\u0026#34;one\u0026#34;); mockedList.clear(); // 校验某个行为是否发生过1次  verify(mockedList).add(\u0026#34;one\u0026#34;); verify(mockedList).clear();   一旦mock对象被创建，mock会记住对其的所有操作，之后，你便可以选择性的校验这些操作。\n1.2 绑定方法参数和返回值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // 也可以mock实体类对象  LinkedList mockedList = mock(LinkedList.class); // 为指定参数的操作绑定返回值（stubbing）  when(mockedList.get(0)).thenReturn(\u0026#34;first\u0026#34;); when(mockedList.get(1)).thenThrow(new RuntimeException()); // 打印 first  System.out.println(mockedList.get(0)); // 抛出 RunTimeException  System.out.println(mockedList.get(1)); // 打印null，因为get(999)的返回值没有指定  System.out.println(mockedList.get(999)); // 尽管也可以对绑定操作进行校验，不过这通常是非必要的  // 如果你关注get(0)的返回值，那么你应该在代码里进行测试  // 如果get(0)的返回值无关紧要，那么就没有必要进行绑定  verify(mockedList).get(0);   一般来说，对于任意有返回值的方法，mockito都会返回null、原始类型/原始类型的包装类、或者一个空的集合。\n返回值的绑定操作可以被覆盖。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // 返回值的绑定可以连续设置 // 最后一次绑定就是实际调用的返回值 // 例如，mock.someMethod(\u0026#34;some arg\u0026#34;)将返回“foo” when(mock.someMethod(\u0026#34;some arg\u0026#34;)) .thenThrow(new RuntimeException()) .thenReturn(\u0026#34;foo\u0026#34;); // 连续绑定的简单形式： when(mock.someMethod(\u0026#34;some arg\u0026#34;)) .thenReturn(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;); // 等价于： when(mock.someMethod(\u0026#34;some arg\u0026#34;)) .thenReturn(\u0026#34;one\u0026#34;) .thenReturn(\u0026#34;two\u0026#34;); // 抛出异常的简单形式： when(mock.someMethod(\u0026#34;some arg\u0026#34;)) .thenThrow(new RuntimeException(), new NullPointerException());   一旦方法的返回值被绑定，那么其将一直返回绑定的值，无论其被调用多少次。\n1.3 参数匹配器 上面形式的返回值绑定在测试时似乎很好用，我们构建参数，设置预期的返回结果，再进行校验即可。但仔细想想，或许少了点什么？对，少了参数的模糊匹配，比如我想绑定get(int)方法的返回值，无论其参数是多少。mockito自然能够为我们做到这些：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 使用mockito内建的anyInt()来进行匹配  when(mockedList.get(anyInt())).thenReturn(\u0026#34;element\u0026#34;); //stubbing using custom matcher (let\u0026#39;s say isValid() returns your own matcher implementation):  // 使用自定义matcher进行绑定  when(mockedList.contains(argThat(isValid()))).thenReturn(true); //following prints \u0026#34;element\u0026#34;  // 打印999  System.out.println(mockedList.get(999)); // 也可以校验方法被调用了一次  verify(mockedList).get(anyInt()); // mockito同样支持java8的lambda表达式进行参数匹配  verify(mockedList).add(argThat(someString -\u0026gt; someString.length() \u0026gt; 5));   参数匹配可以方便地进行动态返回值绑定校验。\n想了解更多关于 argument matcher和hamcrest matcher的内容，可参考：\n https://javadoc.io/static/org.mockito/mockito-core/3.8.0/org/mockito/ArgumentMatchers.html https://javadoc.io/static/org.mockito/mockito-core/3.8.0/org/mockito/hamcrest/MockitoHamcrest.html  除了使用matcher之外，mockito还支持使用类型（class）匹配，这种参数匹配方式在进行MVC测试时，对json参数进行序列化和反序列化时尤其有用：\n1 2 3 4 5 6 7  when(spittleService.pageQuerySpittlesByTimeLine(any(SpittleDTO.class))).thenReturn(page); ResultActions resultActions = mockMvc .perform(MockMvcRequestBuilders.post(\u0026#34;/spittle/range/spittles\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .content(jsonString) );   就像上面那样，在使用RequestBody传参时，若使用JSON，需要对json字符串进行反序列化。这种情形，在进行参数绑定时，自然不能使用\n1  when(spittleService.pageQuerySpittlesByTimeLine(spittleDTO).thenReturn(page);   这样的形式，因为控制器接收到的必然不是这个指定的spittleDTO对象。使用类类型参数，mockito进行参数匹配时，使用equals方法比较的对象的相等性，因此可以获取绑定的返回值。\n Sometimes its just better to refactor the code to allow equals() matching or even implement equals() method to help out with testing.\n 1.4 检验方法被调用的次数 前文我们提到，verify()方法可以校验指定方法被调用过一次。\nmokito提供了更加灵活的校验API，可以用来检验指定方法被调用的次数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  //using mock mockedList.add(\u0026#34;once\u0026#34;); mockedList.add(\u0026#34;twice\u0026#34;); mockedList.add(\u0026#34;twice\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); // 当verify方法不指定次数时，默认检验方法调用1次，以下2个调用是等价的 verify(mockedList).add(\u0026#34;once\u0026#34;); verify(mockedList, times(1)).add(\u0026#34;once\u0026#34;); // add(\u0026#34;twice)被调用了2次 verify(mockedList, times(2)).add(\u0026#34;twice\u0026#34;); // add(\u0026#34;three times\u0026#34;)被调用了3次 verify(mockedList, times(3)).add(\u0026#34;three times\u0026#34;); // add(\u0026#34;never happened\u0026#34;)方法没有被调用 // 等价于 times(0) verify(mockedList, never()).add(\u0026#34;never happened\u0026#34;); // 使用atLeast()/atMost()可以校验参数至少/至多被调用几次 verify(mockedList, atMostOnce()).add(\u0026#34;once\u0026#34;); verify(mockedList, atLeastOnce()).add(\u0026#34;three times\u0026#34;); verify(mockedList, atLeast(2)).add(\u0026#34;three times\u0026#34;); verify(mockedList, atMost(5)).add(\u0026#34;three times\u0026#34;);   times(1)是默认，因此verify(mockedList, times(1)).add(\u0026quot;once\u0026quot;)这样的形式是不必要的。\n除了上面介绍的之外，moikito还有很多使用的测试方法，具体可以参考API文档：\n https://javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html#in_order_verification  2 使用MockMvc测试控制器 介绍了mockito的基本用法，可以开始用它测试控制器了。\nspring web项目的测试使用的是Spring MVC测试框架（Spring MVC Test framework(MockMvc)），其使用方式和Mockito很像，实际上MockMvc借用了Mockito的API，因此，熟悉Mockito的使用对使用MockMVC测试web服务大有裨益。\n2.1 熟悉这几个静态导入  MockMvcBuilders.* MockMvcRequestBuilders.* MockMvcResultMatchers.* MockMvcResultHandlers.*  和Mockito一样，熟悉并使用静态导入会让代码看起来更简洁。不过，对刚使用MockMVC进行测试的新手来说，使用静态导入可能会陷入一个麻烦：方法这么多，我怎么记得这个方法该使用哪个静态导入，容易陷入混乱。\n不过，记住他们的惯用法就行了：\n1 2 3 4 5 6 7 8 9 10 11 12  // MockMvcBuilders.* 用于构建MockMvc应用 MockMvc mockMvc = MockMvcBuilders.stansaloneSetup(controller).build(); // MockMvcRequestBuilders.*用于构建请求 ResultActions resultActions = mockMvc.perform(MockMvcRequestBuilders.get(url)); ResultActions resultActions = mockMvc.perform(MockMvcRequestBuilders.post(url)); // MockMvcResultMatchers.*用于请求结果匹配 resultActions.andExpect(MockMvcResultMatchers.status().isOK()) // MockMvcResultHandlers.* 嘛，用得少，其提供一个print()方法，可以打印请求信息 resultActions.andDo(MockMvcResultHandlers.print());   2.2 测试示例 在进行单元测试时，通常习惯将通用模版进行抽象，本示例中也是如此，我们建立一个抽象测试类，用于准备数据、提供通用方法等：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @SpringBootTest @TestPropertySource(\u0026#34;classpath:application-test.properties\u0026#34;) public class BaseMockInit { // @Autowired // protected ObjectMapper objectMapper;  protected ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json().build(); protected @Mock ISpitterService spitterService; protected @Mock ISpittleService spittleService; protected SpitterController spitterController; protected SpittleController spittleController; @BeforeEach void initMock() { MockitoAnnotations.initMocks(this); spitterController = new SpitterController(); spitterController.setSpitterService(spitterService); spittleController = new SpittleController(); spittleController.setSpittleService(spittleService); } }   你可能注意到上面的示例中使用的@Mock注解和MockitoAnnotations.initMocks(this);方法，实际作用就是mock web测试中所需要使用到的服务层service，因为测试web模块不涉及到数据服务层的业务，因此借助Mockito即可轻松创建测试所需要的实例。\n2.2.1 简单路径参数GET请求测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  @Test public void getSpitterById() throws Exception { SpitterVO source = new SpitterVO(1, \u0026#34;alan\u0026#34;, \u0026#34;walker\u0026#34;, \u0026#34;aw\u0026#34;, \u0026#34;xxx\u0026#34;); Spitter spitter = new Spitter(); BeanUtils.copyBeanProp(spitter, source); when(spitterService.getById(1)).thenReturn(spitter); spitterController.setSpitterService(spitterService); MockMvc mockMvc = standaloneSetup(spitterController).build(); // perform get request with path variables  ResultActions resultActions = mockMvc.perform(get(\u0026#34;/spitter/1\u0026#34;)); log.info(resultActions.andReturn().getResponse().getContentAsString(StandardCharsets.UTF_8)); resultActions.andExpect(status().isOk()) .andExpect(content().contentType(MediaType.APPLICATION_JSON)) .andExpect(jsonPath(\u0026#34;$.data\u0026#34;) .value(objectMapper.convertValue(spitter, HashMap.class))); verify(spitterService).getById(1); }   观察上面的测试用例，我们首先使用Mockito对数据层的mock对象进行了参数和返回值绑定，这在前文已经提及：\n1  when(spitterService.getById(1)).thenReturn(spitter);   随即使用MockMvc发起get请求，发起请求的方式有多种：\n1 2 3  ResultActions resultActions = mockMvc.perform(get(\u0026#34;/spitter/1\u0026#34;)); // 等价于 ResultActions resultActions = mockMvc.perform(get(\u0026#34;/spitter/{id}\u0026#34;, 1));   当请求进入控制器时，根据控制器的业务逻辑，调用spitterService.getById(1)方法，该方法返回之前绑定的返回值，进行封装之后，返回web请求的结果。\n上述请求返回一个ResultActions结果，web请求的结果被封装在内，我们可以对这个结果进行校验：\n1 2 3 4  resultActions.andExpect(status().isOk()) .andExpect(content().contentType(MediaType.APPLICATION_JSON)) .andExpect(jsonPath(\u0026#34;$.data\u0026#34;) .value(objectMapper.convertValue(spitter, HashMap.class)));   注意到，jsonPath(\u0026quot;$.data\u0026quot;)，这意味着请求返回的json字串中包含一个data键，.value()操作暗示其对应的内容就是spitterService.getById(1)的返回对象。所以这个请求返回的json应该像这样：\n1 2 3 4 5 6 7 8 9 10 11  { \u0026#34;code\u0026#34;: 200, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: 1, \u0026#34;usename\u0026#34;: \u0026#34;aw\u0026#34;, \u0026#34;firstname\u0026#34;: \u0026#34;alan\u0026#34;, \u0026#34;lastname\u0026#34;: \u0026#34;walker\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34; } }   1  .andExpect(jsonPath(\u0026#34;$.data\u0026#34;).value(objectMapper.convertValue(spitter, HashMap.class)));   的意义是比较通过jsonPath(\u0026quot;$.data\u0026quot;)解析到的对象和objectMapper.convertValue(spitter, HashMap.class))获取到的对象的相等性。\n实际上，通过jsonPath(\u0026quot;$.data\u0026quot;)获取到的内容是一个LinkedHashMap，而.value()的相等性比较的是map中对应键的值的相等性，单单从这个示例来讲，这个比较是可行的1。\n最后，我们使用verify方法对mock对象的方法调用进行了测试：\n1  verify(spitterService).getById(1);   不过，由于我们已经校验了web接口的返回值，那么mock对象的方法一定被调用了，所以一般我们无需这么做。\n2.2.2 拼接参数的GET方法测试 除了路径参数，使用最多的就是形如?para1=xxx\u0026amp;para2=xxx这样的请求参数，MockMvc同样对这样的web服务提供测试支持\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  @Test public void getUserSpittlesPageTest() throws Exception { // ... 省略准备数据  // 此处必须使用类类型作为参数  when(spittleService.pageQuerySpittleBySpitterId(any(SpittleDTO.class))).thenReturn(page); // perform get with request params transferred by pojo  ResultActions resultActions = mockMvc .perform(get(\u0026#34;/spittle/user/spittles?spitterId={spitterId}\u0026#34;, 4)) // get element from json  // see https://github.com/json-path/JsonPath  .andExpect(jsonPath(\u0026#34;$.data.currentPage\u0026#34;) .value(pageDomain.getCurrentPage())) .andExpect(jsonPath(\u0026#34;$.data.pageSize\u0026#34;) .value(pageDomain.getPageSize())) .andExpect(jsonPath(\u0026#34;$.data.pages\u0026#34;) .value(pageDomain.getPages())) .andExpect(jsonPath(\u0026#34;$.data.total\u0026#34;) .value(pageDomain.getTotal())) .andDo(print()); /* 报错原因 ：long和integer的问题*/ // .andExpect(jsonPath(\u0026#34;$.data.records[0]\u0026#34;) // .value(objectMapper.convertValue(sample, HashMap.class)));  String jsonResult = resultActions.andReturn().getResponse().getContentAsString(StandardCharsets.UTF_8); log.info(jsonResult); // verify is not necessary here  verify(spittleService).pageQuerySpittleBySpitterId(any(SpittleDTO.class)); assertEquals((int) jsonPathParser(jsonResult).read(\u0026#34;$.data.records.length()\u0026#34;), 1); SpittleVO rvo = jsonPathParser(jsonResult).read(\u0026#34;$.data.records[0]\u0026#34;, SpittleVO.class); assertEquals(sample, rvo); }   这个测试和上一个测试有一些区别，首先第一个区别就是mock对象的参数与返回值绑定方式变了：\n1  when(spittleService.pageQuerySpittleBySpitterId(any(SpittleDTO.class))).thenReturn(page);   多数情况下，我们不会直接在控制器中使用具体的参数，而是使用Java Bean作为控制器的参数。这个时候，Spring MVC的MappingJasksonHttpMessageConverter将会发挥作用2，将请求中的中的参数转换为对应的Java Bean实例。\n这样一来，我们便不能指定某一个实例作为mock对象的参数了，只能使用any(class)这样的形式进行模糊匹配。\n其次，关于使用地址栏参数的参数传递，除了使用上述的方式（最简单）之外，还有其他的方式：\n1 2 3  ResultActions resultActions = mockMvc.perform(get(\u0026#34;/spittle/user/spittles?spitterId={spitterId}\u0026#34;, 4)) // 等价于  ResultActions resultActions = mockMvc.perform(get(\u0026#34;/spittle/user\u0026#34;)).param(\u0026#34;spitterId\u0026#34;, 4)   第三，如果再次使用类似于上一个示例那样校验返回数据的方法校验$.data.records[0]，将会得到一个错误。原因也和前文描述的一样。我们必须使用更为稳妥的方法。\n第四，对于同一个控制器的测试，我们可以预先做一些设置，比如依赖@BeforeEach注解，约定好一些通用的内容：\n1 2 3 4 5 6 7 8 9 10 11 12  class MyWebTests { MockMvc mockMvc; @BeforeEach void init(){ mockMvc = standaloneSetup(spittleController) .alwaysExpect(status().isOk()) .alwaysExpect(content().contentType(MediaType.APPLICATION_JSON)) .build(); } }   上述方法在每一个测试之前准备mockMvc对象，并且约定了servlet的返回状态和返回类型。\n2.2.3 POST请求方法测试 如前所述，在发起POST请求时，一般使用JSON，此时MappingJasksonHttpMessageConverter便会介入。它负责将JSON对象反序列化为控制器指定的Java Baean。在使用MockMvc进行测试时，我们直接使用JSON字符串，将其设置在请求体中即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  @Test public void postSpittlesTimeLinePageTest() throws Exception { // ... 省略其他设置  dto.setLeftTime(LocalDateTime.parse(\u0026#34;2012-06-09T00:00:00.000\u0026#34;)); dto.setRightTime(LocalDateTime.parse(\u0026#34;2012-06-09T23:59:59.999\u0026#34;)); when(spittleService.pageQuerySpittlesByTimeLine(any(SpittleDTO.class))).thenReturn(page); // perform post request  String s = objectMapper.writeValueAsString(dto); log.info(\u0026#34;request body: {}\u0026#34;, s); ResultActions resultActions = mockMvc .perform(post(\u0026#34;/spittle/range/spittles\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .characterEncoding(\u0026#34;utf8\u0026#34;) .content(s)) .andDo(print()); // 以下用来获取MockMvc返回(Json)  String jsonResult = resultActions.andReturn().getResponse().getContentAsString(StandardCharsets.UTF_8); log.info(jsonResult); PageDomain\u0026lt;SpittleVO\u0026gt; rpg = jsonPathParser(jsonResult).read(\u0026#34;$.data\u0026#34;, PageDomain.class); assertEquals((int) jsonPathParser(jsonResult).read(\u0026#34;$.data.records.length()\u0026#34;), 1); SpittleVO rvo = jsonPathParser(jsonResult).read(\u0026#34;$.data.records[0]\u0026#34;, SpittleVO.class); rpg.setRecords(new ArrayList\u0026lt;SpittleVO\u0026gt;() {{ add(rvo); }}); assertEquals(rpg, pageDomain); }   可以看到，发起POST请求的方式比较简单：\n1 2 3 4 5  ResultActions resultActions = mockMvc .perform(post(\u0026#34;/spittle/range/spittles\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .characterEncoding(\u0026#34;utf8\u0026#34;) .content(s));   设置好请求头接受的文件类型和编码，使用content(json)方法传入json字符串即可。\n在本节的开头，我们进行了一些通用的配置，你可能暂时还没有注意到这个细节：\n1 2 3  // @Autowired // protected ObjectMapper objectMapper;  protected ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json().build();   我们注释掉了spring自动装配的ObjectMapper，转而使用了Jackson2ObjectMapperBuilder构建了一个默认的ObjectMapper，这样做是有原因的：\n对于spring自动装配的ObjectMapper，我们在项目改变了其对LocalDateTime的序列化与反序列化规则：\n 对于LocalDateTime，默认情况下其字符串输出格式类似于2012-06-09T23:59:59.999，这样的字符串形式非常不利于页面传递参数，因此我们在项目配置中改变了其规则，使得在实际使用时，能够将2012-06-09 23:59:59.999形式的日期字符串直接转化为LocalDateTime对象；反之，LocalDateTime也将会直接转化为2012-06-09 23:59:59.999的形式返回。\n 但是在使用MockMvc进行测试时，其进行反序列化时（将请求JSON转化为Java Bean），使用的可能是默认的消息转换规则。而当我们使用自动装配的ObjectMapper将配置好的Bean转化为JSON时，时间的字符串形式是2012-06-09 23:59:59.999，默认的消息转换无法将其转化为LocaldateTime，因此会出现转换异常。\n关于ObjactMapper的详细内容，会在后续博客中详细介绍。\n3 JsonPath 看到这里，你可能对使用Mockito和MockMvc进行测试有了初步的了解。不过如果你细心的话，就会发现，前面的测试用例对最后的接口的返回校验都没有提及。并且示例代码中关于提取返回内容出现最多的字就是jsonPath。\n并且在前面的测试用例中，我们也通过简单的表达式jsonPath(\u0026quot;$.data\u0026quot;)提取了返回JSON中的结果。\n实际上，Spring MockMvc默认是支持使用JsonPath获取返回内容的，就像jsonPath(\u0026quot;$.data\u0026quot;)那样，不过其灵活性没有直接使用JspnPath大，特别是在反序列化的操作上。\n很多时候，RESTful接口返回的内容实际上是Java Bean序列化之后的JSON串，所以我们希望将获取到的JSON反序列化之后再进行校验，而MockMvc在这方面表现的就比较蹩脚了，其只能转化为Map进行比较，就像###2.2.1节中表现的那样3。\n说实话，测试在获取到返回的JSON串，通过控制台打印输出确认符合预期基本上就可以结束，再去检验JSON的内容有点强迫症的意味了。\n其实在JsonPath的仓库里详细地介绍了JsonPath的基本用法，针对本实例的具体情况，通过阅读文档，我们可以很容易取得想要的值并进行校验。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  { \u0026#34;code\u0026#34;:20000, \u0026#34;msg\u0026#34;:\u0026#34;http.ok\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;currentPage\u0026#34;:1, \u0026#34;pageSize\u0026#34;:10, \u0026#34;total\u0026#34;:4, \u0026#34;pages\u0026#34;:1, \u0026#34;records\u0026#34;: [ { \u0026#34;id\u0026#34;:1, \u0026#34;spitterId\u0026#34;:4, \u0026#34;message\u0026#34;:\u0026#34;sixth man\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2012-06-09 22:20:00\u0026#34;, \u0026#34;latitude\u0026#34;:0.0, \u0026#34;longitude\u0026#34;:0.0 } ] } }   我们要校验的就是data中的内容，现在我们再回过头来看看上面的测试代码，实际上很容易理解:\n1 2 3 4 5 6 7  PageDomain\u0026lt;SpittleVO\u0026gt; rpg = jsonPathParser(jsonResult).read(\u0026#34;$.data\u0026#34;, PageDomain.class); assertEquals((int) jsonPathParser(jsonResult).read(\u0026#34;$.data.records.length()\u0026#34;), 1); SpittleVO rvo = jsonPathParser(jsonResult).read(\u0026#34;$.data.records[0]\u0026#34;, SpittleVO.class); rpg.setRecords(new ArrayList\u0026lt;SpittleVO\u0026gt;() {{ add(rvo); }}); assertEquals(rpg, pageDomain);   首先我们获取了$.data节点的内容，里面也是一个Json对象，按照传统的反序列化理解，这是一个Java Bean，我们该如何将其读取为我们程序中的Bean呢，JsonPath也作了说明\n 默认情况下，通过JsonPath.parse(json).read(\u0026quot;$.data\u0026quot;)获取的到的是Map实例，并不会映射为Java Bean。不过JsonPath也为此提供了可能：\n If you configure JsonPath to use JacksonMappingProvider or GsonMappingProvider you can even map your JsonPath output directly into POJO\u0026rsquo;s.\n  要想映射为JavaBean，我们需要：\n 自定义配置JsonProvider 传入类型参数  配置JsonProvider的方式也很简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  /** * Use json-path, tweaking configuration\u0026lt;br\u0026gt; * The config below change default action of json-path\u0026lt;br\u0026gt; * Use application-context ObjectMapper config as json and mapper provider\u0026lt;br\u0026gt; * \u0026lt;p\u0026gt; * Reference: \u0026lt;a href=\u0026#34;https://github.com/json-path/JsonPath\u0026#34;\u0026gt; * https://github.com/json-path/JsonPath\u0026lt;/a\u0026gt; * * @param json standard json string * @return {@link DocumentContext} */ protected DocumentContext jsonPathParser(String json) { final JsonProvider jsonProvider = new JacksonJsonProvider(objectMapper); final MappingProvider mappingProvider = new JacksonMappingProvider(objectMapper); Configuration.setDefaults(new Configuration.Defaults() { @Override public JsonProvider jsonProvider() { return jsonProvider; } @Override public Set\u0026lt;Option\u0026gt; options() { return EnumSet.noneOf(Option.class); } @Override public MappingProvider mappingProvider() { return mappingProvider; } }); return JsonPath.parse(json); }   此时，我们就已经获取到了接口返回的对象。不过等等，我们再仔细看看上面的Json，会发现$.data.records节点是一个数组，数组里面又是可以映射为Java Bean的Json。而经过上一步，获取的PageDomain对象中的records域实际上还是一个List\u0026lt;Map\u0026gt;的默认映射结果，所以我们还需要梅开二度。\n4 补充内容：使用idea直接进行RESTful接口测试 到这里，本文的主要内容就结束了。\n如果你使用的IDEA，你不妨找找tools-\u0026gt;httpClients，你会发现，idea的绝妙功能：其可以通过脚本文件测试rest接口。\nidea提供了不同HTTP请求的脚本示例，很容易就能上手，脚本文件以.http结尾，你可轻松创建自己的测试脚本。\n例如，我为上面的测试创建一个名为rest-api.http的脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  ### get spitter info by spitterId GET {{host}}/spitter/{{spitterId}}?lang={{lang}} Accept: application/json ### 分页获取spittle， 根据用户spitterId，请求参数放在GET请求体中的情形: GET {{host}}/spittle/user/spittles?lang={{lang}} Accept: application/json Content-Type: application/json { \u0026#34;spitterId\u0026#34;: 4, \u0026#34;currentPage\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 1 } ### 分页获取某个时间段的spittle 1 POST {{host}}/spittle/range/spittles?lang={{lang}} Content-Type: application/json { \u0026#34;leftTime\u0026#34;: \u0026#34;2012-06-09 00:00:00\u0026#34;, \u0026#34;rightTime\u0026#34;: \u0026#34;2012-06-09 23:59:59\u0026#34;, \u0026#34;currentPage\u0026#34;:2, \u0026#34;pageSize\u0026#34;: 1 }   可以看到，.http脚本文件的可读性非常强。其中，为了方便，还使用了用双花括号语法的环境变量，这些变量被命名在一个名为http-client-env.json的json文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;mem\u0026#34;: { \u0026#34;host\u0026#34;:\u0026#34;http://localhost:9000/mem\u0026#34;, \u0026#34;spitterId\u0026#34;: 4, \u0026#34;lang\u0026#34;: \u0026#34;en\u0026#34;, \u0026#34;currentPage\u0026#34;: 1, \u0026#34;pageSize\u0026#34;: 2 }, \u0026#34;mysql\u0026#34;:{ \u0026#34;host\u0026#34;: \u0026#34;http://localhost:9100/dev\u0026#34;, \u0026#34;spitterId\u0026#34;: 2, \u0026#34;lang\u0026#34;: \u0026#34;en\u0026#34; } }   运行脚本时，可以通过执行环境配置传入不同的测试参数，就这么简单。\n参考  本文用例所在项目地址：https://www.github.com/wangy325/mybatis-plus-starter mockito官网：https://www.site.mockito.org/ mockito API官网：https://www.javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html MockMvc java doc：https://www.docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/test/web/servlet/MockMvc.html json-path仓库介绍了其基本使用方法：https://www.github.com/json-path/JsonPath 可能出现的bug：https://www.stackoverflow.com/questions/47276920/mockito-error-however-there-was-exactly-1-interaction-with-this-mock MockMvc官方文档：https://www.docs.spring.io/spring-framework/docs/current/reference/html/testing.html#spring-mvc-test-framework MockMVC官方测试示例代码库：https://www.github.com/spring-projects/spring-framework/tree/master/spring-test/src/test/java/org/springframework/test/web/servlet/samples   这种形式的比较往往会出现问题，例如，如果pojo类中的id字段定义为Long型，使用objectMapper进行转换的时候可能会转换为Integer型。 \u0026#x21a9;\u0026#xfe0e;\n 关于Spring MVC的消息转换器，参考《Spring实战，第4版》第16章相关内容。 \u0026#x21a9;\u0026#xfe0e;\n 或许笔者还没有找到更加优雅的方法。 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"","id":7,"section":"posts","tags":["mockito","单元测试"],"title":"在SpringBoot项目中使用MockMvc进行接口测试","uri":"http://wangy325.top/zh/posts/java/spring/%E5%9C%A8springboot%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%BD%BF%E7%94%A8mockmvc%E8%BF%9B%E8%A1%8C%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/"},{"content":" mybatis自 3.4.5 开始，已经支持使用LocaldateTime作为时间查询入参，映射类型为TimeStamp，参考地址: https://mybatis.org/mybatis-3/zh/configuration.html#typeHandlers\n 1 前言 在介绍Java SE 8中新的日期时间库前，先了解下Java 8之前的日期时间工具的诟病。\n在Java SE 8前，日期时间工具库在java.util包中，包括：\n java.util.Date：表示日期和时间 java.util.Calendar以及其实现子类：表示各种日历系统，常用的是格林威治日历java.util.GregorianCalendar java.util.TimeZone以及其实现子类：表示时区偏移量和夏令时  以及辅助其进行格式化和解析的工具库在java.text包中，包括：\n java.text.DateFormat：格式化日期时间和解析日期时间的工具抽象类 java.text.SimpleDateFormat：DateDateFormat的实现  从以上的简述中，对java 8之前的日期时间库，有所宏观视觉。下面简要总结下其设计上的瑕疵和被开发者无限吐槽的诟病：\n 从以上的api上看，java 8之前的日期时间工具库缺乏年、月、日、时间、星期的单独抽象； Date日期时间类既描述日期又描述时间，耦合，且Date不仅在java.util包中存在，在java.sql中也存在，重复名称，容易导致bug发生； api的设计上晦涩，难用，不够生动，难以以自然人类的思维理解日期时间。年月日需要从Calendar中获取； 最被开发者抱怨的是类型不安全，Calendar类中全局属性是可变的，在多线程访问时，会存在线程安全问题。SimpleDateFormat格式化和解析日期，需要使用年月日时分秒，所以持有了Calendar属性，导致其也是非线程安全；  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  // 以下都是Calendar中持有的全局属性 // 这些全局属性都是可变的，提供了set protected int fields[]; transient private int stamp[]; protected long time; protected boolean isTimeSet; // 在其子类GregorianCalendar中 private transient int[] zoneOffsets; // setTime方法会调用此方法 // 该方法中修改了上述的很多全局属性 public void setTimeInMillis(long millis) { // If we don\u0026#39;t need to recalculate the calendar field values,  // do nothing.  if (time == millis \u0026amp;\u0026amp; isTimeSet \u0026amp;\u0026amp; areFieldsSet \u0026amp;\u0026amp; areAllFieldsSet \u0026amp;\u0026amp; (zone instanceof ZoneInfo) \u0026amp;\u0026amp; !((ZoneInfo)zone).isDirty()) { return; } time = millis; isTimeSet = true; areFieldsSet = false; computeFields(); areAllFieldsSet = areFieldsSet = true; }   所以在多线程环境中使用Calendar是非线程安全的 ，多个线程修改其属性域会导致数据一致性和可见性问题。\n在DateFormat中持有了Calendar属性，用于解析和格式化日期：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  // 从注释上看，Calendar用于计算日期时间域 /** * The {@link Calendar} instance used for calculating the date-time fields * and the instant of time. This field is used for both formatting and * parsing. * * \u0026lt;p\u0026gt;Subclasses should initialize this field to a {@link Calendar} * appropriate for the {@link Locale} associated with this * \u0026lt;code\u0026gt;DateFormat\u0026lt;/code\u0026gt;. * @serial */ protected Calendar calendar; // Called from Format after creating a FieldDelegate private StringBuffer format(Date date, StringBuffer toAppendTo, FieldDelegate delegate) { // Convert input date to time field list  calendar.setTime(date); boolean useDateFormatSymbols = useDateFormatSymbols(); for (int i = 0; i \u0026lt; compiledPattern.length; ) { int tag = compiledPattern[i] \u0026gt;\u0026gt;\u0026gt; 8; int count = compiledPattern[i++] \u0026amp; 0xff; if (count == 255) { count = compiledPattern[i++] \u0026lt;\u0026lt; 16; count |= compiledPattern[i++]; } switch (tag) { case TAG_QUOTE_ASCII_CHAR: toAppendTo.append((char)count); break; case TAG_QUOTE_CHARS: toAppendTo.append(compiledPattern, i, count); i += count; break; default: subFormat(tag, count, delegate, toAppendTo, useDateFormatSymbols); break; } } return toAppendTo; }   format方法中设置了全局成员Calendar的time，多线程访问时每次都会改变Calendar类，导致format格式化时会出现线程安全问题。所以DateFormat和其子类SimpleDateFormat都是非类型安全。\n这个可以说是被开发者极度抱怨的。所以在使用日期格式工具时大多数都会重新new或者使用ThreadLocal。\n基于此诸多问题，java设计者终于在Java SE 8中引入了新的日期时间库。新的日期时间库的易用程度会让你振服！下面开始进入主题，Java SE 8中的日期时间库java.time。\n2 概览 先认识下joda项目，joda项目包括：\n Joda-Time - Basic types for Date and Time Joda-Money - Basic types for Money Joda-Beans - Next generation JavaBeans Joda-Convert - String to Object conversion Joda-Collect - Additional collection data structures  其中Joda-Time是日期时间三方库，但是在java 8之前，joda time其实是标准的日期时间库，其出色的语义表达，易用易于理解的api，类型安全的特性，大受开发者的追捧。而且其日历系统遵循的是IOS_8601国际标准，同时还包括其他的非标准的日历系统。支持时区、持续时间、格式化和解析功能。\n在java 8之前可以依赖joda time三方库，使用其日期时间库。\n但在java 8中提出了JSR 310: Date and Time API规范，该规范即新版的日期时间库java.time规约。可以说JSR-310的设计上汲取了大量的joda time的特性。新版本的日期时间库基于JSR 310: Date and Time API开发，java.time是基于国际化标准日历系统（International Organization for Standardization）ISO_8601，同时java.time.chrono支持对全球日历系统的扩展。\nJSR-310中设计的java.time包括年、月、星期、日期时间、持续时间段、瞬时、时钟、时区的抽象及处理。且api的设计上使用易读易于理解的名称和设计模式，让使用者欣然接受。而且提供旧版和新版api之间的互通以处理兼容性问题。\n下面看张概览图，从宏观角度了解下java.time\n 第一层是对年、月、月中日、星期的抽象； 第二层是对日期、日期时间、时区的抽象，其中时区分为时区Id（Europe/Paris）和时区偏移量(Z/+hh:mm/-hh:mm)； 第三层是对区域时间和便宜时间的抽象； 第四层是对瞬时和时钟的抽象； 第五层是对时序时段和持续周期的抽象 右侧层是辅助工具类，如：日期时间格式、日期时间调整器、其他的日历系统；  java 8中日期时间库共分为五个package：\n java.time：基于ISO_8601日历系统实现的日期时间库 java.time.chrono：全球日历系统扩展库，可以自行扩展 java.time.format：日期时间格式，包含大量预定义的格式，可以自行扩展 java.time.zone：时区信息库 java.time.temporal：日期时间调整辅助库  关于日期时间库的使用详细过程，推荐查看oracle提供的java教程The Java™ Tutorials——Trail: Date Time\n3 java.time优点 3.1 设计 java.time中使用了大量的设计模式：\n 工厂模式：now()工厂方法直接生成当前日期时间或者瞬时；of()工厂方法根据年月日时分秒生成日期或者日期时间； 装饰模式：时区时间ZoneDateTime/偏移时间OffsetDateTime，都是在LocalDateTime的基础上加上时区/偏移量的修饰成为时区时间，然后可以进行时区转换； 建造者模式：Calendar中加入建造者类，用于生成新的Calendar对象；  3.2 命名 java 8中的日期时间库类名、方法名命名上都是极其形象生动，易于理解，让开发者极易于使用——语义清晰精确！如：LocalDate中提供的now表示现在的日期，of用于年月日组成的日期（这里和英文中的of意义非常贴切），plus/minus加减等等；\n3.3 合理的接口设计  LocalDate表示日期，由年月日组成，提供了获取所在年，所在月，所在日的api，提供所在一年的第几天api，用于比较日期前后api，替换年份、月份、日的api，这些api使得日期或者日期时间的处理上得到的功能上的极大提升； 抽象出年、月、日、星期、日期、日期时间、瞬时、周期诸多接口，对事物本质有了细腻的抽象，并提供了相互转换的能力——提供极强的处理能力和语言表达能力； 对于遗留的日期时间库Calendar/Date/Timezone和新的日期时间库的互通性； 将全球的非标准日历系统单独抽象并支持扩展，从标准日历系统中隔离（符合设计原则：对修改关闭，对扩展开放）  4 java.time使用示例 得益于新日期时间框架的设计，无论是类名还是方法名以及可读性，都相当容易理解，其上手成本比Date/Calendar要低得多。\n并且，LocalDateTime/LocalDate之间，以及它们和jdk 1.8之前的Date也可以互相转换。\n以下是一个使用示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154  public class Intro { static String yyyy = \u0026#34;yyyy\u0026#34;; static String yyyy_MM = \u0026#34;yyy-MM\u0026#34;; static String yyyy_MM_dd = \u0026#34;yyyy-MM-dd\u0026#34;; static String yyyy_MM_dd_HH_mm_ss = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;; static String yyyy_MM_dd_HH_mm_ss_SSS = \u0026#34;yyyy-MM-dd HH:mm:ss.SSS\u0026#34;; /** * If the pattern like \u0026#39;yyyy\u0026#39;, result {@link LocalDateTime} could be like \u0026#39;yyyy-01-01 00:00:00\u0026#39;.\u0026lt;br\u0026gt; * If the pattern like \u0026#39;yyyy-MM\u0026#39;, result {@link LocalDateTime} could be like \u0026#39;yyyy-MM-01 00:00:00\u0026#39;.\u0026lt;br\u0026gt; * If the pattern like \u0026#39;yyyy-MM-dd\u0026#39;, result {@link LocalDateTime} could be like \u0026#39;yyyy-MM-dd 00:00:00\u0026#39;.\u0026lt;br\u0026gt; * Other patterns acts the same. * \u0026lt;p\u0026gt; * * \u0026lt;b\u0026gt;Important:\u0026lt;/b\u0026gt; the pattern and the the {@link LocalDateTime#parse(CharSequence, DateTimeFormatter)} method\u0026#39;s input {@link CharSequence} must match. * e.g. The following method call will throw {@link java.time.format.DateTimeParseException}: * \u0026lt;pre\u0026gt; * LocalDateTime localDateTime = LocalDateTime.parse(\u0026#34;2021\u0026#34;,dtfBuilder(\u0026#34;yyyy-MM\u0026#34;)); * \u0026lt;/pre\u0026gt; * * @param pattern the string pattern * @see DateTimeFormatter javadoc * @see LocalDateTime#parse(CharSequence, DateTimeFormatter) */ static DateTimeFormatter dtfBuilder(String pattern) { return new DateTimeFormatterBuilder() .appendPattern(pattern) .parseDefaulting(ChronoField.YEAR_OF_ERA, LocalDateTime.now().getYear()) .parseDefaulting(ChronoField.MONTH_OF_YEAR, 1) .parseDefaulting(ChronoField.DAY_OF_MONTH, 1) .parseDefaulting(ChronoField.HOUR_OF_DAY, 0) .parseDefaulting(ChronoField.MINUTE_OF_HOUR, 0) .parseDefaulting(ChronoField.SECOND_OF_MINUTE, 0) .parseDefaulting(ChronoField.NANO_OF_SECOND, 0) .toFormatter(); } static SimpleDateFormat sdfBuilder(String pattern) { return new SimpleDateFormat(pattern); } /** * solution1: * Get yyyy-MM-dd 00:00:00, start of the day.\u0026lt;br\u0026gt; * If you use yyyy-MM-dd as parameter */ static Date getStartOfDay() { LocalDateTime localDateTime = LocalDateTime.parse(\u0026#34;2021-02-02\u0026#34;, dtfBuilder(yyyy_MM_dd)); Instant instant = localDateTime.atZone(ZoneId.systemDefault()).toInstant(); return Date.from(instant); } /** * solution2: * get yyyy-MM-dd 00:00:00, start of the day.\u0026lt;br\u0026gt; * If you use yyyy-MM-dd as parameter\u0026lt;br\u0026gt; * \u0026lt;p\u0026gt; * Using {@link LocalDate#atStartOfDay()} * * @param dateString datePattern like 2012-09-08 */ static Date getStartOfDay(String dateString) throws ParseException { //由于dtfBuilder的设置 这里的时间已经是 00:00:00  LocalDate localDate = LocalDate.parse(dateString, dtfBuilder(yyyy_MM_dd)); ZonedDateTime zonedDateTime = localDate.atStartOfDay(ZoneId.systemDefault()); return Date.from(zonedDateTime.toInstant()); // return sdfBuilder().parse(zonedDateTime.format(dtfBuilder(yyyy_MM_dd_HH_mm_ss)));  } /** * */ static Date getStartOfDay(LocalDate localDate){ ZonedDateTime zonedDateTime = localDate.atStartOfDay(ZoneId.systemDefault()); LocalDateTime localDateTime = localDate.atStartOfDay(); Instant instant = localDateTime.toInstant(ZoneOffset.of(\u0026#34;+8\u0026#34;)); // return Date.from(zonedDateTime.toInstant());  return Date.from(instant); } /** * Get yyyy-MM-dd 23:59:59.999, end of the day.\u0026lt;br\u0026gt; * By using {@link LocalDateTime#plus(long, TemporalUnit)} */ static Date getEndOfDay() { //由于dtfBuilder的设置 这里的时间已经是 00:00:00  LocalDateTime localDateTime = LocalDateTime.parse(\u0026#34;2020-12-21\u0026#34;, dtfBuilder(yyyy_MM_dd)); //plusXxx()方法没有提供毫秒/微秒的相应方法，直接到纳秒； 相应的，可以使用plus方法指定单位  localDateTime = localDateTime.plusHours(23).plusMinutes(59).plusSeconds(59).plusNanos(999_999_999); /* * 好方法，将其下级单位的值清零 * ChronoUnit.DAYS: 清零hh:mm:ss.SSS * 最大单位 DAYS，也就是说此方法只能用来清零时间 */ localDateTime = localDateTime.truncatedTo(ChronoUnit.DAYS); localDateTime = localDateTime .plus(23, ChronoUnit.HOURS) .plus(59, ChronoUnit.MINUTES) .plus(59, ChronoUnit.SECONDS) .plus(999, ChronoUnit.MILLIS); return Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); } /** * Get yyyy-MM-dd 23:59:59.999, end of the day.\u0026lt;br\u0026gt; * By using {@link LocalDate#atTime(LocalTime)} * * @param dateString date pattern like \u0026#39;2012-09-18\u0026#39; */ static Date getEndOfDay(String dateString) { LocalDate localDate = LocalDate.parse(dateString, dtfBuilder(yyyy_MM_dd)); // localDate.  LocalDateTime localDateTime = localDate.atTime(23, 59, 59, 999_999_999); return Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); } /** * Get first day of month * * @param dateString pattern like \u0026#39;2020-10-25\u0026#39; * @return */ static Date getFirstDayOfMonth(String dateString) { LocalDateTime localDateTime = LocalDateTime.parse(dateString, dtfBuilder(yyyy_MM_dd)); localDateTime = localDateTime.withDayOfMonth(1); return Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); } /** * Get the first day of year. * * @param yearString pattern like \u0026#39;2012\u0026#39; */ static Date getFirstDayOfYear(String yearString) { LocalDateTime localDateTime = LocalDateTime.parse(yearString, dtfBuilder(yyyy)); return Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); } public static void main(String[] args) throws ParseException { System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss).format(getStartOfDay())); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss).format(getStartOfDay(\u0026#34;2021-02-02\u0026#34;))); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss_SSS).format(getStartOfDay(LocalDate.parse(\u0026#34;2021-02-22\u0026#34;, dtfBuilder(yyyy_MM_dd))))); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss_SSS).format(getEndOfDay())); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss_SSS).format(getEndOfDay(\u0026#34;2020-12-21\u0026#34;))); System.out.println(sdfBuilder(yyyy_MM_dd).format(getFirstDayOfMonth(\u0026#34;2020-12-18\u0026#34;))); System.out.println(sdfBuilder(yyyy_MM_dd_HH_mm_ss).format(getFirstDayOfYear(\u0026#34;2012\u0026#34;))); } }   源码地址：https://github.com/wangy325/java-review/blob/master/src/main/java/com/wangy/common/time/Intro.java\n5 补充内容 5.1 时区 时区是地球上的区域使用同一个时间定义。以前，人们通过观察太阳的位置（时角）决定时间，这就使得不同经度的地方的时间有所不同（地方时）。1863年，首次使用时区的概念。时区通过设立一个区域的标准时间部分地解决了这个问题。\n世界各个国家位于地球不同位置上，因此不同国家，特别是东西跨度大的国家日出、日落时间必定有所偏差。这些偏差就是所谓的时差。\n理论时区以被15整除的子午线为中心，向东西两侧延伸7.5度，即每15°划分一个时区，这是理论时区。理论时区的时间采用其中央经线（或标准经线）的地方时。所以每差一个时区，区时相差一个小时，相差多少个时区，就相差多少个小时。东边的时区时间比西边的时区时间早。为了避免日期的紊乱，提出国际日期变更线的概念\n但是，为了避开国界线，有的时区的形状并不规则，而且比较大的国家以国家内部行政分界线为时区界线，这是实际时区，即法定时区。请参见时区列表。\n5.2 子午线 即经线，和纬线一样是人类为度量而假设出来的辅助线，定义为地球表面连接南北两极的大圆线上的半圆弧。任两根经线的长度相等，相交于南北两极点。每一根经线都有其相对应的数值，称为经度。经线指示南北方向。\n5.3 本初子午线 即0度经线，亦称格林尼治子午线或本初经线，是经过英国格林尼治天文台的一条经线（亦称子午线）。本初子午线的东西两边分别定为东经和西经，于180度相遇。\n5.4 国际标准ISO 8601 国际标准ISO 8601：是国际标准化组织的日期和时间的表示方法，全称为《数据存储和交换形式·信息交换·日期和时间的表示方法》。目前是2004年12月1日发行的第三版“ISO8601:2004”以替代1998年的第一版“ISO8601:1988”与2000年的第二版“ISO8601:2000”。\n年由4位数字组成YYYY，或者带正负号的四或五位数字表示±YYYYY。以公历公元1年为0001年，以公元前1年为0000年，公元前2年为-0001年，其他以此类推。应用其他纪年法要换算成公历，但如果发送和接受信息的双方有共同一致同意的其他纪年法，可以自行应用。\n5.5 协调世界时  英语：Coordinated Universal Time，\n法语：Temps Universel Coordonné，简称UTC\n 是最主要的世界时间标准，其以原子时秒长为基础，在时刻上尽量接近于格林尼治标准时间。中华民国采用CNS 7648的《资料元及交换格式–资讯交换–日期及时间的表示法》（与ISO 8601类似）称之为世界协调时间。中华人民共和国采用ISO 8601:2000的国家标准GB/T 7408-2005《数据元和交换格式 信息交换 日期和时间表示法》中亦称之为协调世界时。\n协调世界时是世界上调节时钟和时间的主要时间标准，它与0度经线的平太阳时相差不超过1秒，并不遵守夏令时。协调世界时是最接近格林威治标准时间（GMT）的几个替代时间系统之一。对于大多数用途来说，UTC时间被认为能与GMT时间互换，但GMT时间已不再被科学界所确定。\n如果时间是以协调世界时（UTC）表示，则在时间后面直接加上一个“Z”（不加空格）。“Z”是协调世界时中0时区的标志。因此，“09:30 UTC”就写作“09:30Z”或是“0930Z”。“14:45:15 UTC”则为“14:45:15Z”或“144515Z”。\n5.6 UTC偏移量 UTC偏移量用以下形式表示：±[hh]:[mm]、±[hh][mm]、或者±[hh]。如果所在区时比协调世界时早1个小时（例如柏林冬季时间），那么时区标识应为“+01:00”、“+0100”或者直接写作“+01”。这也同上面的“Z”一样直接加在时间后面。\n\u0026ldquo;UTC+8\u0026quot;表示当协调世界时（UTC）时间为凌晨2点的时候，当地的时间为2+8点，即早上10点。\n5.7 格林尼治平时  英语：Greenwich Mean Time，GMT）\n 是指位于英国伦敦郊区的皇家格林尼治天文台当地的平太阳时，因为本初子午线被定义为通过那里的经线。\n自1924年2月5日开始，格林尼治天文台负责每隔一小时向全世界发放调时信息。\n格林尼治平时的正午是指当平太阳横穿格林尼治子午线时（也就是在格林尼治上空最高点时）的时间。由于地球每天的自转是有些不规则的，而且正在缓慢减速，因此格林尼治平时基于天文观测本身的缺陷，已经被原子钟报时的协调世界时（UTC）所取代。\n6 参考  原文地址：https://www.cnblogs.com/lxyit/p/9442135.html is-java-util-calendar-thread-safe-or-not：https://www.stackoverflow.com/questions/12131324/is-java-util-calendar-thread-safe-or-not 如何使用1： https://www.jianshu.com/p/19bd58b30660 如何使用2：https://www.github.com/wangy325/java-review/blob/master/src/main/java/com/wangy/common/time/Intro.java exceptions-may-occure：https://www.stackoverflow.com/questions/27454025/unable-to-obtain-localdatetime-from-temporalaccessor-when-parsing-localdatetime JSR 310：https://www.jcp.org/aboutJava/communityprocess/pfd/jsr310/JSR-310-guide.html 时区：https://www.zh.wikipedia.org/wiki/%E6%97%B6%E5%8C%BA 时区列表：https://www.zh.wikipedia.org/wiki/%E6%97%B6%E5%8C%BA%E5%88%97%E8%A1%A8#UTC%EF%BC%88WET_-%E6%AD%90%E6%B4%B2%E8%A5%BF%E9%83%A8%E6%99%82%E5%8D%80%EF%BC%8CGMT-_%E6%A0%BC%E6%9E%97%E5%A8%81%E6%B2%BB%E6%A0%87%E5%87%86%E6%97%B6%E9%97%B4%EF%BC%89 经线：https://www.zh.wikipedia.org/wiki/%E7%BB%8F%E7%BA%BF ISO 8601：https://www.zh.wikipedia.org/wiki/ISO_8601 UTC：https://www.zh.wikipedia.org/wiki/%E5%8D%8F%E8%B0%83%E4%B8%96%E7%95%8C%E6%97%B6 GMT：https://www.zh.wikipedia.org/wiki/%E6%A0%BC%E6%9E%97%E5%B0%BC%E6%B2%BB%E6%A8%99%E6%BA%96%E6%99%82%E9%96%93 ","description":"本文介绍了Java8中新增的java.util.time包及其中的实用组件，其API在设计上的易用性以及易理解性都优于之前的java.util.Date，java.util.calendar 类，并且能够和它们进行互相转换。","id":8,"section":"posts","tags":["DateTime"],"title":"Java8中的新日期和时间工具库","uri":"http://wangy325.top/zh/posts/java/basic/java-new-time-api/"},{"content":"本文介绍在如何在xxl-job中使用创建并使用分片任务。\nxxl-job是国内开发者提供的一款轻量级分布式任务调度平台，开发者是大众点评的工程师，其目前维护一个开源社区，里面还有很多已经发布或尚在孵化的开源项目。\n任务分片是一个以空间换时间的概念，旨在将耗时任务进行拆分，然后同时执行，拆分之后执行的结果对任务任务原来不分片执行的结果没有影响。\n 比如要核对id从1-1000的用户的邮箱信息，找出无效的邮箱信息。可以将id分成合适的多小段，1-100，101-200，\u0026hellip;，901-1000，然后交给不同的任务去执行。这就是任务分片的简单模型。\n 在阅读此文之前，需要理解xxl-job的基本模型与工作流程，其核心概念有2:\n  调度中心\n负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码。调度系统与任务解耦，提高了系统可用性和稳定性，同时调度系统性能不再受限于任务模块；\n支持可视化、简单且动态的管理调度信息，包括任务新建，更新，删除，GLUE开发和任务报警等，所有上述操作都会实时生效，同时支持监控调度结果以及执行日志，支持执行器Failover。\n  执行器\n负责接收调度请求并执行任务逻辑。任务模块专注于任务的执行等操作，开发和维护更加简单和高效；接收“调度中心”的执行请求、终止请求和日志请求等。\n  调度中心自动发现并注册执行器，并且通过执行器提供的api对任务进行调度（执行/终止等操作）。\n本文测试所使用的xxl-job所有模块基于最新的迭代版本v2.3.0，此次迭代中配置分片任务的方式与之前版本有些许不同：\n   【新增】新增任务辅助工具 XxlJobHelper：提供统一任务辅助能力，包括：任务上下文信息维护获取（任务参数、任务ID、分片参数）、日志输出、任务结果设置……等； ShardingUtil 组件废弃：改用 XxlJobHelper.getShardIndex()/getShardTotal(); 获取分片参数； XxlJobLogger 组件废弃：改用 XxlJobHelper.log 进行日志输出；  其他更新日志可以查看该版本的RELEASE NOTE\n在xxl-job中，可以通过两种方式实现分片任务：\n 单实例多任务执行分片，等效于前文中的例子，将一个大任务拆分成多个小任务； 多实例单任务执行分片，将任务按照一定的方式分配到多个实例上去运行——以多个实例上配置相同的任务为前提；  模拟需要完成的工作 在开始之前，我们先模拟需要完成的工作：有100个账户，每个账户有随机1-10条数据需要处理。代码片段如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  private final static Random RAND = new Random(47); /** * 100 ids */ private static final List\u0026lt;Integer\u0026gt; CITY_ID_LIST = new ArrayList\u0026lt;Integer\u0026gt;() {{ for (int i = 1; i \u0026lt;= 100; i++) { add(i); } }}; /** * task num for each id */ private static int task_num_per_id; /** * 任务数据库 */ private static final Map\u0026lt;Integer, List\u0026lt;String\u0026gt;\u0026gt; TASKS; static { TASKS = new HashMap\u0026lt;\u0026gt;(); CITY_ID_LIST.forEach(city -\u0026gt; { task_num_per_id = RAND.nextInt(10); List\u0026lt;String\u0026gt; cityTasks = new ArrayList\u0026lt;\u0026gt;(task_num_per_id); IntStream.rangeClosed(1, task_num_per_id).forEach(index -\u0026gt; { String orderInfo = city + \u0026#34;------NO.\u0026#34; + index; cityTasks.add(orderInfo); }); TASKS.put(city, cityTasks); }); }   单实例多任务分片 当使用单执行器实例时，我们可以在调度中心创建多个任务，通过分配不同的任务参数来实现任务的分片。任务的实现代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  @XxlJob(\u0026#34;singleExecutorMultiThreads\u0026#34;) public void singleExecutorMultiThreadsCityJob() throws Exception { // 当不配置参数时，此方法返回空字符串\u0026#34;\u0026#34;  String shards = XxlJobContext.getXxlJobContext().getJobParam(); XxlJobHelper.log(\u0026#34;XXL-JOB, 单机分片任务开始. 分片参数：{}\u0026#34;, shards); if (StringUtils.isEmpty(shards)) { // XxlJobHelper.handleFail(\u0026#34;任务参数不能为空！\u0026#34;);  // 不分片，全量执行  IntStream.range(0, CITY_ID_LIST.size()) .forEach(i -\u0026gt; { int cityId = CITY_ID_LIST.get(i); List\u0026lt;String\u0026gt; task = TASKS.get(cityId); task.forEach(t -\u0026gt; XxlJobHelper.log(\u0026#34;【{}】执行【{}】，任务内容为：{}\u0026#34;, Thread.currentThread().getName(), cityId, t)); }); } else { // 分片执行  Arrays.stream(shards.split(\u0026#34;,\u0026#34;)) .map(String::trim) .filter(StringUtils::isNotBlank) .map(Integer::parseInt) .forEach(cityId -\u0026gt; { List\u0026lt;String\u0026gt; task = TASKS.get(cityId); Optional.ofNullable(task).ifPresent(todoTasks -\u0026gt; { todoTasks.forEach(t -\u0026gt; XxlJobHelper.log(\u0026#34;【{}】执行【{}】，任务内容为：{}\u0026#34;, Thread.currentThread().getName(), cityId, t)); }); }); } }   在调度中心，我们可以像这样创建分片任务：\n可以根据情况创建任务数，来进行单实例复杂任务的分片。\n配置完成后的任务列表看起来像这样：\n这2个任务使用不同的任务参数，其他配置可以大体相同甚至完全一致。\n这里需要说明的是，当前版本对于任务参数的处理做了修改，JobHandler中的方法不再直接直接调用含有参数的任务方法，而是通过XxlJobContext.getXxlJobContext().getJobParam()直接在任务中获取分片参数。\n配置完成之后，我们执行任务，即可以看到调度日志（部分）：\n可以看到，执行器开启了不同的线程分别执行分片任务，这样可以节省任务执行的时间开销。\n这就是xxl-job的单实例分片任务创建方法。\n需要说明的是，上面的任务如果不设置分片参数，那么将会执行全部的任务。\n多实例分片广播 在多执行器实例的情况下，分片任务有多种路由策略，此处暂且不讨论路由策略，在分片广播的模式下进行测试。分片任务的实现代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @XxlJob(\u0026#34;multiExecutorsSharding\u0026#34;) public void multiExecutorShardingCityJob() throws Exception { XxlJobHelper.log(\u0026#34;XXL-JOB, 多实例分片任务开始.\u0026#34;); int shardIndex = XxlJobHelper.getShardIndex(); int shardTotal = XxlJobHelper.getShardTotal(); IntStream.range(0, CITY_ID_LIST.size()).forEach(i -\u0026gt; { if (i % shardTotal == shardIndex) { int cityId = CITY_ID_LIST.get(i); List\u0026lt;String\u0026gt; task = TASKS.get(cityId); Optional.ofNullable(task).ifPresent(todoTasks -\u0026gt; { todoTasks.forEach(t -\u0026gt; XxlJobHelper.log(\u0026#34;实例【{}】执行【{}】，任务内容为：{}\u0026#34;, shardIndex, cityId, t)); }); } }); }   可以看到，实际上是通过对所有执行器实例id取模的方式，将任务均匀地分配到所有的执行器上去执行。\n调度中心创建任务像这样：\n在这个模式下，任务并没有设置分片参数，不过我们需要额外启动一个执行器实例：\njava -jar -Dserver.port=8082 -Dxxl.job.executor.port=9998 xxl-job-executor-sample-springboot-2.3.0-SNAPSHOT.jar 上述指定的端口需要和之前的实例不同即可。\n运行任务成功之后，我们可以看到调度日志（部分）：\n从日志可以看出，任务被规律地分配到了2个执行器实例上。\n参考  XXL-JOB任务分片-伊布拉西莫-csdn ","description":"","id":9,"section":"posts","tags":["任务调度"],"title":"在xxl-job中使用分片任务","uri":"http://wangy325.top/zh/posts/java/job/xxl-sharding-job/"},{"content":"2020，我，作为一个处于危机边缘而不自觉的人，果不其然地，陷入了失业的漩涡。这不是“主动离职”4个字就能概括的一年，里面包含了太多的曲折与困难。\n转行3年，或许我还没有摸清行业的门道，还没有清楚地知道我自己究竟需要的是什么，希望从事的工作是什么？常常戏谑地说，都是为钱过活，但是最初的愿景是切实的打好技术基础，钱是水到渠成的事情。就是这样的一个简单的愿景，一直在被现实干扰，当然，这种干扰是无法规避的，除非我到了另一个次元。所以，生活在世，有些固有的坚持是必要的，不然轻易被现实洪流冲乱了方向。\n说实话，在“愤而离职”之前，我从没有想过，能有如此之长（10个月）的真空期，这自然是偏离计划之外的事情。面试时被问及为何如此，总是苦笑的说“那时冲动”之类的话语，当然，这是坦诚的回答，同时也是敷衍的回答。现在回想起来，还是高估了自己的能力，低估了市场的残酷。\n经历了段不长的转行工作经历之后，自然地意识到Java系统的庞大与自身积累的局限，更重要的是学习的速度跟不上技术的发展。纵使接触一些新的技术，凭浅薄的原始积累，也仅仅凭记忆记住「有这个技术」罢了，谈原理与机制就是妄想了。这是最初离职的缘由——希望花点时间整理知识体系。当然，现阶段说体系这个词，尚有些浮夸，还是搭建基础知识框架的阶段。基础不行，接触再多的技术，那都是空中楼阁，一段时间不用，再捡起来，就得重新开始了，我是这么认为的。\n既然如此，还是从源头Java开始，毕竟短浅的年限，Java语言的高级特性还是一知半解，这是迫切需要解决的问题。正是因为有了这个觉悟，这篇总结能够规整地呈现在页面，而不是散落在硬盘的角落或者在某个笔记APP的文件夹里。我希望借助一个静态博客托管工具来保存、记录技术的积累，于是找到了Hugo，一切就绪之后，就可以撸起袖子开始干了。\n这几年工作方面的问题，无论是bug的处理还是新技术的整合使用问题，大多是网络上搜集资料的多，记录的少，只汲取而不输出可不是什么好习惯，况且记录并解决问题也是学习的过程，几天的时间处理一个问题还是值得记录一笔的，这一想法由来已久，于是Hugo便成了理所应当之选择。\n另一方面，意识到知识的获取应始于书本而不是网络鱼龙混杂的博客，而各个博客平台的的技术文章比较杂乱，如果仅仅依赖于此，必然获取到的知识也是不纯粹的，所以还是需要自己动手，构建自己的记录。加之近来专业相关的书籍买了一堆，但是烦于处理工作事务而轻阅读，也是在疫情端口离职的缘由之一。\n基于上述种种，2020年初离职之后，便开始了自修之旅，此番过程以《Thinking In Java》和《Java核心技术卷·I》这2本书的内容纲要为主，打算重新拾取Java技术的盲区，或者说一些之前理解不够透彻、深入的内容，包括且不限于\n 抽象类，接口，工厂以及模版方法 内部类（重要的类组成成员） java8 的函数式接口，lambda表达式与方法引用 集合框架的深入理解（基于源码和JavaDoc） Java的反射与代理  同时，在最流行的Java开发框架Spring方面，以《Spring In Action》为主，从头开始领略了Spring容器在Java开发过程中的发挥，其中也接触到了3.0/4.0之后就有的一些特性与功能，包括但不限于：\n 基于Java Bean以及注解（去xml）的配置 基于@Profile的多环境配置 基于@Conditional的条件化注入 基于注解的的AOP配置 基于注解和JavaBean的WebMvc配置（完全取代mvc.xml和web.xml）  此外，在数据库与持久化方面，接触了Spring jdbc、Hibernate以及jpa，并使用H2内存数据库进行了集成测试，这里面涉及了完全在之前项目里面没有涉及（一直使用mybatis）的内容：\n spring jdbc提供了完全的持久化功能，JdbcTemplate使用方便，但是其基于原生SQL（尽管支持SQL构造器），代码不够优雅 Hibernate的持久化基于Java Bean（@Entity），并且支持多种查询方式  原生SQL HQL（Hibernate Query Language），代码简介于基于原生SQL CriteriaQuery的SQL语句与返回结果的拼装（去SQL）   javax.persistence-api提供了一整套联结JavaBean与数据层的注解（@Id，@Column，@ManyToOne，@OneToMany\u0026hellip;）  鉴于数据库开发工作限于在Mapper中编写简单的SQL，于是借助《MySQL必知必会》这本书对MySQL整体有了初略的了解。当然阅读本书并不能够将SQL编写能力提升一个档次，但是能够全局掌握SQL语法组成，这是至关重要的，以至于编写SQL时不至于胡乱拼凑。\n做完这些基础之后，已年中。彼时曾找过一段时间的工作，其中不乏长达2个小时的面试，结果自然是一无所获。这又回到了之前的表述：高估了自己的能力，低估了市场的残酷。\n当沉浸于昨日收获的一个知识点的时候，现实的当头一棒把人敲的昏沉。上述所列之内容，在技术官看来，不过是开发人员理所应当掌握的基础罢了，不值一提，确实如此。当我有理有据地说出希望公司加班强度不那么大，希望能留多时间继续延续这个看书（自修）的过程的时候，可能在面试官心里，就已经取消了你的录用资格。\n那时候，我内心埋藏的希望已经彻底破灭了。甚至一度对于自己的喜好产生了怀疑，找不到技术所向往从事的行业。我迷失了，我不再接收招聘信息，每日熬夜游戏、看剧。希望永远是黑夜，我一直可以睡觉而不必理会任何事物。\n直到我又重新拿起了《Thinking In Java》，翻到了从未深入理解的并发那几页，每日不断的看、写，从而内心又找到了一丝慰藉。并发这一块的内容是花费时间最长，可以说是线程的创建开始，重头仔细学习了一遍，时间花的越多，收获也就越多。当然，此期间也看了网络上一些优秀的关于并发的文章，以及阿里大佬关于并发的书《Java并发编程的艺术》，可以说是收获颇丰：\n 线程的状态及生命周期 资源的共享 线程的交互（sleep，wait，join），简单的无锁同步 同步关键字与临界区 死锁与解除死锁 锁与条件 获取任务的返回值（Callable/Future/FutureTask） 线程本地存储（ThreadLocal） 执行器与线程池 周期执行的任务（ScheduleThreadPool） 生产者-消费者与阻塞队列 并发组件（CountDownLatch/CycleBarrier/Exchanger/Semaphore） 线程安全的集合（CopyOnWriteList/ConcurrentHashMap/\u0026hellip;）  得益于这一番自修，使得自己博客的字数突破10w，Java并发的内容独占了7成！当然，这并不是并发框架的全部，甚至对有些内容的了解都尚粗浅，如果需要进一步，还需要多读读源码。\n并发的内容阅读记录下来，已经接近11月底了。还是计划在年底找一份工，年后好直接上岗。于是开始了第二次的求职尝试。像临考之前无心看书一样，临面试时也无心看书。不过此时心境有变，还是在Github上面找了一个很好的仓库，里面涵盖介绍了Java框架绝大部分内容。 在这个过程中，\n接触了几个比较重要的内容：\n JVM虚拟机内存模型与垃圾回收 数据库的事务基础 redis的内存淘汰机制与持久化方式  Java虚拟机的内存模型零零碎碎地看过多次，但是没有形成系统的印象，只知道几个零星的概念（堆、栈、程序计数器、常量池、本地方法栈等），虽然现在也不敢说每个内存区域储存的具体信息，但是大概知道了每个内存区域在的功能，也基本了解堆的内存分配，垃圾回收的的常用算法等等。当然，如想深入理解其中的机制与缘由，还需深读《深入理解Java虚拟机》，值得一提的是，《深入理解Java虚拟机》这本书是在研究并发内容【volatile关键字】的时候购买的。\n另外一个重要的点就是数据库事务这块内容（经常被问）。偶尔的灵光一闪，竟然领悟到事务是一个并发概念，而由于之前所了解的关于并发的内容，此时，了解并发相关的内容便是势在必行的了。于是参看了《高性能MySQL》的部分内容，了解了MySQL的存储引擎与事务相关的基础【并没有深入的去探究数据在MySQL的是怎么存储的】，此基础是为继续深入学习MySQL而打下的。\n关于缓存或者说NoSQL数据库这一块内容，受限于业务场景，个人使用偏多的是字符串和哈希，更侧重的是利用Java进行redis的整合，包括redis几种使用方式【单实例、哨兵、集群】的搭建，而少关注redis数据类型的实现以及其内部的优化机制，包括内存淘汰机制、防止redis穿透甚至redis的持久化这些内容都缺乏了解，这一次算是补充这些概念的短板，同MySQL一样，只是建立了知识模型，后续的深入理解，还需借助更加系统的书籍。\n10个月的空窗期，中间认认真真看书写博客的时间估计就有6个月左右。也只有些许知识的积累能够让内心稍感慰藉，不然容易陷入空虚谷，这是一方面，另一方面，正是由于长时间的自修，疲乏下来，效率自然下跌。其实总体回想起来，这几个月的时间，实际上产出效率并不算出色，甚至显得平庸了。不过，那些沉浸在源码里的夜晚，确实一定程度上，加深了对Java语言的理解，有点只可意会不可言传的感觉。\n值得一提的是华为的面试经历【OD】，面试的周期拖的挺长的，差不多20天了，机试题虽然简单，但是也不得不拿出来说一下。牛客网老早就是知道的一个在线题库，里面聚集了太多科班的技术同学，我作为半路出家的典型，其实去的少，颇有羞于踏足的意味。但是听闻华为的机试是牛客平台，还是得去准备一下。生手上来，直接遇到了几个算法题，缺乏基础的我虽然能解出其中一道两道，查看其他同学的题解，那么简洁、高级，我顿时自惭形秽。这也是情理之中的事情，没有处理特定问题的经验，不知道算法套路，自然是很难找到最优解的，如果我找到了，那我一定是天赋型选手了。所以，计划将牛客网刷题记录作为一个长期任务坚持下去，作为积累的一部分。其次说说华为最后一次的主管面，在我阐述了我的基本信息之后，主管也给出了一些指导性建议，是关于自修这条路行不行得通，能走到哪里，是否曲折的建议，也算是比较中肯的。首先，自学肯定是可以的，只要保持学习的态度和积极性。我也常常自省，或者说感叹，Java的领域太过于庞大了，里面所涉及的技术从项目的搭建、部署、运维、监控几个维度来看就已经够庞大了，其次在项目的搭建这一过程中，所涉及的细分面就广的难以技术了，任何业务需求都有多种可行性选择，正是这种灵活性，造就了Java体系的庞大。\n就是在初踏进Java的大门之后，接触到这个庞大的体系，有些迷茫而不知所措，有太多的东西要学而不知道该学哪个东西。其实，也不算迷茫，而是偏离了既定的方向，走了一些弯路，在一个分支上花费了一些时间。现在看来，应以Java为本体，毕竟Java的源码包，这段时间也就接触了一个juc而已！所有的那些Java所涉及的领域，其实都是从Java的能力发散开来的，简单的例子，没有javax.persistence，哪有什么hibernate啊！Java提供了上游技术【框架】的基础，学好Java再进行良好的知识发散，从事正确的途径。有些技术是Java无关性的，技术计算机网络，以及算法。\n所以接下来的任务就变得很明显了\n 还是应以Java为主，重点在I/O，JEE的Servlet Jvm辅助阅读 Spring【不急于SpringBoot和Cloud，spring framework才是基础】 算法入门 计算机网络  大部分的书籍实际上都是已经储备了的，无论是纸质版还是电子版，应该还是以阅读书籍为主。一件好笑的事情是，之前使用spring5整合swagger2的时候，发现swagger的页面总是无法访问，在csdn上折腾了2个晚上，结果使用google，只在starkflow上看了一篇文章，问题就解决了。\n","description":"","id":10,"section":"posts","tags":[""],"title":"2020年度总结","uri":"http://wangy325.top/zh/posts/z/annual-summary-2020/"},{"content":"这篇文章介绍了几种常见的使用printf()方法进行格式化输出的方法。\nprintf()方法隶属于java.io.PrintStream类，提供了和C语言中相似的格式化字符串输出的方法。\n1 语法 printf()有一些重载方法，可以用来格式化输出：\n1 2  System.out.printf(format, arguments); System.out.printf(locale, format, arguments);   format参数1用来指定格式化规则，一般以百分号%开头。\n在进一步剖析格式化规则之前，不妨看一个简单的例子：\n1  System.out.printf(\u0026#34;Hello %s!%n\u0026#34;, \u0026#34;World\u0026#34;);   上面的代码输出如下内容：\nHello World!  如上所示，格式化参数包含一个字符串（Hello）和2个格式化规则。第一个规则（%s）用来格式化字符串参数（World），第二个规则（%n）则表示在末尾添加一个换行符。\n1.1 格式化规则 格式化参数由纯字符串以及格式化标志符组成，其中格式化标志符包括标记（flags）、宽度、精度、转换字符组成：\n %[flags][width][.precision]conversion-character\n Specifiers in the brackets are optional.\n方括号内的标识符是可选的。\n实际上，printf()使用 java.util.Formatter类来转换格式字符串并进行输出。完整的格式化选项可以从Formatter的 Javadoc中获取。\n1.2 转换字符 The conversion-character is required and determines how the argument is formatted. Conversion characters are only valid for certain data types. Some common ones are:\n转换字符是必须的，其决定如何格式化传入的字符串参数。转换字符对应指定的数据类型，一些常见的转换字符有：\n s – 用来格式化字符串 d –用来格式化小数 f – 用来格式化浮点数 t– 用来格式化日期/时间类型  下文会详细解释这些和一些其他转换字符。\n2.3 可选修饰符 The [flags] define standard ways to modify the output and are most common for formatting integers and floating point numbers.\n[flags]定义了修改输出的标准方法，是用来格式化整数和浮点数的最常用方法。\nThe [width] specifies the field width for outputting the argument. It represents the minimum number of characters written to the output.\n[width]约定了输出参数的宽度（占位），它约定的是输出的最小字符数。\nThe [.precision] specifies the number of digits of precision when outputting floating-point values. Additionally, we can use it to define the length of a substring to extract from a String.\n[.precision]约定了浮点数的数据精度，此外，还可以通过其来约定格式化时字符串的长度。\n2 换行符 使用%n来将字符串换行：\n1  System.out.printf(\u0026#34;baeldung%nline%nterminator\u0026#34;);   上述代码的输出像这样：\nbaeldung line terminator  printf()方法中的%n会自动插入当前系统中的换行符2。\n3 布尔值的格式化 printf()使用%b来格式化布尔值，当传入的值（？）是true，其输出true，否则输出false。\n参考下例：\n1 2 3 4  System.out.printf(\u0026#34;%b%n\u0026#34;, null); System.out.printf(\u0026#34;%B%n\u0026#34;, false); System.out.printf(\u0026#34;%B%n\u0026#34;, 5.3); System.out.printf(\u0026#34;%b%n\u0026#34;, \u0026#34;random text\u0026#34;);   上面的输出为：\nfalse FALSE TRUE true  可以%B来使printf输出大写。\n4 字符串格式化 printf()使用%s来格式化字符串。同样地，%S用于输出大写。\n如代码\n1 2  printf(\u0026#34;\u0026#39;%s\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;); printf(\u0026#34;\u0026#39;%S\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;);   输出:\n'baeldung' 'BAELDUNG'  前文提过，可以使用[width]来约定字符串的最小长度：\n1 2  printf(\u0026#34;\u0026#39;%15s\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;); printf(\u0026#34;\u0026#39;%1s\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;);   输出为:\n' baeldung' 'baeldung'  从输出可知，默认格式为右对其，并且当字符串长度大于约定的最小长度时，witdh配置无效。\n如果想使输出左对其，可以添加-标记（flags）\n如\n1  printf(\u0026#34;\u0026#39;%-10s\u0026#39; %n\u0026#34;, \u0026#34;baeldung\u0026#34;);   将输出:\n'baeldung '  此外，可以通过[.precision]控制输出字符串的字符数：\n1 2 3  System.out.printf(\u0026#34;%2.2s\u0026#34;, \u0026#34;Hi there!\u0026#34;); System.out.printf(\u0026#34;%10.2s\u0026#34;, \u0026#34;Hi there!\u0026#34;); System.out.printf(\u0026#34;%1.2s\u0026#34;, \u0026#34;Hi there!\u0026#34;);   %x.ys 格式中的\u0026rsquo;x\u0026rsquo;代表width，\u0026lsquo;y\u0026rsquo;代表precision。\n所以，上例中的输出为：\nHi Hi Hi  可以看到，precision参数控制着输出字符的个数。\n5 字符格式化 The result of %c is a Unicode character:\nprintf()使用%c来格式化Unicode字符。同样地，%C用于输出大写。\n1 2  System.out.printf(\u0026#34;%c%n\u0026#34;, \u0026#39;s\u0026#39;); System.out.printf(\u0026#34;%C%n\u0026#34;, \u0026#39;s\u0026#39;);   输出:\ns S  值得一提的是，如果传入无效参数，将会抛出IllegalFormatConversionException。\n6 数字格式化 6.1 整数格式化 printf() 方法使用%d来格式化整型，其接受所有Java语言的整数： byte、short、 int、 long以及BigInteger。\n1  System.out.printf(\u0026#34;simple integer: %d%n\u0026#34;, 10000L);   在\u0026rsquo;d\u0026rsquo;的作用下，上例的输出为：\nsimple integer: 10000  有时候，可能需要千位分隔符来使较大的数据更易读，可以使用,标记。并且可以根据不同地区的使用规范来使用不同的分隔符：\n1 2  System.out.printf(Locale.US, \u0026#34;%,d %n\u0026#34;, 10000); System.out.printf(Locale.ITALY, \u0026#34;%,d %n\u0026#34;, 10000);   如我们所见，美国和印度锁使用的千位分隔符是不同的：\n10,000 10.000  6.2 浮点数和双精度浮点数格式化 使用 %f 来格式化浮点数:\n1  System.out.printf(\u0026#34;%f%n\u0026#34;, 5.1473);   输出:\n5.147300  看到这个输出，我们首先想到的就是控制精度：\n1  System.out.printf(\u0026#34;\u0026#39;%5.2f\u0026#39;%n\u0026#34;, 5.1473);   上例中，我们约定了数字占用字符宽度[width]为5，小数部分的长度[.precision]为2:\n' 5.15'  可以看到，输出的数字开头存在1个字符的空白填充——由于约定的宽度为5。\n此外，为了获取科学计数法输出，只需要使用%e转换字符即可：\n1  System.out.printf(\u0026#34;\u0026#39;%5.2e\u0026#39;%n\u0026#34;, 5.1473);   将输出：\n'5.15e+00'  7 日期和时间格式化 至于日期和时间的格式化，需要使用t或T加上一些特殊含义的后缀组合。下面的示例中展示了一些常用的日期时间格式化的后缀字符。\n实际上，Java8提供了更加完整易用的 DateTimeFormatter来进行日期时间的格式化3。\n7.1 时间格式化 首先介绍关于常用时间格式化的后缀字符及其含义：\n H, M, S – 时/分/秒 L, N – 毫秒/纳秒 p – 上午/下午（am/pm） z – 时区  接下来，试试格式化输出日期：\n1 2  Date date = new Date(); System.out.printf(\u0026#34;%tT%n\u0026#34;, date);   \u0026lsquo;%tT\u0026rsquo; 格式输出如下所示：\n13:51:15  如果需要更详细的输出，不妨看看使用上面的后缀字符：\n1  System.out.printf(\u0026#34;hours %tH: minutes %tM: seconds %tS%n\u0026#34;, date, date, date);   通过使用‘H’，‘M’，‘S’，得到如下输出：\nhours 13: minutes 51: seconds 15  你肯定会觉得要获取一个时间单位，就要传入一个date实例很麻烦，Java的设计者也是这么认为，所以，可以通过使用参数索引字符1$来规避掉需要重复传递的参数：\n1  System.out.printf(\u0026#34;%1$tH:%1$tM:%1$tS %1$tp %1$tL %1$tN %1$tz %n\u0026#34;, date);   看，借助1$，传入一个date实例就获取了所有的信息：\n13:51:15 pm 061 061000000 +0400  7.2 日期格式化 和时间格式化类似，日期格式化也有特定的字符后缀：\n A – 输出星期全名 d – 输出2位数的日期 B – 输出完整的月份名称 m – 输出2位数的月份 Y – 输出4位数的年份 y – 输出2位数的年份  如果我们想打印星期，可以这样做：\n1  System.out.printf(\u0026#34;%1$tA, %1$tB %1$tY %n\u0026#34;, date);   输出：\nThursday, November 2018  也可以获得数字形式的输出：\n1  System.out.printf(\u0026#34;%1$td.%1$tm.%1$ty %n\u0026#34;, date);   输出：\n22.11.18  8 总结 此文讨论了printf()的常见用法，介绍了使用printf()对常见数据类型进行格式化输出的方法。\n 原文地址 Formatting with printf() in Java   下文统称为格式化参数，其本身也是一个字符串。 \u0026#x21a9;\u0026#xfe0e;\n windows系统的默认换行符为'\\r\\n'（回车换行），linux/unix下为'\\n'。 \u0026#x21a9;\u0026#xfe0e;\n 关于Java8的新日期时间库，也可以参考这篇文章 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"","id":11,"section":"posts","tags":[""],"title":"使用printf格式化输出","uri":"http://wangy325.top/zh/posts/java/trans/how2use-printf/"},{"content":"背包问题其实属于动态规划（ Dynamic Programming ）问题的一种。动态规划的手段是将大问题拆解为多个小问题，小问题解决之后，大问题也就随之而解。\n背包问题的典型描述是：\n 给定n种物品和一背包。物品 i 的重量似乎 wi，其价值为 vi，背包的容量为 c。问应该如何选择装入背包中的物品，\n使得装入背包中物品的总价值最大？\n 引例 为了阐述问题方便，引用算法图解一书中关于此书的图解好了(没有比这更好的解释方法了)。首先引入问题：\n 假设你是一个小偷，有一个可以装下4磅东西的背包，你可以偷窃的商品有:\n  4磅的音响，价值3000 3磅的笔记本电脑，价值2000 1磅的吉他，价值1500  当然，这个问题很简单，就算是遍历所有的可能性，也不过8种而已($2^3$)，不过当商品的数量增加时，可能性是指数式增长的，所以这种计算方式的运算时间复杂度是$O(2^n)$。现在尝试使用动态规划的方法来解决问题。\n动态规划算法从一个网格开始，如下表的空白部分表示了示例问题中需要填充的表格：\n   重量 价值 商品 \\ 背包重量 1 2 3 4     4 3000 音响       3 2000 笔记本电脑       1 1500 吉他        比如音响行第1列表示重量为1的背包装入音响所能获取的最大价值，笔记本电脑行第2列的表示重量为2的背包装入音响和笔记本电脑所能获取的最大价值\u0026hellip;以此类推。现在我们尝试填充此表格，按照行的顺序\n  音响行\n根据音响的重量，我们很容易就知道，重量为1、2、3的背包无法装下音响，当背包重量为4时，可以装下音响，此时的价值是3000，所以音响行填充完毕后，表格应该长这样：\n   重量 价值 商品 \\ 背包重量 1 2 3 4     4 3000 音响 0 0 0 3000   3 2000 笔记本电脑       1 1500 吉他          笔记本电脑行\n接下来继续填充笔记本电脑行，记住，此时背包可以选择的物品有音响和笔记本电脑2种。\n 当背包重量为1、2时，装不下笔记本电脑和音响中的任意一件商品，最大价值为0； 当背包重量为3时，不放入笔记本电脑时的最大价值为0（上一行已经计算得知），当放入笔记本电脑时，获得笔记本的电脑的价值2000，其剩余重量为0，无法装入音响；2000\u0026gt;0，因此背包重量为3时获得的最大价值就是2000； 当背包重量为4时，不放入笔记本电脑获得的最大价值是3000，当放入笔记本电脑时，获得笔记本的电脑的价值2000，其剩余重量为1，由音响行的计算结果可知，当背包重量为1时获得的最大价值是0（音响行第一列的值）；3000\u0026gt;2000+0，因此背包重量为3时获得的最大价值就是3000；  所以填充第二行之后的表格长这样：\n   重量 价值 商品 \\ 背包重量 1 2 3 4     4 3000 音响 0 0 0 3000   3 2000 笔记本电脑 0 0 2000 3000   1 1500 吉他          吉他行\n接下来填充吉他行，此时，背包可以选择的物品有音响、笔记本电脑和吉他3种。\n 当背包重量为1时，恰好可以装入吉他，因此其获得的最大价值就是1500； 当背包重量为2时，不放入吉他所能获得的最大价值是0，装入吉他之后，其获得价值1500；剩余重量为1，装入笔记本电脑和音响的最大价值就是0（笔记本电脑行的第1列）；因此最大价值是1500； 当背包重量为3时，不放入吉他所能获得的最大价值是2000，装入吉他之后获得价值1500，剩余重量为2，装入笔记本电脑和音响所能获取的最大价值是0（笔记本电脑行的第2列）；因此最大价值是2000； 当背包重量为4时，不放入吉他所能获取的最大价值是3000，装入吉他之后获得价值1500，剩余重量为3，装入笔记本电脑和音响所能获取的最大价值是2000（笔记本电脑行的第3列），1500+2000\u0026gt;3000，故获得的最大价值是3500  所以填充第三行之后的表格长这样：\n   重量 价值 商品 \\ 背包重量 1 2 3 4     4 3000 音响 0 0 0 3000   3 2000 笔记本电脑 0 0 2000 3000   1 1500 吉他 1500 1500 2000 3500      到此为止，表格填充完毕，从表格中可以直观地看到容量为4的背包所能获取的最大价值是3500。除此之外，还可以看到，表格的行从左至右，列从上至下（填充顺序）所获得的最大价值都是递增的（或维持不变），不可能出现最大价值变小的情况！同时，计算容量较小的背包的最大价值这个工作并没有白费，它将用来帮助快速计算大容量的背包所能获取的最大价值。\n关于背包问题，行（商品）的顺序并不影响最终的结果。对上例而言，任意打乱行的顺序获得的结果都是一样的。\n 上例中，若在可选商品列表中添加一个重1磅，价值2000美元的iphone，结果会如何呢？\n  我们可以在已完成的表格中继续添加一个iphone行，得到的结果应该是这样的：\n    重量 价值 商品 \\ 背包重量 1 2 3 4      4 3000 音响 0 0 0 3000    3 2000 笔记本电脑 0 0 2000 3000    1 1500 吉他 1500 1500 2000 3500    1 2000 iphone 2000 3500 3500 4000    如果新增一个商品，重量为1.5磅，价值为2000元，动态规划表应该如何变化呢？\n只需要将动态规划表格的列粒度变为0.5，再重新规划即可  状态转移方程 对于商品而言，其只有2个状态：放入背包或者不放入背包。动态规划的过程就是计算出不同承重的背包所能装入的最大价值，当考虑是否应当将物品装入背包时，比较其装入背包和不装入背包2种情况下获得的最大价值即可得到该背包的最大价值。\n我们可以使用一个二维数组dp[i][j]表示i件物品放入重量为j的背包所能获取的最大价值。\n如dp[3][4]=3500表示3件可选物品，放入容量为4的背包所获得的最大价值为3500。\n和前面讨论的一样，dp[i][j]的计算分为3步：\n 该物品不放入背包的最大价值 v1 = dp[i-1][j] 该物品放入背包的最大价值 v2 = vi + dp[i-1][j-wi]，其中  vi表示物品i的价值 dp[i-1][j-wi]表示前i-1件物品放入容量为j-wi的背包中获取的最大价值，wi为物品i的重量   比较v1和v2，取较大值作为dp[i][j]  综上，背包问题的状态转移方程可以总结为：\n$$\ndp[i][j] = max(dp[i-1][j],dp[i-1][j-w[i]]+v[i])\n$$\nJava代码示例 了解了思路，我们就可以轻松地将其使用编程语言解释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  public class PackIssue { public static void main(String[] args) { Good[] gs = new Good[]{ null, new Good(4, 3000), new Good(3, 2000), new Good(1, 1500) }; int N = 4; // 背包最大容量  // 物品数, 空一行是为了防止计算dp时数组指针越界  // 不然计算dp时i = 0需要单独讨论  int m = gs.length - 1; // 最大价值表是一张N*m的二维表格，表格的每一格数据dp[i][j]表示i件物品放入容量为j的背包中  // 所能获取的最大价值，这个最大价值的形成有2个条件：物品i要么放入背包，要么不放入背包  // 典型的dp公式  // dp[i][j] = max{dp[i-1][j], dp[i-1,j-w[i]] + v[i]}  // N也无需从0开始，没有意义  int[][] dp = new int[m + 1][N + 1]; for (int i = 1; i \u0026lt; m + 1; i++) { int w = gs[i].w; for (int j = 1; j \u0026lt; N + 1; j++) { if (j \u0026gt;= w) { dp[i][j] = Math.max( dp[i - 1][j], dp[i - 1][j - w] + gs[i].v ); } else { dp[i][j] = dp[i - 1][j]; } } } for (int i = 1; i \u0026lt; m + 1; i++) { for (int j = 1; j \u0026lt;= N; j++) { System.out.printf(\u0026#34;%5d\\t\u0026#34;, dp[i][j]); } System.out.println(); } System.out.println(dp[m][N]); } } class Good { // 物品重量  int w; // 物品价值  int v; public Good(int w, int v) { this.w = w; this.v = v; } } /* output 0\t0\t0\t3000 0\t0\t2000\t3000 1500\t1500\t2000\t3500 3500 *///:~   复杂的背包问题  这个问题发现自华为的机试题库，来源：https://www.nowcoder.com/questionTerminal/f9c6f980eeec43ef85be20755ddbeaf4\n 王强今天很开心，公司发给N元的年终奖。王强决定把年终奖用于购物，他把想买的物品分为两类：主件与附件，附件是从属于某个主件的，下表就是一些主件与附件的例子：\n   主件 附件     电脑 打印机，扫描仪   书柜 图书   书桌 台灯，文具   工作椅 无    如果要买归类为附件的物品，必须先买该附件所属的主件。每个主件可以有 0 个、 1 个或 2 个附件。附件不再有从属于自己的附件。王强想买的东西很多，为了不超出预算，他把每件物品规定了一个重要度，分为 5 等：用整数 1 ~ 5 表示，第 5 等最重要。他还从因特网上查到了每件物品的价格（都是 10 元的整数倍）。他希望在不超过 N 元（可以等于 N 元）的前提下，使每件物品的价格与重要度的乘积的总和最大。\n设第 j 件物品的价格为 v[j] ，重要度为 w[j] ，共选中了 k 件物品，编号依次为 j 1 ， j 2 ，……， j k ，则所求的总和为：\nv[j 1 ]*w[j 1 ]+v[j 2 ]*w[j 2 ]+ … +v[j k ]*w[j k ] 。（其中 * 为乘号）\n请你帮助王强设计一个满足要求的购物单。\n输入描述:\n   输入的第 1 行，为两个正整数，用一个空格隔开：N m。（其中 N （ \u0026lt;32000 ）表示总钱数， m （ \u0026lt;60 ）为希望购买物品的个数。） 从第 2 行到第 m+1 行，第 j 行给出了编号为 j-1 的物品的基本数据，每行有 3 个非负整数 v p q 其中 v 表示该物品的价格（ v\u0026lt;10000 ）， p 表示该物品的重要度（ 1 ~ 5 ）， q 表示该物品是主件还是附件。如果 q=0 ，表示该物品为主件，如果 q\u0026gt;0 ，表示该物品为附件， q 是所属主件的编号  输出描述:\n 输出一个正整数，为不超过总钱数的物品的价格与重要度乘积的总和的最大值（ \u0026lt;200000 ）。\n 示例输入：\n 1000 5\n800 2 0\n400 5 1\n300 5 1\n400 3 0\n500 2 0\n 示例输出：\n 2200\n 这个问题和简单的背包问题有诸多类似，差别在于，每一个物品多了附件，因此计算dp[i][j]时需要考虑的情况变得复杂了。将主件+附件看作一个整体计算dp，问题也就得到解决了。\n除了动态规划之外，这个题目的题干也给出了很多有用的信息（审题也很重要啊）：\n 每个主件只有至多2个附件； 每一行（n）输入的数据都有一个id（n-1）； 若q = 0 并不是其id为0，而是指示其是主件，其id由输入次序指定； 若q\u0026gt;0，指示其是附件，q的值是其主件的id，其id由输入次序指定； 物品价格是10的倍数——指定表格列的粒度  获取并理解上面的信息，对于构建模型和录入数据都是非常有利的。就使用示例输入来分析，示例输入了5个物品，id为1～5。其中id=2和id=3的物品为id=1的附件，id=4和id=5的物品为主件。\n回归到背包问题，由于附件是绑定主件的，所以解题时直接将附件的价值归结到主件中，那么问题就变成了1000元购买3件物品所能获取的最大价值。而对应于每一个主件，其最大价值的组成有多种可能性，我们需要在所有的可能性中找出最大价值：\n 不买主件，dp[i][j] = dp[i-1][j]； 只买主件，dp[i][j] = dp[i-1][j-wi] + vi； 买主件+附件1，dp[i][j] = dp[i-1][j-wi-wa1i] + vi + va1i； 买主件+附件2，dp[i][j] = dp[i-1][j-wi-wa2i] + vi + va2i； 买主件+附件1+附件2，dp[i][j] = dp[i-1][j-wi-wa1i-wa2i] + vi + va1i + va2i；  以下是该问题的java语言解决方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110  public class PackIssue2 { public static void main(String[] args) { Scanner in = new Scanner(System.in); int N = in.nextInt(); // price limit  if (N \u0026gt;= 32000) return; int m = in.nextInt(); // goods want buy  if (m \u0026gt;= 60) return; Tar[] tars = new Tar[m + 1]; // index from 1  for (int i = 1; i \u0026lt; m + 1; i++) { int v = in.nextInt(); int p = in.nextInt(); int q = in.nextInt(); Tar tar = new Tar(v, p, q \u0026gt; 0); if (q \u0026gt; 0) { if (tars[q].a1 == 0) { tars[q].setA1(i); } else { tars[q].setA2(i); } } // add all goods to Tar[]  tars[i] = tar; } // dp  int[][] dp = new int[m + 1][N + 1]; for (int i = 1; i \u0026lt; m + 1; i++) { Tar tar = tars[i]; int vi = tar.v; for (int j = 10; j \u0026lt; N + 1; j += 10) { if (tar.isAttach) { // skip attachments  dp[i][j] = dp[i - 1][j]; continue; } if (j \u0026gt;= vi) { // only main  int dp1 = vi * tar.p; int dp2 = dp1, dp3 = dp1, dp4 = dp1; int lv2 = vi, lv3 = vi, lv4 = vi; int lj = j - vi; // main + attachment1  if (tar.a1 \u0026gt; 0) { Tar a1 = tars[tar.a1]; if (lj \u0026gt;= a1.v) { dp2 += a1.v * a1.p; lv2 += a1.v; } } // main + attachment2  if (tar.a2 \u0026gt; 0) { Tar a2 = tars[tar.a2]; if (lj \u0026gt;= a2.v) { dp3 += a2.v * a2.p; lv3 += a2.v; } } // main + attachment1 + attachment2  if (tar.a1 \u0026gt; 0 \u0026amp;\u0026amp; tar.a2 \u0026gt; 0) { Tar a1 = tars[tar.a1]; Tar a2 = tars[tar.a2]; if (lj \u0026gt;= a1.v) { dp4 += a1.v * a1.p; lj -= a1.v; lv4 += a1.v; if (lj \u0026gt;= a2.v) { dp4 += a2.v * a2.p; lv4 += a2.v; } } } dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - vi] + dp1); dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - lv2] + dp2); dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - lv3] + dp3); dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - lv4] + dp4); } else { dp[i][j] = dp[i - 1][j]; } } } System.out.println(dp[m][N]); } } class Tar { int v; // price  int p; // priority, from 1-5  boolean isAttach; int a1; // index of attachment 1 in Tar[]  int a2; // index of attachment 2 in Tar[]  public Tar(int p, int w, boolean isAttach) { this.v = p; this.p = w; this.isAttach = isAttach; } public void setA1(int a1) { this.a1 = a1; } public void setA2(int a2) { this.a2 = a2; } }   参考  0-1背包问题 购物车问题 算法图解-像小说一样有趣的算法入门书 ","description":"","id":12,"section":"posts","tags":["动态规划"],"title":"背包问题","uri":"http://wangy325.top/zh/posts/algo/01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"content":" 如果没有特殊说明，都是针对的是 HotSpot 虚拟机。\n 1 概述 对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像 C/C++程序开发程序员这样为每一个 new 操作去写对应的 delete/free 操作，不容易出现内存泄漏和内存溢出问题。正是因为 Java 程序员把内存控制权利交给 Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。\n2 运行时数据区域 Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK. 1.8 和之前的版本略有不同，下面会介绍到。\nJDK 1.8 之前：\nJDK8之前的内存模型:   JDK 1.8 ：\nJDK8的内存模型:   线程私有的：\n 程序计数器 虚拟机栈 本地方法栈  线程共享的：\n 堆 方法区 直接内存 (非运行时数据区的一部分)  2.1 程序计数器 程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。\n另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。\n从上面的介绍中我们知道程序计数器主要有两个作用：\n 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。  注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。\n2.2 Java 虚拟机栈 与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。\nJava 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 （实际上，Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。）\n局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。\nJava 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。\n StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 若 Java 虚拟机堆中没有空闲内存，并且垃圾回收器也无法提供更多内存的话。就会抛出 OutOfMemoryError 错误。  Java 虚拟机栈也是线程私有的，每个线程都有各自的 Java 虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。\n扩展：那么方法/函数如何调用？\nJava 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。\nJava 方法有两种返回方式：\n return 语句。 抛出异常。  不管哪种返回方式都会导致栈帧被弹出。\n2.3 本地方法栈 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。\n本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。\n方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。\n2.4 堆 Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。\nJava世界中“几乎”所有的对象都在堆中分配，但是，随着JIT编译期的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。从jdk 1.7开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。\nJava 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。\n在 JDK 7 版本及JDK 7 版本之前，堆内存被通常被分为下面三部分：\n 新生代内存(Young Generation) 老生代(Old Generation) 永生代(Permanent Generation)  JDK7-JVM堆内存结构:   JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。\nJDK8-JVM堆内存结构:   上图所示的 Eden 区、两个 Survivor 区都属于新生代（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to），中间一层属于老年代。\n大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-\u0026gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n 修正（issue552）：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。\n 动态年龄计算的代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) { //survivor_capacity是survivor空间的大小 size_t desired_survivor_size = (size_t) ((((double) survivor_capacity)*TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; while (age \u0026lt; table_size) { total += sizes[age];//sizes数组是每个年龄段对象大小  if (total \u0026gt; desired_survivor_size) break; age++; } uint result = age \u0026lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; //... }   堆这里最容易出现的就是 OutOfMemoryError 错误，并且出现这种错误之后的表现形式还会有几种，比如：\n OutOfMemoryError: GC Overhead Limit Exceeded ： 当JVM花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。 java.lang.OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发java.lang.OutOfMemoryError: Java heap space 错误。(和本机物理内存无关，和你配置的内存大小有关！) \u0026hellip;\u0026hellip;  2.5 方法区 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。\n方法区也被称为永久代。很多人都会分不清方法区和永久代的关系，为此我也查阅了文献。\n2.5.1 方法区和永久代的关系  《Java 虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法。\n 2.5.2 常用参数 JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小\n1 2 3 4 5  -XX:PermSize=N //方法区 (永久代) 初始大小 -XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常: //java.lang.OutOfMemoryError: PermGen   相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。\nJDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。\n下面是一些常用参数：\n1 2  -XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小） -XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小   与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。\n2.5.3 为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢?   整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。\n 当你元空间溢出时会得到如下错误： java.lang.OutOfMemoryError: MetaSpace\n 你可以使用 -XX：MaxMetaspaceSize 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。-XX：MetaspaceSize 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。\n  元空间里面存放的是类的元数据，这样加载多少类的元数据就不由 MaxPermSize 控制了, 而由系统的实际可用空间来控制，这样能加载的类就更多了。\n  在 JDK8，合并 HotSpot 和 JRockit 的代码时, JRockit 从来没有一个叫永久代的东西, 合并之后就没有必要额外的设置这么一个永久代的地方了。\n  2.6 运行时常量池 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用）\n既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。\nJDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。\n 修正(issue747，reference)：\n JDK1.7之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时hotspot虚拟机对方法区的实现为永久代 JDK1.7 字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是hotspot中的永久代 。 JDK1.8 hotspot移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace)   相关问题：JVM 常量池中存储的是对象还是引用呢？： https://www.zhihu.com/question/57109429/answer/151717241 by RednaxelaFX\n2.7 直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。\nJDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。\n本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。\n3 HotSpot 虚拟机对象探秘 通过上面的介绍我们大概知道了虚拟机的内存情况，下面我们来详细的了解一下 HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。\n3.1 对象的创建 下图便是 Java 对象的创建过程，我建议最好是能默写出来，并且要掌握每一步在做什么。\ngraph LR A[类加载检查] --\u0026gt;B[分配内存] --\u0026gt;C[初始化0值] --\u0026gt;D[设置对象头] --\u0026gt;E[执行init方法] 3.1.1 类加载检查 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。\n3.1.2 分配内存 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n内存分配的两种方式：（补充内容，需要掌握）\n选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是\u0026quot;标记-清除\u0026quot;，还是\u0026quot;标记-整理\u0026quot;（也称作\u0026quot;标记-压缩\u0026quot;），值得注意的是，复制算法内存也是规整的\n   \\ 指针碰撞 空闲列表     适用场合 堆内存规整，没有内存碎片 堆内存不规整的情况下   原理 用过的内存整理到一边，没用过的内存整理到另一边，使用分界值指针，只要向没使用过的内存方向将指针移动对象内存大小的位置即可 虚拟机维护一个列表，该列表记录那些内存块是可用的，分配一块足够大的内存块给新对象，然后更新列表   收集器 serial，parNew CMS    内存分配并发问题（补充内容，需要掌握）\n在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：\n CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配  3.1.3 初始化零值 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。\n3.1.4 设置对象头 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。\n3.1.5 执行 init 方法 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，\u0026lt;init\u0026gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 \u0026lt;init\u0026gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。\n3.2 对象的内存布局 在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头、实例数据和对齐填充。\nHotspot 虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。\n实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。\n对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。\n3.3 对象的访问定位 建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有①使用句柄和②直接指针两种：\n  句柄： 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；\n对象的访问定位-使用句柄:     直接指针： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。\n对象的访问定位-直接指针:     这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。\n4 补充内容 4.1 String类和常量池 String 对象的两种创建方式：\n1 2 3 4 5 6  String str1 = \u0026#34;abcd\u0026#34;;//先检查字符串常量池中有没有\u0026#34;abcd\u0026#34;，如果字符串常量池中没有，  //则创建一个，然后 str1 指向字符串常量池中的对象，如果有，则直接将 str1 指向\u0026#34;abcd\u0026#34;\u0026#34;； String str2 = new String(\u0026#34;abcd\u0026#34;);//堆中创建一个新的对象 String str3 = new String(\u0026#34;abcd\u0026#34;);//堆中创建一个新的对象 System.out.println(str1==str2);//false System.out.println(str2==str3);//false   这两种不同的创建方法是有差别的。\n 第一种方式是在常量池中拿对象； 第二种方式是直接在堆内存空间创建一个新的对象。  记住一点：只要使用 new 方法，便需要创建新的对象。\n再给大家一个图应该更容易理解，图片来源：https://www.journaldev.com/797/what-is-java-string-pool：\nJava String Pool:   String 类型的常量池比较特殊。它的主要使用方法有两种：\n 直接使用双引号声明出来的 String 对象会直接存储在常量池中。 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，JDK1.7之前（不包含1.7）的处理方式是在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用，JDK1.7以及之后的处理方式是在常量池中记录此字符串的引用，并返回该引用。  1 2 3 4 5 6  String s1 = new String(\u0026#34;计算机\u0026#34;); String s2 = s1.intern(); String s3 = \u0026#34;计算机\u0026#34;; System.out.println(s2);//计算机 System.out.println(s1 == s2);//false，因为一个是堆内存中的 String 对象一个是常量池中的 String 对象， System.out.println(s3 == s2);//true，因为两个都是常量池中的 String 对象   字符串拼接:\n1 2 3 4 5 6 7 8 9  String str1 = \u0026#34;str\u0026#34;; String str2 = \u0026#34;ing\u0026#34;; String str3 = \u0026#34;str\u0026#34; + \u0026#34;ing\u0026#34;;//常量池中的对象 String str4 = str1 + str2; //在堆上创建的新的对象\tString str5 = \u0026#34;string\u0026#34;;//常量池中的对象 System.out.println(str3 == str4);//false System.out.println(str3 == str5);//true System.out.println(str4 == str5);//false   字符串拼接:   尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 StringBuilder 或者 StringBuffer。\n4.2 String s1 = new String(\u0026ldquo;abc\u0026rdquo;);这句话创建了几个字符串对象？ 将创建 1 或 2 个字符串。如果池中已存在字符串常量“abc”，则只会在堆空间创建一个字符串常量“abc”。如果池中没有字符串常量“abc”，那么它将首先在池中创建，然后在堆空间中创建，因此将创建总共 2 个字符串对象。\n验证：\n1 2 3 4  String s1 = new String(\u0026#34;abc\u0026#34;);// 堆内存的地址值 String s2 = \u0026#34;abc\u0026#34;; System.out.println(s1 == s2);// 输出 false,因为一个是堆内存，一个是常量池的内存，故两者是不同的。 System.out.println(s1.equals(s2));// 输出 true   4.3 八种基本类型的包装类和常量池 Java 基本类型的包装类的大部分都实现了常量池技术，即 Byte,Short,Integer,Long,Character,Boolean；前面 4 种包装类默认创建了数值[-128，127] 的相应类型的缓存数据，Character创建了数值在[0,127]范围的缓存数据，Boolean 直接返回True Or False。如果超出对应范围仍然会去创建新的对象。 为啥把缓存设置为[-128，127]区间？（参见issue/461）性能和资源之间的权衡。\n1 2 3  public static Boolean valueOf(boolean b) { return (b ? TRUE : FALSE); }   1 2 3 4 5 6 7 8 9  private static class CharacterCache { private CharacterCache(){} static final Character cache[] = new Character[127 + 1]; static { for (int i = 0; i \u0026lt; cache.length; i++) cache[i] = new Character((char)i); } }   两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。\n1 2 3 4 5 6 7 8 9  Integer i1 = 33; Integer i2 = 33; System.out.println(i1 == i2); // true Integer i11 = 333; Integer i22 = 333; System.out.println(i11 == i22);\t// false Double i3 = 1.2; Double i4 = 1.2; System.out.println(i3 == i4); // false   Integer 缓存源代码：\n1 2 3 4 5 6 7 8 9  /** *此方法将始终缓存-128 到 127（包括端点）范围内的值，并可以缓存此范围之外的其他值。 */ public static Integer valueOf(int i) { if (i \u0026gt;= IntegerCache.low \u0026amp;\u0026amp; i \u0026lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); }   应用场景：\n Integer i1=40；Java 在编译的时候会直接将代码封装成 Integer i1=Integer.valueOf(40);，从而使用常量池中的对象。 Integer i1 = new Integer(40);这种情况下会创建新的对象。  1 2 3  Integer i1 = 40; Integer i2 = new Integer(40); System.out.println(i1==i2);//输出 false   Integer 比较更丰富的一个例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13  Integer i1 = 40; Integer i2 = 40; Integer i3 = 0; Integer i4 = new Integer(40); Integer i5 = new Integer(40); Integer i6 = new Integer(0); System.out.println(\u0026#34;i1=i2 \u0026#34; + (i1 == i2));\t// true System.out.println(\u0026#34;i1=i2+i3 \u0026#34; + (i1 == i2 + i3));\t// true System.out.println(\u0026#34;i1=i4 \u0026#34; + (i1 == i4));\t// false System.out.println(\u0026#34;i4=i5 \u0026#34; + (i4 == i5));\t// false System.out.println(\u0026#34;i4=i5+i6 \u0026#34; + (i4 == i5 + i6)); // true 自动拆箱 System.out.println(\u0026#34;40=i5+i6 \u0026#34; + (40 == i5 + i6)); // true   解释：\n语句 i4 == i5 + i6，因为+这个操作符不适用于 Integer 对象，首先 i5 和 i6 进行自动拆箱操作，进行数值相加，即 i4 == 40。然后 Integer 对象无法与数值进行直接比较，所以 i4 自动拆箱转为 int 值 40，最终这条语句转为 40 == 40 进行数值比较。\n参考  《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第二版》 《实战 java 虚拟机》 https://docs.oracle.com/javase/specs/index.html http://www.pointsoftware.ch/en/under-the-hood-runtime-data-areas-javas-memory-model/ https://dzone.com/articles/jvm-permgen-%E2%80%93-where-art-thou https://stackoverflow.com/questions/9095748/method-area-and-permgen 深入解析String#intern https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html  点击查看原文\n","description":"本文介绍了HotSpot虚拟机的内存空间分配，以及各空间的主要职能。","id":13,"section":"posts","tags":["Java虚拟机"],"title":"Java内存区域详解(转)","uri":"http://wangy325.top/zh/posts/java/jvm/java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AF%A6%E8%A7%A3/"},{"content":"开发过程中，或多或少会碰到需要使用数据库事务的业务场景，而Spring框架提供的能力使得开发者无需过多地关注事务本身，这带来诸多便利，但也带来弊端：开发者只知其貌，而不知其理，一旦Spring框架抛出异常，便往往手足无措。本文简单地介绍了MySQL事务相关的基本概念，使用例证阐述了不同事务隔离级别下MySQL的数据可见性，简单讨论了MySQL如何保证数据一致性。有了这些基本的概念，遇到事务与数据库锁相关的问题时，开发者能够多一点思考。\n事务的概念可以这样理解：\n 在mysql中，有些操作必须要分步完成，那么我们可以把这些分步完成的操作声明为一个“事务”，用来保证mysql数据一致性。\n对于单条sql语句而言，mysql将其处理为一个「隐式事务」。\n 看起来，事务的概念还是有些空泛。事实上，有了一定的并发基础后（这也是这篇文章写在java并发之后的原因），更加容易理解事务这个概念，这并不是说事务一个并发概念，不过，事务是有了并发之后才衍生的概念，这很容易理解。试想一个只容许一个客户端连接的mysql服务，是否需要“事务”呢？答案应该是否定的。单个客户端执行sql语句总是有序的，数据一致性就能得到保证了1。试想，如果是多客户端的系统（事实上正是如此）同时执行sql语句，就好似多线程同时访问资源一样，对于数据库系统而言，所有的数据表都是共享资源2，那么事务就像是那把保证并发安全的锁。\n1 事务的ACID性质 事务可以保证被声明为事务的分步操作要么都成功执行，要么都不执行。若某一分步遇到错误，执行成功的那些步骤操作会被回滚，这样不会对mysql的数据完整性进行破坏。\n  Atomicity 原子性\n原子性的概念和所有并发编程的概念一样，如果声明一个操作是原子的，那么这个操作要么执行，要么不执行。如果声明了一个事务，那么就可以把事务开启之后执行的SQL语句看作一个「并发编程里面的临界区」中的代码，它只能允许一个SQL连接访问数据。包含的SQL分步操作要么全部执行，要么全不执行。\n  Consistency 一致性\n数据库的状态只会从一个一致状态转移到另一个一致状态，事务操作不应该影响数据的一致性。比如转账操作，A账户转出100，B账户一定会转入100。若A账户转出100之后系统崩溃，账户A也不会损失100元，因为事务没有提交，所有事务的修改不会提交到数据库中。\n  Isolation 隔离性\n如果有多个事务并发执行，那么事务之间应该不能产生干扰，这也是保证数据安全性的重要环节。比如A账户转出100元，此时有另一个事务读取了A账户的值，读取到的账户的值不应该是A账户减去100元的值，而应该是原始值。\n  Durability 持久性\n一旦事务被提交，其对数据的修改是永久性的。即使系统崩溃，修改的数据也不会丢失。\n  2 事务的隔离级别 如果事务满足ACID性质，那么数据安全性就不会受到威胁。那么，设计一个逻辑来保证事务的ACID性质不就解决问题了么，为什么还要设计事务的隔离级别呢？结合实际情况来看，并非所有的事务都需要满足ACID特性，有些数据对准确性要钱不高的的事务，是允许读取到其他事务修改的数据例证。另外，在实现过程中，一个满足ACID特性的数据库系统要复杂的多，系统需要做很多额外的操作来满足ACID特性，这样会造成额外的开销，系统会占用更多的资源而影响数据库的执行效率。这也是数据库中仍然有不支持事务的存储引擎一席之地的原因3。\n事务的隔离级别并不是mysql独有的，它是SQL标准中定义的，没种隔离级别都规定了一个事务中所做的修改在那些事务内和事务間是可见的，哪些是不可见的。较低的隔离级别支持更高的并发、拥有更高的效率。\n  READ UNCOMMITTED（读未提交）\n这个隔离级别中，事务中的修改，即使没有提交，对其他事务都是可见的。其他事务可以读取到未提交的数据，这种情况称为脏读（dirty read）。这个级别会导致很多问题，一般很少使用。\n  READ COMMITTED（读已提交）\n这个隔离级别中，满足隔离性的简单定义，一个事务开始前，只能读取到已经提交的事务所做的修改。换言之，一个事务对数据库所做的任何修改在其提交之前都其他事务都是不可见的。这会导致是个现象：一个事务可能2次读取到的数据是不一致的（事务A提交前与提交后），这种情况称为不可重复读（nonrepeatable read）\n  REPEATABLE READ（可重复读）\n可重复读解决了脏读的问题，同时也保证了在事务了多次对同一个数据取样，读取到的数据是一致的。但是，理论上，该隔离级别的不能解决幻读（phantom read）的问题：幻读指的是某个事务在读取某个范围的记录时，另外一个事务又在该范围内插入了新的记录，那么，当之前的事务再次读取这个范围的记录时，就会出现幻行（phantom row）。不过InnoDB引擎通过MVCC(multi version concurrency control)多版本并发控制解决了幻读的问题。\n可重复读是mysql的默认隔离级别\n  SERIALIZABLE（可串行化）\nSERIALIZABLE是最高的隔离级别，它通过强制所有的SQL语句串行执行来避免幻读的问题。该隔离级别下，每一行使用到的数据都会加锁，所以当数据库请求量大的时候，就有可能造成大量的超时等待4和锁争用的问题。这个隔离级别很少使用，因为其牺牲了很大量的性能来保证数据一致性。如果不是严格地要求数据一致性，可以考虑此隔离级别表述有误？。\n  下表展示了事务隔离级别以及其可能引起的后果之间的额关系：\n  隔离级别 脏读可能性 不可重复读可能性 幻读可能性 加锁读     READ UNCOMMITTED Y Y Y N   READ COMMITTED N Y Y N   REPEATABLE READ N N Y N   SERIALIZABLE N N N Y    3 查看数据库的基本信息 在实例演示之前，需要查看几个基本信息，来确保测试环境的一致性与可行性。这些基本信息包括，数据库当前所使用的引擎，数据库当前的事务隔离级别。\n3.1 引擎 使用下面的命令查看当前数据库的引擎信息\n1 2 3 4 5 6 7 8 9 10  mysql\u0026gt; show variables like \u0026#39;%engine%\u0026#39;; +----------------------------------+--------+ | Variable_name | Value | +----------------------------------+--------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | disabled_storage_engines | | | internal_tmp_disk_storage_engine | InnoDB | +----------------------------------+--------+ 4 rows in set (0.01 sec)   看到系统当前数据库（版本5.7）的默认存储引擎是InnoDB，InnoDB引擎支持事务，就用这个引擎测试。\n我们使用供应商表vendors完成接下来的测试，先看看vendors表所使用的引擎：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  mysql\u0026gt; show table status like \u0026#39;vendors\u0026#39; \\G *************************** 1. row *************************** Name: vendors Engine: InnoDB Version: 10 Row_format: Dynamic Rows: 6 Avg_row_length: 2730 Data_length: 16384 Max_data_length: 0 Index_length: 0 Data_free: 0 Auto_increment: 1008 Create_time: 2020-11-25 18:37:46 Update_time: NULL Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec)   我们看到vendors表的引擎也是InnoDB。\n3.2 隔离级别 使用如下命令查看当前数据库的事务隔离级别\n1 2 3 4 5 6 7  mysql\u0026gt; show variables like \u0026#39;tx_isolation\u0026#39;; +---------------+-----------------+ | Variable_name | Value | +---------------+-----------------+ | tx_isolation | REPEATABLE-READ | +---------------+-----------------+ 1 row in set (0.01 sec)   当前数据库的事务隔离级别为可重复读，加上InnoDB引擎的MVCC，基本上是满足事务的ACID特性的数据库系统。\n在进行测试时，我们可以通过\n1  mysql\u0026gt; SET TRANSACTION ISOLATION LEVEL [tx_isolation];   来控制当前客户端连接的下个事务隔离级别——只对当前连接的下一次事务生效生效，这样便于测试。\n更多关于set transaction命令的内容：https://dev.mysql.com/doc/refman/8.0/en/set-transaction.html\n在测试过程中，涉及到的客户端命令有：\n begin或者start transaction开始事务 rollback回滚/结束事务 commit提交/结束事务  4 读未提交 READ UNCOMMITTED 从上面的执行图可以看到：\n 会话1（左）和会话2（右）的事务隔离级别都设置为READ UNCOMMITTED 会话1将vend_id=1007对应的vend_address改为sz； 此时会话2中去读取vend_id=1007的数据，已经读取到了会话1未提交的更改；\u0026lt;==脏读 接着会话1将更改回滚； 会话2再次读取vend_id=1007的数据，发现数据列vend_address变为初始值。\u0026lt;==不可重复读  上面的执行流程完整的演示了在READ UNCOMMITTED隔离级别下的脏读和不可重复读现象。\n5 读已提交 READ COMMITTED 从上面的执行图可以看到：\n 会话1和会话2的事务隔离级别都设置为READ COMMITTED； 会话1将vend_id=1007对应的vend_address改为sz； 此时会话2中去读取vend_id=1007的数据，不能读取到会话1未提交的更改；\u0026lt;==结果1 会话1提交更改 会话2再次读取vend_id=1007的数据，读取到数据列vend_address的更改。\u0026lt;==结果2  上面的执行流程完整演示了在READ COMMITTED隔离级别下，两次读取到的结果不一致的现象，即在此隔离级别下不可重复读。\n6 多版本并发控制（MVCC） 前文提到，mysql的InnoDB引擎使用MVCC解决了在可重复读(REPEATABLE READ)隔离级别下幻读(phantom read)的问题。因此，在执行可重复读隔离级别的测试之前，先介绍一下多版本并发控制(Multi Version Cocurrency Control)5。\n可以认为，MVCC是行级锁的一个变种，但是其在很多情况下避免了加锁操作6，因此可以节省部分开销，获得更好的性能。\n在InnoDB的MVCC中，通过在每行记录之后添加2个隐藏的列来实现的：\n    \\\\ 隐藏列1 隐藏列2     记录内容 行的创建时间 行的过期时间（删除时间）     要注意的是，实际上存储的并不是实际的时间值，而是当前的系统版本号（system version number）。系统版本号有如下特征：\n 每开始一个新事务，系统版本号都会递增 ； 事务开始时的版本号作为事务的版本号； 事务的版本号用来和查询到的每条记录的版本号对比，决定语句的操作；  在REPEATABLE READ隔离级别下，MVCC的具体行为是：\n  SELECT\nInnoDB会根据一下条件检查每行记录：\n InnoDB只查找版本号早于当前事务版本号的数据（小于等于事务的版本号） 。这样做，可以保证当前事务只能读取事务开始前已经存在的数据行，或者该事务自身插入或者修改的数据行； 行的删除版本要么未定义，要么大于当前事务版本号。这可以保证事务开始前，读取到的行未被删除。    INSERT\nInnoDB为新插入的每一行保存当前系统版本号所为行版本号。\n  DELETE\nInnoDB为删除的每一行保存当前系统版本号作为删除标识。\n  INSERT\nInnoDB为插入一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识\n  事实上，MVCC是通过保存数据在某个时间点的快照（snapshot）来实现的，也就是说不管事务执行多长时间，其所能看到的数据都是一致的。这就可能造成一个现象：\n 根据事务开始的时间的不同，每个事务对同一张表，同一时刻看到的数据可能是不一致的。\n 在接下来的演示中，我们将会看到MVCC在事务执行过程中的行为。\n7 可重复读 REPEATABLE READ 这是一个相对完整的示例，演示了InnoDB引擎在默认事务隔离级别下，不同事务在处理同一行数据之间的表现，其中有一些结果出乎意料却又在MVCC以及事务隔离级别的“情理之中”。在这个示例中我们可以看到以下重要内容：\n 事务只能读取到在其开始之前就已经存在的数据，或者其自身修改的数据； 事务使用了行级锁来保证数据一致； 事务B可以修改事务A创建但未提交的数据，并且事务B随即可读取之，这验证了第1点； 事务A无法读取到事务B的修改（只要这个修改发生在事务A开始之后，无论事务B是否提交），这保证了可重复读； 如果数据行在事务A在开始前已经存在，但随即被事务B删除，那么事务A无法再对数据行进行修改。但是事务A依旧可以读取到数据行的内容。这就是“快照”的概念在MVCC中的行为。  遗憾的是，笔者试图从MVCC“系统版本号”的概念去推断事务的执行，始终无法得出与预期一致的结果，所以关于MVCC“系统版本号”的工作机制，此文尚不能详述，不过，程序的执行期望却和前文描述的MVCC行为是一致的。其实，使用“快照”的概念去理解MVCC的行为，会显得更容易。\n8 串行 SERIALIZABLE 当使用最高的事务级别同时开启2个事务时，2个事务只能依次执行，换言之，会话2会阻塞会话1的insert操作，只有当会话2commit/rollback之后，会话1才会结束阻塞。\n 上图中第一次执行insert的时候，发现语句迟迟不返回，以为是语句故障，使用ctrl-c结束了语句执行，控制台输出：\n    ERROR 1317 (70100): Query execution was interrupted\n 看到interruptted，间接证明了insert操作确实是处于阻塞状态  9 参考  高性能mysql 第3版 廖雪峰的官方网站-数据库事务 mysql document page 【推荐】数据库的事务和锁7   类比资源的序列访问，可能不太恰当，大可不必过分纠结于此。 \u0026#x21a9;\u0026#xfe0e;\n 当然可以使用权限控制将某个资源排除对特定连接的共享。 \u0026#x21a9;\u0026#xfe0e;\n 这也是有些业务不需要事务支持，使用MyISAM(indexed sequencial access method)作为数据库引擎的原因。 \u0026#x21a9;\u0026#xfe0e;\n 一些存储引擎在处理数据库死锁的时选用的方法。InnoDB并不是采用的此方法，其是将持有最少行锁的事务回滚。 \u0026#x21a9;\u0026#xfe0e;\n 不仅仅mysql，很多数据库系统包括Oracle，PostGreSQL都实现了MVCC，尽管其实现机制不尽相同。 \u0026#x21a9;\u0026#xfe0e;\n MVCC的并发控制有乐观加锁和悲观加锁两种方式，并不是所有的实现都不加锁，只有使用乐观锁是不加锁的。 \u0026#x21a9;\u0026#xfe0e;\n 此链接正文部分关于索引的讨论有些谬误，这些谬误在评论区可找到相关讨论。 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文介绍了mysql的事务ACID性质以及4种事务隔离级别，顺便提了提MVVC的相关概念。","id":14,"section":"posts","tags":["acid","事务"],"title":"mysql事务与隔离级别","uri":"http://wangy325.top/zh/posts/java/sql/mysql%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"},{"content":"本节常见面试题 问题答案在文中都有提到\n 如何判断对象是否死亡（两种方法）。 简单的介绍一下强引用、软引用、弱引用、虚引用（虚引用与软引用和弱引用的区别、使用软引用能带来的好处）。 如何判断一个常量是废弃常量 如何判断一个类是无用的类 垃圾收集有哪些算法，各自的特点？ HotSpot 为什么要分为新生代和老年代？ 常见的垃圾回收器有哪些？ 介绍一下 CMS,G1 收集器。 Minor Gc 和 Full GC 有什么不同呢？  本文概览 graph LR A[Java内存分配规则] --\u0026gt; B[找出垃圾] --\u0026gt;C[触发GC] --\u0026gt;D[如何回收垃圾] 当需要排查各种内存溢出问题、当垃圾收集成为系统达到更高并发的瓶颈时，我们就需要对这些“自动化”的技术实施必要的监控和调节。\n1 揭开 JVM 内存分配与回收的神秘面纱 Java 的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java 自动内存管理最核心的功能是 堆 内存中对象的分配与回收。\nJava 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。\n堆空间的基本结构：\n上图所示的 Eden 区、From Survivor0(\u0026ldquo;From\u0026rdquo;) 区、To Survivor1(\u0026ldquo;To\u0026rdquo;) 区都属于新生代，Old Memory 区属于老年代。\n大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-\u0026gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n 修正（issue552）：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。\n动态年龄计算的代码如下\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) { //survivor_capacity是survivor空间的大小  size_t desired_survivor_size = (size_t)((((double) survivor_capacity) *TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; while (age \u0026lt; table_size) { total += sizes[age];//sizes数组是每个年龄段对象大小  if (total \u0026gt; desired_survivor_size) break; age++; } uint result = age \u0026lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; ... }   经过这次GC后，Eden区和\u0026quot;From\u0026quot;区已经被清空。这个时候，\u0026ldquo;From\u0026quot;和\u0026quot;To\u0026quot;会交换他们的角色，也就是新的\u0026quot;To\u0026quot;就是上次GC前的“From”，新的\u0026quot;From\u0026quot;就是上次GC前的\u0026quot;To\u0026rdquo;。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，\u0026ldquo;To\u0026quot;区被填满之后，会将所有对象移动到老年代中。\ngraph LR A[堆内存常见分配策略]-- 1 --\u0026gt;B[对象优先在eden区分配] A -- 2 --\u0026gt; C[大对象直接进入老年代] A -- 3 --\u0026gt; D[长期存活的对象将进入老年代] 1.1 对象优先在 eden 区分配 目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。\n大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC.下面我们来进行实际测试以下。\n测试：\n1 2 3 4 5 6 7 8  public class GCTest { public static void main(String[] args) { byte[] allocation1, allocation2; allocation1 = new byte[30900*1024]; //allocation2 = new byte[900*1024]; \t} }   通过以下方式运行：\n添加的参数：-XX:+PrintGCDetails\n运行结果 (红色字体描述有误，应该是对应于 JDK1.7 的永久代)：\n从上图我们可以看出 eden 区内存几乎已经被分配完全（即使程序什么也不做，新生代也会使用 2000 多 k 内存）。假如我们再为 allocation2 分配内存会出现什么情况呢？\n1  allocation2 = new byte[900*1024];   简单解释一下为什么会出现这种情况： 因为给 allocation2 分配内存的时候 eden 区内存几乎已经被分配完了，我们刚刚讲了当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC.GC 期间虚拟机又发现 allocation1 无法存入 Survivor 空间，所以只好通过 分配担保机制 把新生代的对象提前转移到老年代中去，老年代上的空间足够存放 allocation1，所以不会出现 Full GC。执行 Minor GC 后，后面分配的对象如果能够存在 eden 区的话，还是会在 eden 区分配内存。可以执行如下代码验证：\n1 2 3 4 5 6 7 8 9 10 11  public class GCTest { public static void main(String[] args) { byte[] allocation1, allocation2,allocation3,allocation4,allocation5; allocation1 = new byte[32000*1024]; allocation2 = new byte[1000*1024]; allocation3 = new byte[1000*1024]; allocation4 = new byte[1000*1024]; allocation5 = new byte[1000*1024]; } }   1.2 大对象直接进入老年代 大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。\n为什么要这样呢？\n为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。\n1.3 长期存活的对象将进入老年代 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。\n如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n1.4 动态对象年龄判定 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-\u0026gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n 修正（issue552）：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。\n动态年龄计算的代码如下\n 1 2 3 4 5 6 7 8 9 10 11 12 13  uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) { //survivor_capacity是survivor空间的大小  size_t desired_survivor_size = (size_t)((((double) survivor_capacity)*TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; while (age \u0026lt; table_size) { total += sizes[age];//sizes数组是每个年龄段对象大小  if (total \u0026gt; desired_survivor_size) break; age++; } uint result = age \u0026lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; ... }    额外补充说明(issue672)：关于默认的晋升年龄是15，这个说法的来源大部分都是《深入理解Java虚拟机》这本书。\n如果你去Oracle的官网阅读相关的虚拟机参数，你会发现-XX:MaxTenuringThreshold=threshold这里有个说明\nSets the maximum tenuring threshold for use in adaptive GC sizing. The largest value is 15. The default value is 15 for the parallel (throughput) collector, and 6 for the CMS collector.默认晋升年龄并不都是15，这个是要区分垃圾收集器的，CMS就是6.\n 1.5主要进行 gc 的区域 周志明先生在《深入理解Java虚拟机》第二版中P92如是写道：\n “老年代GC（Major GC/Full GC），指发生在老年代的GC……”\n 上面的说法已经在《深入理解Java虚拟机》第三版中被改正过来了。感谢R大的回答：\n总结：\n针对HotSpot VM的实现，它里面的GC其实准确分类只有两大种：\n部分收集 (Partial GC)：\n 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集； 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集； 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。  整堆收集 (Full GC)：收集整个 Java 堆和方法区。\n2 对象已经死亡？ 堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。\n2.1 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。\n这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。\n1 2 3 4 5 6 7 8 9 10 11 12  public class ReferenceCountingGc { Object instance = null; public static void main(String[] args) { ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; } }   2.2 可达性分析算法 这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。\n ![可达性分析算法 ](/img/jvm-gc-object-death-2.png)  可作为GC Roots的对象包括下面几种:\n 虚拟机栈(栈帧中的本地变量表)中引用的对象 本地方法栈(Native方法)中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象  2.3 再谈引用 无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。\nJDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。\nJDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱）\n1．强引用（StrongReference）\n以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。\n2．软引用（SoftReference）\n如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。\n软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。\n3．弱引用（WeakReference）\n如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。\n弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。\n4．虚引用（PhantomReference）\n\u0026ldquo;虚引用\u0026quot;顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。\n虚引用主要用来跟踪对象被垃圾回收的活动。\n虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。\n特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。\n2.4 不可达的对象并非“非死不可” 即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。\n被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。\n2.5 如何判断一个常量是废弃常量？ 运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？\nJDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。\n 修正(issue747，reference)：\n JDK1.7之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时hotspot虚拟机对方法区的实现为永久代 JDK1.7 字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是hotspot中的永久代 。 JDK1.8 hotspot移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace)   假如在字符串常量池中存在字符串 \u0026ldquo;abc\u0026rdquo;，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 \u0026ldquo;abc\u0026rdquo; 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\u0026ldquo;abc\u0026rdquo; 就会被系统清理出常量池了。\n2.6 如何判断一个类是无用的类 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？\n判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ：\n 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。  虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。\n3 垃圾收集算法 graph TD A[垃圾收集算法]--\u0026gt; B[标记-清除算法] A --\u0026gt;C[复制算法] \u0026amp; D[标记-整理算法] \u0026amp; E[分代收集算法] 3.1 标记-清除算法 该算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：\n 效率问题 空间问题（标记清除后会产生大量不连续的碎片）  标记-清除算法:   3.2 复制算法 为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。\n复制算法:   3.3 标记-整理算法 根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。\n标记-整理算法:   3.4 分代收集算法 当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。\n比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。\n延伸面试问题： HotSpot 为什么要分为新生代和老年代？\n根据上面的对分代收集算法的介绍回答。\n4 垃圾收集器 graph TD A[垃圾收集器分类]--\u0026gt; B[serial收集器] A --\u0026gt;C[ParNew收集器] \u0026amp; D[Parallel Scavenge收集器] \u0026amp; E[CMS收集器] \u0026amp; F[G1收集器] 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。\n虽然我们对各个收集器进行比较，但并非要挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的 HotSpot 虚拟机就不会实现那么多不同的垃圾收集器了。\n4.1 Serial 收集器 Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ \u0026ldquo;Stop The World\u0026rdquo; ），直到它收集结束。\nSerial 收集器: 新生代复制算法，老年代标记-整理算法   虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。\n但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。\n4.2 ParNew 收集器 ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。\nParNew 收集器: 新生代复制算法，老年代标记-整理算法   它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。\n并行和并发概念补充：\n  并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。\n  并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。\n  4.3 Parallel Scavenge 收集器 Parallel Scavenge 收集器也是使用复制算法的多线程收集器，它看上去几乎和ParNew都一样。 那么它有什么特别之处呢？\n-XX:+UseParallelGC 使用 Parallel 收集器+ 老年代串行 -XX:+UseParallelOldGC 使用 Parallel 收集器+ 老年代并行 Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。\nParallel Scavenge 收集器: 新生代复制算法，老年代标记-整理算法   是JDK1.8默认收集器\n使用java -XX:+PrintCommandLineFlags -version命令查看\n-XX:InitialHeapSize=262921408 -XX:MaxHeapSize=4206742528 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC java version \u0026quot;1.8.0_211\u0026quot; Java(TM) SE Runtime Environment (build 1.8.0_211-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode) JDK1.8默认使用的是Parallel Scavenge + Parallel Old，如果指定了-XX:+UseParallelGC参数，则默认指定了-XX:+UseParallelOldGC，可以使用-XX:-UseParallelOldGC来禁用该功能\n4.4.Serial Old 收集器 Serial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。\n4.5 Parallel Old 收集器 Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。\n4.6 CMS 收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。\nCMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。\n从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：\n 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。  CMS 垃圾收集器:   从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点：\n 对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。  4.7 G1 收集器 G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.\n被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：\n 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记\u0026ndash;清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。  G1 收集器的运作大致分为以下几个步骤：\n 初始标记 并发标记 最终标记 筛选回收  G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。\n5 JVM 配置常用参数 5.1 Java内存区域常见配置概览 5.2 堆参数 堆参数:   5.3 回收器参数 垃圾回收器参数:   如上表所示，目前主要有串行、并行和并发三种，对于大内存的应用而言，串行的性能太低，因此使用到的主要是并行和并发两种。并行和并发 GC 的策略通过 UseParallelGC 和 UseConcMarkSweepGC 来指定，还有一些细节的配置参数用来配置策略的执行方式。例如：XX:ParallelGCThreads， XX:CMSInitiatingOccupancyFraction 等。 通常：Young 区对象回收只可选择并行（耗时间），Old 区选择并发（耗 CPU）。\n5.4 推荐配置 在Java8中永久代的参数-XX:PermSize 和-XX：MaxPermSize已经失效。\n 按需求弹性配置各项参数，请勿死记硬背  项目中垃圾回收器常用配置:   5.5 常用的垃圾回收器组合 垃圾回收器常用组合配置:   6 不要急着GC调优 在调优之前，我们需要记住下面的原则：\n 多数的 Java 应用不需要在服务器上进行 GC 优化； 多数导致 GC 问题的 Java 应用，都不是因为我们参数设置错误，而是代码问题； 在应用上线之前，先考虑将机器的 JVM 参数设置到最优（最适合）； 减少创建对象的数量； 减少使用全局变量和大对象； GC 优化是到最后不得已才采用的手段； 在实际使用中，分析 GC 情况优化代码比优化 GC 参数要多得多。  总结一句话，养成良好的编码习惯，是避免GC调优的好办法，GC调优应该是最后的选择。\n要始终相信Java虚拟机自身的性能，如果项目的负荷重、体量大，并发高，代码层面优化的余地小，再尝试做GC优化方面的工作。\n6.1 GC调优目的 将转移到老年代的对象数量降低到最小； 减少GC的执行时间。\n6.2 GC调优策略  策略1： 将新对象预留在新生代，由于 Full GC 的成本远高于 Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据 GC 日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最大限度降低新对象直接进入老年代的情况。 策略2： 大对象进入老年代，虽然大部分情况下，将对象分配在新生代是合理的。但是对于大对象这种做法却值得商榷，大对象如果首次在新生代分配可能会出现空间不足导致很多年龄不够的小对象被分配的老年代，破坏新生代的对象结构，可能会出现频繁的 full gc。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收来说简直就是噩梦）。-XX:PretenureSizeThreshold 可以设置直接进入老年代的对象大小。 策略3： 合理设置进入老年代对象的年龄，-XX:MaxTenuringThreshold 设置对象进入老年代的年龄大小，减少老年代的内存占用，降低 full gc 发生的频率。 策略4： 设置稳定的堆大小，堆大小设置有两个参数：-Xms 初始化堆大小，-Xmx 最大堆大小。 策略5： 注意： 如果满足下面的指标，则一般不需要进行 GC 优化：   MinorGC 执行时间不到50ms； Minor GC 执行不频繁，约10秒一次； Full GC 执行时间不到1s； Full GC 执行频率不算频繁，不低于10分钟1次。\n 参考  《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第二版》 https://my.oschina.net/hosee/blog/644618 https://docs.oracle.com/javase/specs/jvms/se8/html/index.html  点我查看原文\n","description":"本文介绍了JVM垃圾回收的几个机制，以及集中主要的垃圾回收算法。","id":15,"section":"posts","tags":["gc"],"title":"JVM垃圾回收概要(转)","uri":"http://wangy325.top/zh/posts/java/jvm/java-gc/"},{"content":"简单来说 Redis 就是一个使用 C 语言开发的数据库，不过与传统数据库不同的是 Redis 的数据是存在内存中的 ，也就是它是内存数据库，所以读写速度非常快，因此 Redis 被广泛应用于缓存方向。\n另外，Redis 除了做缓存之外，Redis 也经常用来做分布式锁，甚至是消息队列。\nRedis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。\n2. 分布式缓存常见的技术选型方案有哪些？ 分布式缓存的话，使用的比较多的主要是 Memcached 和 Redis。不过，现在基本没有看过还有项目使用 Memcached 来做缓存，都是直接用 Redis。\nMemcached 是分布式缓存最开始兴起的那会，比较常用的。后来，随着 Redis 的发展，大家慢慢都转而使用更加强大的 Redis 了。\n分布式缓存主要解决的是单机缓存的容量受服务器限制并且无法保存通用的信息。因为，本地缓存只在当前服务里有效，比如如果你部署了两个相同的服务，他们两者之间的缓存数据是无法共同的。\n3. 说一下 Redis 和 Memcached 的区别和共同点 现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！不过，了解 Redis 和 Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！\n共同点 ：\n 都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者的性能都非常高。  区别 ：\n Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。 Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。 Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。 Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的. Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。 （Redis 6.0 引入了多线程 IO ） Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。 Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。  相信看了上面的对比之后，我们已经没有什么理由可以选择使用 Memcached 来作为自己项目的分布式缓存了。\n4. 缓存数据的处理流程是怎样的？ 作为暖男一号，我给大家画了一个草图。\ngraph TD A[User] --\u0026gt;|Query data| B{In cache} B --\u0026gt;|Y|C[Return data] B --\u0026gt;|N|D{In DB} D --\u0026gt;|Y|E[Update cache] --\u0026gt;C D --\u0026gt;|N|F[Return null] 简单来说就是:\n 如果用户请求的数据在缓存中就直接返回。 缓存中不存在的话就看数据库中是否存在。 数据库中存在的话就更新缓存中的数据。 数据库中不存在的话就返回空数据。  5. 为什么要用 Redis/为什么要用缓存？ 简单，来说使用缓存主要是为了提升用户体验以及应对更多的用户。\n下面我们主要从“高性能”和“高并发”这两点来看待这个问题。\ngraph TD A[User] --\u0026gt;|Load Balance| B(nginx) B --\u0026gt;|1|C[Business 1] B --\u0026gt;|2|D[Business 2] C \u0026amp; D--\u0026gt;E[(Cache)] E --\u0026gt; F[(DataBase)] 高性能 ：\n对照上面 👆 我画的图。我们设想这样的场景：\n假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。\n这样有什么好处呢？ 那就是保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。\n不过，要保持数据库和缓存中的数据的一致性。 如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！\n高并发：\n一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）。\n QPS（Query Per Second）：服务器每秒可以执行的查询次数；\n 所以，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高的系统整体的并发。\n6. Redis 常见数据结构以及使用场景分析 你可以自己本机安装 redis 或者通过 redis 官网提供的在线 redis 环境。\n6.1. string  介绍 ：string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 简单动态字符串（simple dynamic string，SDS）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的 SDS API 是安全的，不会造成缓冲区溢出。 常用命令: set,get,strlen,exists,dect,incr,setex 等等。 应用场景 ：一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。  下面我们简单看看它的使用！\n普通字符串的基本操作：\n1 2 3 4 5 6 7 8 9 10 11 12  127.0.0.1:6379\u0026gt; set key value #设置 key-value 类型的值 OK 127.0.0.1:6379\u0026gt; get key # 根据 key 获得对应的 value \u0026#34;value\u0026#34; 127.0.0.1:6379\u0026gt; exists key # 判断某个 key 是否存在 (integer) 1 127.0.0.1:6379\u0026gt; strlen key # 返回 key 所储存的字符串值的长度。 (integer) 5 127.0.0.1:6379\u0026gt; del key # 删除某个 key 对应的值 (integer) 1 127.0.0.1:6379\u0026gt; get key (nil)   批量设置 :\n1 2 3 4 5  127.0.0.1:6379\u0026gt; mset key1 value1 key2 value2 # 批量设置 key-value 类型的值 OK 127.0.0.1:6379\u0026gt; mget key1 key2 # 批量获取多个 key 对应的 value 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34;   计数器（字符串的内容为整数的时候可以使用）：\n1 2 3 4 5 6 7 8 9 10 11  127.0.0.1:6379\u0026gt; set number 1 OK 127.0.0.1:6379\u0026gt; incr number # 将 key 中储存的数字值增一 (integer) 2 127.0.0.1:6379\u0026gt; get number \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; decr number # 将 key 中储存的数字值减一 (integer) 1 127.0.0.1:6379\u0026gt; get number \u0026#34;1\u0026#34;   过期：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; expire key 60 # 数据在 60s 后过期 (integer) 1 127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) OK 127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期 (integer) 56   6.2. list  介绍 ：list 即是 链表。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 LinkedList，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。 常用命令: rpush,lpop,lpush,rpop,lrange、llen 等。 应用场景: 发布与订阅或者说消息队列、慢查询。  下面我们简单看看它的使用！\n通过 rpush/lpop 实现队列：\n1 2 3 4 5 6 7 8 9 10 11 12  127.0.0.1:6379\u0026gt; rpush myList value1 # 向 list 的头部（右边）添加元素 (integer) 1 127.0.0.1:6379\u0026gt; rpush myList value2 value3 # 向list的头部（最右边）添加多个元素 (integer) 3 127.0.0.1:6379\u0026gt; lpop myList # 将 list的尾部(最左边)元素取出 \u0026#34;value1\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) \u0026#34;value2\u0026#34; 2) \u0026#34;value3\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) \u0026#34;value2\u0026#34; 2) \u0026#34;value3\u0026#34;   通过 rpush/rpop 实现栈：\n1 2 3 4  127.0.0.1:6379\u0026gt; rpush myList2 value1 value2 value3 (integer) 3 127.0.0.1:6379\u0026gt; rpop myList2 # 将 list的头部(最右边)元素取出 \u0026#34;value3\u0026#34;   我专门花了一个图方便小伙伴们来理解：\n通过 lrange 查看对应下标范围的列表元素：\n1 2 3 4 5 6 7 8 9  127.0.0.1:6379\u0026gt; rpush myList value1 value2 value3 (integer) 3 127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value3\u0026#34;   通过 lrange 命令，你可以基于 list 实现分页查询，性能非常高！\n通过 llen 查看链表长度：\n1 2  127.0.0.1:6379\u0026gt; llen myList (integer) 3   6.3. hash  介绍 ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。 常用命令： hset,hmset,hexists,hget,hgetall,hkeys,hvals 等。 应用场景: 系统中对象数据的存储。  下面我们简单看看它的使用！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;guide\u0026#34; description \u0026#34;dev\u0026#34; age \u0026#34;24\u0026#34; OK 127.0.0.1:6379\u0026gt; hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。 (integer) 1 127.0.0.1:6379\u0026gt; hget userInfoKey name # 获取存储在哈希表中指定字段的值。 \u0026#34;guide\u0026#34; 127.0.0.1:6379\u0026gt; hget userInfoKey age \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值 1) \u0026#34;name\u0026#34; 2) \u0026#34;guide\u0026#34; 3) \u0026#34;description\u0026#34; 4) \u0026#34;dev\u0026#34; 5) \u0026#34;age\u0026#34; 6) \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hkeys userInfoKey # 获取 key 列表 1) \u0026#34;name\u0026#34; 2) \u0026#34;description\u0026#34; 3) \u0026#34;age\u0026#34; 127.0.0.1:6379\u0026gt; hvals userInfoKey # 获取 value 列表 1) \u0026#34;guide\u0026#34; 2) \u0026#34;dev\u0026#34; 3) \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;GuideGeGe\u0026#34; # 修改某个字段对应的值 127.0.0.1:6379\u0026gt; hget userInfoKey name \u0026#34;GuideGeGe\u0026#34;   6.4. set  介绍 ： set 类似于 Java 中的 HashSet 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。 常用命令： sadd,spop,smembers,sismember,scard,sinterstore,sunion 等。 应用场景: 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景  下面我们简单看看它的使用！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  127.0.0.1:6379\u0026gt; sadd mySet value1 value2 # 添加元素进去 (integer) 2 127.0.0.1:6379\u0026gt; sadd mySet value1 # 不允许有重复元素 (integer) 0 127.0.0.1:6379\u0026gt; smembers mySet # 查看 set 中所有的元素 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; scard mySet # 查看 set 的长度 (integer) 2 127.0.0.1:6379\u0026gt; sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素 (integer) 1 127.0.0.1:6379\u0026gt; sadd mySet2 value2 value3 (integer) 2 127.0.0.1:6379\u0026gt; sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中 (integer) 1 127.0.0.1:6379\u0026gt; smembers mySet3 1) \u0026#34;value2\u0026#34;   6.5. sorted set  介绍： 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。 常用命令： zadd,zcard,zscore,zrange,zrevrange,zrem 等。 应用场景： 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  127.0.0.1:6379\u0026gt; zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重 (integer) 1 127.0.0.1:6379\u0026gt; zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素 (integer) 2 127.0.0.1:6379\u0026gt; zcard myZset # 查看 sorted set 中的元素数量 (integer) 3 127.0.0.1:6379\u0026gt; zscore myZset value1 # 查看某个 value 的权重 \u0026#34;3\u0026#34; 127.0.0.1:6379\u0026gt; zrange myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素 1) \u0026#34;value3\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value1\u0026#34; 127.0.0.1:6379\u0026gt; zrange myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start 1 为 stop 1) \u0026#34;value3\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; zrevrange myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start 1 为 stop 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34;   7. Redis 单线程模型详解 Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型 （Netty 的线程模型也基于 Reactor 模式，Reactor 模式不愧是高性能 IO 的基石），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。\n既然是单线程，那怎么监听大量的客户端连接呢？\nRedis 通过IO 多路复用程序 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发生。\n这样的好处非常明显： I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像）。\n另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件： 1. 文件事件; 2. 时间事件。\n时间事件不需要多花时间了解，我们接触最多的还是 文件事件（客户端进行读取写入等操作，涉及一系列网络通信）。\n《Redis 设计与实现》有一段话是如是介绍文件事件的，我觉得写得挺不错。\n Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据 套接字目前执行的任务来为套接字关联不同的事件处理器。\n当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。\n虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n 可以看出，文件事件处理器（file event handler）主要是包含 4 个部分：\n 多个 socket（客户端连接） IO 多路复用程序（支持多个客户端连接的关键） 文件事件分派器（将 socket 关联到相应的事件处理器） 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）  《Redis设计与实现：12章》\n8. Redis 没有使用多线程？为什么不使用多线程？ 虽然说 Redis 是单线程模型，但是， 实际上，Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。\n不过，Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理”。\n大体上来说，Redis 6.0 之前主要还是单线程处理。\n那，Redis6.0 之前 为什么不使用多线程？\n我觉得主要原因有下面 3 个：\n 单线程编程容易并且更容易维护； Redis 的性能瓶颈不再 CPU ，主要在内存和网络； 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。  9. Redis6.0 之后为何引入了多线程？ Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。\n虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。\nRedis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis 配置文件 redis.conf ：\n1  io-threads-do-reads yes   开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 redis.conf :\n1  io-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程   推荐阅读：\n Redis 6.0 新特性-多线程连环 13 问！ 为什么 Redis 选择单线程模型  10. Redis 给缓存数据设置过期时间有啥用？ 一般情况下，我们设置保存的缓存数据的时候都会设置一个过期时间。为什么呢？\n因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接Out of memory。\nRedis 自带了给缓存数据设置过期时间的功能，比如：\n1 2 3 4 5 6  127.0.0.1:6379\u0026gt; exp key 60 # 数据在 60s 后过期 (integer) 1 127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) OK 127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期 (integer) 56   注意：**Redis中除了字符串类型有自己独有设置过期时间的命令 setex 外，其他方法都需要依靠 expire 命令来设置过期时间 。另外， persist 命令可以移除一个键的过期时间： **\n过期时间除了有助于缓解内存的消耗，还有什么其他用么？\n很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在1分钟内有效，用户登录的 token 可能只在 1 天内有效。\n如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。\n11. Redis是如何判断数据是否过期的呢？ Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。\n过期字典是存储在redisDb这个结构里的：\n1 2 3 4 5 6 7  typedef struct redisDb { ... dict *dict; //数据库键空间,保存着数据库中所有键值对  dict *expires // 过期字典,保存着键的过期时间  ... } redisDb;   12. 过期的数据的删除策略了解么？ 如果假设你设置了一批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进行删除的呢？\n常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：\n 惰性删除 ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。 定期删除 ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。  定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采用的是 定期删除+惰性/懒汉式删除 。\n但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。\n怎么解决这个问题呢？答案就是： Redis 内存淘汰机制。\n13. Redis 内存淘汰机制了解么？  相关问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?\n Redis 提供 6 种数据淘汰策略：\n volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的） allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！  4.0 版本后增加以下两种：\nvolatile-lfu（least frequently used）：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key  14. Redis 持久化机制(怎么保证 Redis 挂掉之后再重启数据可以进行恢复) 很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。\nRedis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持两种不同的持久化操作。Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）。这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。\n快照（snapshotting）持久化（RDB）\nRedis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。\n快照持久化是 Redis 默认采用的持久化方式，在 Redis.conf 配置文件中默认有此下配置：\nsave 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 AOF（append-only file）持久化\n与快照持久化相比，AOF 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：\nappendonly yes 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。\n在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：\nappendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度 appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘 appendfsync no #让操作系统决定何时进行同步 为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。\n相关 issue ：783：Redis 的 AOF 方式\n拓展：Redis 4.0 对于持久化机制的优化\nRedis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。\n如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。\n补充内容：AOF 重写\nAOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。\nAOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。\n在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作\n15. Redis 事务 Redis 可以通过 MULTI，EXEC，DISCARD 和 WATCH 等命令来实现事务(transaction)功能。\n1 2 3 4 5 6 7 8 9  \u0026gt; MULTI OK \u0026gt; INCR foo QUEUED \u0026gt; INCR bar QUEUED \u0026gt; EXEC 1) (integer) 1 2) (integer) 1   使用 MULTI命令后可以输入多个命令。Redis不会立即执行这些命令，而是将它们放到队列，当调用了EXEC命令将执行所有命令。\nRedis官网相关介绍 https://redis.io/topics/transactions 如下：\n但是，Redis 的事务和我们平时理解的关系型数据库的事务不同。我们知道事务具有四大特性： 1. 原子性，2. 隔离性，3. 持久性，4. 一致性。\n 原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；  Redis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。\nRedis官网也解释了自己为啥不支持回滚。简单来说就是Redis开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。\n你可以将Redis中的事务就理解为 ：Redis事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。\n相关issue :issue452: 关于 Redis 事务不满足原子性的问题 ，推荐阅读：https://zhuanlan.zhihu.com/p/43897838 。\n16. 缓存穿透 16.1. 什么是缓存穿透？ 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。\n16.2. 缓存穿透情况的处理流程是怎样的？ 如下图所示，用户的请求最终都要跑到数据库中查询一遍。\ngraph TD A[User] --\u0026gt;|Query data|B{In cache} B --\u0026gt;|N|C[(DataBase)] 16.3. 有哪些解决办法？ 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。\n1）缓存无效 key\n如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。\n另外，这里多说一嘴，一般情况下我们是这样设计 key 的： 表名:列名:主键名:主键值 。\n如果用 Java 代码展示的话，差不多是下面这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public Object getObjectInclNullById(Integer id) { // 从缓存中获取数据  Object cacheValue = cache.get(id); // 缓存为空  if (cacheValue == null) { // 从数据库中获取  Object storageValue = storage.get(key); // 缓存空对象  cache.set(key, storageValue); // 如果存储数据为空，需要设置一个过期时间(300秒)  if (storageValue == null) { // 必须设置过期时间，否则有被攻击的风险  cache.expire(key, 60 * 5); } return storageValue; } return cacheValue; }   2）布隆过滤器\n布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。\n具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。\n加入布隆过滤器之后的缓存处理流程图如下。\ngraph TD A[User] --\u0026gt;|Query data|B{Bloom filter} B --\u0026gt;|valid key|C[Query Cache] B --\u0026gt;|unexist key|D([Return illegal request]) C --\u0026gt; F[Continue...] 但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。\n为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！\n我们先来看一下，当一个元素加入布隆过滤器中的时候，会进行哪些操作：\n 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。  我们再来看一下，当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：\n 对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。  然后，一定会出现这样一种情况：不同的字符串可能哈希出来的位置相同。 （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）\n更多关于布隆过滤器的内容可以看我的这篇原创：《不了解布隆过滤器？一文给你整的明明白白！》 ，强烈推荐，个人感觉网上应该找不到总结的这么明明白白的文章了。\n17. 缓存雪崩 17.1. 什么是缓存雪崩？ 我发现缓存雪崩这名字起的有点意思，哈哈。\n实际上，缓存雪崩描述的就是这样一个简单的场景：缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。\n举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。\n还有一种缓存雪崩的场景是：有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。 这样的情况，有下面几种解决办法：\n举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。\n17.2. 有哪些解决办法？ 针对 Redis 服务不可用的情况：\n 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 限流，避免同时处理大量的请求。  针对热点缓存失效的情况：\n 设置不同的失效时间比如随机设置缓存的失效时间。 缓存永不失效。  18. 如何保证缓存和数据库数据的一致性？ 细说的话可以扯很多，但是我觉得其实没太大必要（小声BB：很多解决方案我也没太弄明白）。我个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。\n下面单独对 Cache Aside Pattern（旁路缓存模式） 来聊聊。\nCache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。\n如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：\n 缓存失效时间变短（不推荐，治标不治本） ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。 增加cache更新重试机制（常用）： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可。  19. 参考  《Redis 开发与运维》 《Redis 设计与实现》 Redis 命令总结：http://Redisdoc.com/string/set.html 通俗易懂的 Redis 数据结构基础教程：https://juejin.im/post/5b53ee7e5188251aaa2d2e16 WHY Redis choose single thread (vs multi threads): https://medium.com/@jychen7/sharing-redis-single-thread-vs-multi-threads-5870bd44d153  点击查看原文\n","description":"此文总结了redis相关的基础性知识体系，但不包括redis主从、哨兵、集群相关内容","id":16,"section":"posts","tags":["redis"],"title":"redis必知必会(转)","uri":"http://wangy325.top/zh/posts/java/redis/redis-all/"},{"content":"海量数据处理以及缓存穿透这两个场景让我认识了 布隆过滤器 ，我查阅了一些资料来了解它，但是很多现成资料并不满足我的需求，所以就决定自己总结一篇关于布隆过滤器的文章。希望通过这篇文章让更多人了解布隆过滤器，并且会实际去使用它！\n下面我们将分为几个方面来介绍布隆过滤器：\n 什么是布隆过滤器？ 布隆过滤器的原理介绍。 布隆过滤器使用场景。 通过 Java 编程手动实现布隆过滤器。 利用Google开源的Guava中自带的布隆过滤器。 Redis 中的布隆过滤器。  1.什么是布隆过滤器？ 首先，我们需要了解布隆过滤器的概念。\n布隆过滤器（Bloom Filter）是一个叫做 Bloom 的老哥于1970年提出的。我们可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。\n布隆过滤器示意图:   位数组中的每个元素都只占用 1 bit ，并且每个元素只能是 0 或者 1。这样申请一个 100w 个元素的位数组只占用 1000000Bit / 8 = 125000 Byte = 125000/1024 kb ≈ 122kb 的空间。\n总结：一个名叫 Bloom 的人提出了一种来检索元素是否在给定大集合中的数据结构，这种数据结构是高效且性能很好的，但缺点是具有一定的错误识别率和删除难度。并且，理论情况下，添加到集合中的元素越多，误报的可能性就越大。\n2.布隆过滤器的原理介绍 当一个元素加入布隆过滤器中的时候，会进行如下操作：\n 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。  当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：\n 对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。  举个简单的例子：\n布隆过滤器hash计算:   如图所示，当字符串存储要加入到布隆过滤器中时，该字符串首先由多个哈希函数生成不同的哈希值，然后在对应的位数组的下表的元素设置为 1（当位数组初始化时 ，所有位置均为0）。当第二次存储相同字符串时，因为先前的对应位置已设置为 1，所以很容易知道此值已经存在（去重非常方便）。\n如果我们需要判断某个字符串是否在布隆过滤器中时，只需要对给定字符串再次进行相同的哈希计算，得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。\n不同的字符串可能哈希出来的位置相同，这种情况我们可以适当增加位数组大小或者调整我们的哈希函数。\n综上，我们可以得出：布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。\n3.布隆过滤器使用场景  判断给定数据是否存在：比如判断一个数字是否存在于包含大量数字的数字集中（数字集很大，5亿以上！）、 防止缓存穿透（判断请求的数据是否有效避免直接绕过缓存请求数据库）等等、邮箱的垃圾邮件过滤、黑名单功能等等。 去重：比如爬给定网址的时候对已经爬取过的 URL 去重。  4.通过 Java 编程手动实现布隆过滤器 我们上面已经说了布隆过滤器的原理，知道了布隆过滤器的原理之后就可以自己手动实现一个了。\n如果你想要手动实现一个的话，你需要：\n 一个合适大小的位数组保存数据 几个不同的哈希函数 添加元素到位数组（布隆过滤器）的方法实现 判断给定元素是否存在于位数组（布隆过滤器）的方法实现。  下面给出一个我觉得写的还算不错的代码（参考网上已有代码改进得到，对于所有类型对象皆适用）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  import java.util.BitSet; public class MyBloomFilter { /** * 位数组的大小 */ private static final int DEFAULT_SIZE = 2 \u0026lt;\u0026lt; 24; /** * 通过这个数组可以创建 6 个不同的哈希函数 */ private static final int[] SEEDS = new int[]{3, 13, 46, 71, 91, 134}; /** * 位数组。数组中的元素只能是 0 或者 1 */ private BitSet bits = new BitSet(DEFAULT_SIZE); /** * 存放包含 hash 函数的类的数组 */ private SimpleHash[] func = new SimpleHash[SEEDS.length]; /** * 初始化多个包含 hash 函数的类的数组，每个类中的 hash 函数都不一样 */ public MyBloomFilter() { // 初始化多个不同的 Hash 函数  for (int i = 0; i \u0026lt; SEEDS.length; i++) { func[i] = new SimpleHash(DEFAULT_SIZE, SEEDS[i]); } } /** * 添加元素到位数组 */ public void add(Object value) { for (SimpleHash f : func) { bits.set(f.hash(value), true); } } /** * 判断指定元素是否存在于位数组 */ public boolean contains(Object value) { boolean ret = true; for (SimpleHash f : func) { ret = ret \u0026amp;\u0026amp; bits.get(f.hash(value)); } return ret; } /** * 静态内部类。用于 hash 操作！ */ public static class SimpleHash { private int cap; private int seed; public SimpleHash(int cap, int seed) { this.cap = cap; this.seed = seed; } /** * 计算 hash 值 */ public int hash(Object value) { int h; return (value == null) ? 0 : Math.abs(seed * (cap - 1) \u0026amp; ((h = value.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16))); } } }   测试：\n1 2 3 4 5 6 7 8 9  String value1 = \u0026#34;https://javaguide.cn/\u0026#34;; String value2 = \u0026#34;https://github.com/Snailclimb\u0026#34;; MyBloomFilter filter = new MyBloomFilter(); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2)); filter.add(value1); filter.add(value2); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2));   Output:\nfalse false true true 测试：\n1 2 3 4 5 6 7 8 9  Integer value1 = 13423; Integer value2 = 22131; MyBloomFilter filter = new MyBloomFilter(); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2)); filter.add(value1); filter.add(value2); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2));   Output:\n1 2 3 4  false false true true   5.利用Google开源的 Guava中自带的布隆过滤器 自己实现的目的主要是为了让自己搞懂布隆过滤器的原理，Guava 中布隆过滤器的实现算是比较权威的，所以实际项目中我们不需要手动实现一个布隆过滤器。\n首先我们需要在项目中引入 Guava 的依赖：\n1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;28.0-jre\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   实际使用如下：\n我们创建了一个最多存放 最多 1500个整数的布隆过滤器，并且我们可以容忍误判的概率为百分之（0.01）\n1 2 3 4 5 6 7 8 9 10 11 12 13  // 创建布隆过滤器对象 BloomFilter\u0026lt;Integer\u0026gt; filter = BloomFilter.create( Funnels.integerFunnel(), 1500, 0.01); // 判断指定元素是否存在 System.out.println(filter.mightContain(1)); System.out.println(filter.mightContain(2)); // 将元素添加进布隆过滤器 filter.put(1); filter.put(2); System.out.println(filter.mightContain(1)); System.out.println(filter.mightContain(2));   在我们的示例中，当mightContain（） 方法返回true时，我们可以99％确定该元素在过滤器中，当过滤器返回false时，我们可以100％确定该元素不存在于过滤器中。\nGuava 提供的布隆过滤器的实现还是很不错的（想要详细了解的可以看一下它的源码实现），但是它有一个重大的缺陷就是只能单机使用（另外，容量扩展也不容易），而现在互联网一般都是分布式的场景。为了解决这个问题，我们就需要用到 Redis 中的布隆过滤器了。\n6.Redis 中的布隆过滤器 6.1介绍 Redis v4.0 之后有了 Module（模块/插件） 功能，Redis Modules 让 Redis 可以使用外部模块扩展其功能 。布隆过滤器就是其中的 Module。详情可以查看 Redis 官方对 Redis Modules 的介绍 ：https://redis.io/modules\n另外，官网推荐了一个 RedisBloom 作为 Redis 布隆过滤器的 Module,地址：https://github.com/RedisBloom/RedisBloom. 其他还有：\n redis-lua-scaling-bloom-filter （lua 脚本实现）：https://github.com/erikdubbelboer/redis-lua-scaling-bloom-filter pyreBloom（Python中的快速Redis 布隆过滤器） ：https://github.com/seomoz/pyreBloom \u0026hellip;\u0026hellip;  RedisBloom 提供了多种语言的客户端支持，包括：Python、Java、JavaScript 和 PHP。\n6.2使用Docker安装 如果我们需要体验 Redis 中的布隆过滤器非常简单，通过 Docker 就可以了！我们直接在 Google 搜索docker redis bloomfilter 然后在排除广告的第一条搜素结果就找到了我们想要的答案（这是我平常解决问题的一种方式，分享一下），具体地址：https://hub.docker.com/r/redislabs/rebloom/ （介绍的很详细 ）。\n具体操作如下：\n1 2 3 4  ➜ ~ docker run -p 6379:6379 --name redis-redisbloom redislabs/rebloom:latest ➜ ~ docker exec -it redis-redisbloom bash root@21396d02c252:/data# redis-cli 127.0.0.1:6379\u0026gt;   6.3常用命令一览  注意： key:布隆过滤器的名称，item : 添加的元素。\n  BF.ADD ：将元素添加到布隆过滤器中，如果该过滤器尚不存在，则创建该过滤器。格式：BF.ADD {key} {item}。 BF.MADD  : 将一个或多个元素添加到“布隆过滤器”中，并创建一个尚不存在的过滤器。该命令的操作方式BF.ADD与之相同，只不过它允许多个输入并返回多个值。格式：BF.MADD {key} {item} [item ...] 。 BF.EXISTS : 确定元素是否在布隆过滤器中存在。格式：BF.EXISTS {key} {item}。 BF.MEXISTS ： 确定一个或者多个元素是否在布隆过滤器中存在格式：BF.MEXISTS {key} {item} [item ...]。  另外，BF.RESERVE 命令需要单独介绍一下：\n这个命令的格式如下：\nBF.RESERVE {key} {error_rate} {capacity} [EXPANSION expansion] 。\n下面简单介绍一下每个参数的具体含义：\n key：布隆过滤器的名称 error_rate :误报的期望概率。这应该是介于0到1之间的十进制值。例如，对于期望的误报率0.1％（1000中为1），error_rate应该设置为0.001。该数字越接近零，则每个项目的内存消耗越大，并且每个操作的CPU使用率越高。 capacity: 过滤器的容量。当实际存储的元素个数超过这个值之后，性能将开始下降。实际的降级将取决于超出限制的程度。随着过滤器元素数量呈指数增长，性能将线性下降。  可选参数：\n expansion：如果创建了一个新的子过滤器，则其大小将是当前过滤器的大小乘以expansion。默认扩展值为2。这意味着每个后续子过滤器将是前一个子过滤器的两倍。  6.4实际使用 1 2 3 4 5 6 7 8 9 10  127.0.0.1:6379\u0026gt; BF.ADD myFilter java (integer) 1 127.0.0.1:6379\u0026gt; BF.ADD myFilter javaguide (integer) 1 127.0.0.1:6379\u0026gt; BF.EXISTS myFilter java (integer) 1 127.0.0.1:6379\u0026gt; BF.EXISTS myFilter javaguide (integer) 1 127.0.0.1:6379\u0026gt; BF.EXISTS myFilter github (integer) 0   点击查看原文\n","description":"本文介绍了布隆过滤器的原理，并用Java语言实现了简单的布隆过滤器。","id":17,"section":"posts","tags":["bloomfilter"],"title":"布隆过滤器(转)","uri":"http://wangy325.top/zh/posts/java/redis/bloom-filter/"},{"content":"Java 1.5以后的并发类库新加入了一些用于解决并发问题的新构件，合理地使用这些构件能够帮助我们写出更加简单且健壮的并发程序。本节内容介绍java.util.concurrent包中一些具有代表性的构件，包括\n CountDownLatch CyclicBarrier Semaphore Exchanger DelayQueue PriorityBlockingQueue  1 CountDownLatch 在讨论线程的基本概念时，我们说过join()方法可使当前线程等待调用join方法的线程执行完，可以实现简单的无锁同步，使用CountDownLatch可以更加简单的实现这一目的。毕竟，join()方法的语义“加入一个线程”不是很容易就能让人理解。相较于join()方法，CountDownLatch的语义就明确多了。\n在有些文档上，将CountDownLatch译为\u0026quot;倒计时门闩【shuān】\u0026quot;，其维护一个计数器，这个计数器在CountDownLatch初始化之后便不能重置。在CountDownLatch上调用countDown()方法来将计数值减1，调用这个方法并不会引起阻塞。不过，在这个计数器为0之前，任何调用CountDownLatch的await()方法的任务都将阻塞。\nCountDownLatch的典型用法是将一个任务分割为n个可以独立解决的部分，并创建一个计数器值为n的CountDownLatch，在每个任务完成时，调用countDown()方法将计数器减1，在等待所有任务完成的线程上调用await()方法，将任务阻塞，知道计数器为0之后再继续运行。\n下面的代码演示了CountdownLatch的用法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  public class CountDownLatchDemo { private static class TaskPortion implements Runnable { private static int counter = 0; private final int id = counter++; private static Random rand = new Random(47); private final CountDownLatch latch; TaskPortion(CountDownLatch latch) { this.latch = latch; } @Override public void run() { try { doWork(); } catch (InterruptedException ex) { // Acceptable way to exit  } finally { latch.countDown(); } } void doWork() throws InterruptedException { TimeUnit.MILLISECONDS.sleep(rand.nextInt(2000)); System.out.println(this + \u0026#34;completed\u0026#34;); } @Override public String toString() { return String.format(\u0026#34;%1$-3d \u0026#34;, id); } } /** Waits on the CountDownLatch: */ private static class WaitingTask implements Runnable { private static int counter = 0; private final int id = counter++; private final CountDownLatch latch; WaitingTask(CountDownLatch latch) { this.latch = latch; } @Override public void run() { try { latch.await(); System.out.println(\u0026#34;Latch barrier passed for \u0026#34; + this); } catch (InterruptedException ex) { System.out.println(this + \u0026#34; interrupted\u0026#34;); } } @Override public String toString() { return String.format(\u0026#34;WaitingTask %1$-3d \u0026#34;, id); } } static final int SIZE = 10; public static void main(String[] args) { ExecutorService exec = Executors.newCachedThreadPool(); // 所有任务都必须使用同一个CountDownLatch对象  CountDownLatch latch = new CountDownLatch(SIZE); exec.execute(new WaitingTask(latch)); for (int i = 0; i \u0026lt; SIZE; i++) { exec.execute(new TaskPortion(latch)); } System.out.println(\u0026#34;Launched all tasks\u0026#34;); exec.shutdown(); // Quit when all tasks complete  } } /* output (sample) Launched all tasks 7 completed 9 completed 5 completed 8 completed 1 completed 2 completed 6 completed 4 completed 0 completed 3 completed Latch barrier passed for WaitingTask 0 *///:~   上面的示例中，WaitingTask将会阻塞，直到所有的TaskPortion执行完成，TaskPortion完成之后调用了countDown()方法，注意，countDown()方法是在finally块中调用的，这是为了防止TaskPortion出现异常而导致任务一直阻塞。当计数器为0后，我们看到WaitingTask成功执行。\nawait()还有一个重载方法await(long, TimeUnit)，避免任务让线程一直等待。\n2 CyclicBarrier CyclicBarrier被称为“同步屏障”，事实上就可以把它理解为一个屏障，多个任务调用屏障的await()方法将被阻塞，直到所有的任务都进入阻塞，那么屏障开启，所有任务继续执行。这看起来和CountDownLatch非常像，不过CountDownLatch只能触发一次，而CyclicBarrier可以多次重用，这是它们的主要区别之一。\n和CountDownLatch一样，CyclicBarrier接受一个整型参数，表示可限制的线程数。除此之外，CyclicBarrier还可以接受一个Runnable作为参数，这个参数称作barrierAction，barrierAction在所有线程到达屏障之后即开始执行，其他任务只能等待barrierAction执行完毕之后才能继续执行，这是CyclicBarrier和CountDownLatch的区别之二。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  public class TestCyclicBarrier { private static StringBuffer sb = new StringBuffer(); /** CyclicBarrier的构造器任务总是会先执行完毕 */ static CyclicBarrier c = new CyclicBarrier(2, () -\u0026gt; { sb.append(3); }); private static final int ASSERT_VALUE = 312; static int run() { Thread t = new Thread(() -\u0026gt; { try { c.await(); } catch (Exception e) { // ignore;  } sb.append(1); }); t.start(); try { c.await(); sb.append(2); t.join(); } catch (Exception e) { // ignore  } return Integer.parseInt(sb.toString()) | (sb.delete(0, sb.length())).length(); } public static void main(String[] args) { for (; ; ) { int r; if ((r = run()) != ASSERT_VALUE) { // should be 321  System.out.println(r); return; } } } }   上例中，barrier有一个barrierAction和2个“屏障任务”，main方法的输出大概率为312，小概率为321，不会出现其他结果，所以main方法无论执行多长时间，其总会结束。由于barrierAction总是先执行，故结果总是3xx1，其先执行完毕的原因在源码中很容易找到：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  //... // 所有任务到达屏障 if (index == 0) { // tripped boolean ranAction = false; try { final Runnable command = barrierCommand; //直接在当前线程调用command的run方法  if (command != null) command.run(); ranAction = true; nextGeneration(); return 0; } finally { if (!ranAction) breakBarrier(); } } //...   不过，屏障开启后，任务的执行顺序完全是由cpu调度的。同时，本例中的CyclicBarrier是静态域，在main方法重复执行时，并不会重新初始化，因此也直接证明了CyclicBarrier的可重用性——屏障开启后，任务继续执行后调用屏障的await()方法同样会阻塞而等待所有任务到达屏障，依次循环。\n下例的“赛马游戏”2完美地阐述了CyclicBarrier可以多次重用的特点，马每次跑一步，不过不同的马步长不同，等待所有的马都“跑出这一步”后，屏障开启，先确定是否有马到达终点，如有则结束赛跑，否则继续下一轮，直到有马越过终点线，下面是示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97  public class HorseRace { static class Horse implements Runnable { private static int counter = 0; private final int id = counter++; private int strides = 0; private static Random rand = new Random(47); private static CyclicBarrier barrier; public Horse(CyclicBarrier b) { barrier = b; } public int getStrides() { return strides; } @Override public void run() { try { while (!Thread.interrupted()) { strides += rand.nextInt(3); // Produces 0, 1 or 2  barrier.await(); } } catch (InterruptedException e) { // A legitimate way to exit  } catch (BrokenBarrierException e) { // This one we want to know about  throw new RuntimeException(e); } } @Override public String toString() { return \u0026#34;Horse \u0026#34; + id + \u0026#34; \u0026#34;; } public String tracks() { StringBuilder s = new StringBuilder(); for (int i = 0; i \u0026lt; getStrides(); i++) { s.append(\u0026#34;*\u0026#34;); } s.append(id); return s.toString(); } } static final int FINISH_LINE = 20; private List\u0026lt;Horse\u0026gt; horses = new ArrayList\u0026lt;\u0026gt;(); private ExecutorService exec = Executors.newCachedThreadPool(); private CyclicBarrier barrier; /** 这是一构造器 */ public HorseRace(int nHorses, final int pause) { barrier = new CyclicBarrier(nHorses, () -\u0026gt; { StringBuilder s = new StringBuilder(); for (int i = 0; i \u0026lt; FINISH_LINE; i++) { s.append(\u0026#34;=\u0026#34;); // The fence on the racetrack  } System.out.println(s); for (Horse horse : horses) { System.out.println(horse.tracks()); } for (Horse horse : horses) { if (horse.getStrides() \u0026gt;= FINISH_LINE) { System.out.println(horse + \u0026#34;won!\u0026#34;); exec.shutdownNow(); return; } } try { TimeUnit.MILLISECONDS.sleep(pause); } catch (InterruptedException e) { System.out.println(\u0026#34;barrier-action sleep interrupted\u0026#34;); } }); for (int i = 0; i \u0026lt; nHorses; i++) { Horse horse = new Horse(barrier); horses.add(horse); exec.execute(horse); } } public static void main(String[] args) { int nHorses = 7; int pause = 200; if (args.length \u0026gt; 0) { // Optional argument  int n = new Integer(args[0]); nHorses = n \u0026gt; 0 ? n : nHorses; } if (args.length \u0026gt; 1) { // Optional argument  int p = new Integer(args[1]); pause = p \u0026gt; -1 ? p : pause; } new HorseRace(nHorses, pause); } }   实际上程序通过获取每匹马的strides域来判断马是否到达终点。在TIJ原书中，对strides域的有关操作做了同步处理，而本例中移除了这些同步，这是否安全？虽然CyclicBarrier的barrierAction和HorseRace都访问了strides域，不过，二者访问域的时间一定是错开的：前者在所有马都到达屏障后开始访问，而此时的马处于阻塞状态，而马获得访问权时，barrierAction一定没在执行。因此本例中，不使用同步也是安全的。\nCyclicBarrier还有一些特殊方法\n1 2 3 4 5 6 7 8 9 10  public void reset(); 这个方法将CyclicBarrier重置到初始状态 注意，这个方法会导致已经在屏障处等待的线程抛出BrokenBarrierException 如果确实需要一个新的CyclicBarrier来执行操作，新建一个实例是更好的选择 public int getNumberWaiting() ; 这个方法获取在屏障等待的线程数 public int getParties() ; 这个方法获取所有的线程数（用来构建CyclicBarrier实例的int入参）   下面的例子展示了在任务执行时重置CyclicBarrier的操作，这个示例只是为了展示上面几个方法的用法，千万不要在执行任务时贸然去做这样的操作！如果处理不得当将很大可能引发阻塞或其他并发问题。\n 笔者本意是计划执行批量任务，这些任务有一个域来计算其运行次数，并可能在某个任务上调用reset()方法，在reset()调用之前和之后的任务其运行次数会有差别，通过这个运行差异在barrierAction中来终结线程池。事实上这个预想完全落空了，reset()之后，如果不再次使所有线程重新到达屏障处等待，barrierAction就不可能执行\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109  public class ResetCyclicBarrier { static void reSetBarrierIf(int parties, int bound) { TaskMayFail[] tasks = new TaskMayFail[parties]; ThreadPoolExecutor exec = (ThreadPoolExecutor) Executors.newCachedThreadPool(); exec.setKeepAliveTime(0, TimeUnit.SECONDS); AtomicInteger ai = new AtomicInteger(); CyclicBarrier c2 = new CyclicBarrier(parties, () -\u0026gt; { // if reset barrier while task is running, the  // barrier action can not reach in this cycle  // until relaunch all parties to reach at barrier  // in next round  int i = 0; int r = tasks[i].runtime; while (i \u0026lt; parties) { if (r != tasks[i].runtime) { System.out.println(tasks[i] + \u0026#34;:\u0026#34; + tasks[i].runtime + \u0026#34;: \u0026#34; + r); exec.shutdownNow(); return; } r = tasks[i].runtime; i++; } }); for (int i = 0; i \u0026lt; parties; i++) { TaskMayFail taskMayFail = new TaskMayFail(c2, ai, bound); tasks[i] = taskMayFail; exec.execute(taskMayFail); } } private static class TaskMayFail implements Runnable { static Random rand = new Random(); static int count = 1; final CyclicBarrier cb; final AtomicInteger reSetCount; final int bound; final int id = count++; int runtime = 0; public TaskMayFail(CyclicBarrier cb, AtomicInteger reSetCount, int bound) { this.cb = cb; this.reSetCount = reSetCount; this.bound = bound; } @Override public String toString() { return \u0026#34;[TaskMayFail-\u0026#34; + id + \u0026#34;-runtime-\u0026#34; + runtime + \u0026#34;]\u0026#34;; } @Override public void run() { try { while (!Thread.currentThread().isInterrupted()) { if (rand.nextBoolean()) { // bound值可调整reset的概率  if (rand.nextInt(bound) == 0) { throw new ArithmeticException(); } } runtime++; cb.await(); } } catch (ArithmeticException ae) { reSetCount.incrementAndGet(); while (cb.getNumberWaiting() \u0026lt; (cb.getParties() - reSetCount.intValue())) { // waiting for all parties reach at barrier  // or all parties throws exception  } // reset barrier  cb.reset(); System.out.printf(\u0026#34;%s-%s reset %s%n\u0026#34;, Thread.currentThread().getName(), this, cb); } catch (InterruptedException | BrokenBarrierException ae) { reSetCount.incrementAndGet(); // once barrier reset, other parties wait on barrier  // will throw BrokenBarrierException  System.out.printf(\u0026#34;%s-%s return by broken barrier.%n\u0026#34;, Thread.currentThread().getName(), this); } finally { Thread.currentThread().interrupt(); } } public static void main(String[] args) { reSetBarrierIf(13, 100); } } } /* output (sample) pool-1-thread-3-[TaskMayFail-3-runtime-19] reset java.util.concurrent.CyclicBarrier@618bfe9a pool-1-thread-4-[TaskMayFail-4-runtime-20] return by broken barrier. pool-1-thread-9-[TaskMayFail-9-runtime-20] return by broken barrier. pool-1-thread-8-[TaskMayFail-8-runtime-20] return by broken barrier. pool-1-thread-5-[TaskMayFail-5-runtime-20] return by broken barrier. pool-1-thread-12-[TaskMayFail-12-runtime-20] return by broken barrier. pool-1-thread-7-[TaskMayFail-7-runtime-20] return by broken barrier. pool-1-thread-13-[TaskMayFail-13-runtime-20] return by broken barrier. pool-1-thread-1-[TaskMayFail-1-runtime-20] return by broken barrier. pool-1-thread-11-[TaskMayFail-11-runtime-20] return by broken barrier. pool-1-thread-2-[TaskMayFail-2-runtime-20] return by broken barrier. pool-1-thread-10-[TaskMayFail-10-runtime-20] return by broken barrier. pool-1-thread-6-[TaskMayFail-6-runtime-19] reset java.util.concurrent.CyclicBarrier@618bfe9a *///:~   从输出可以看到，CyclicBarrier可以重复使用。上例的设计很巧妙，因为屏障在开启之后，任务可能很快就进入抛出ArithmeticException而进入reset流程，而此时其他任务可能在屏障处等待或者还未执行，若此时贸然reset，那些等待的线程会抛出BrokenBarrierException并退出，但是未执行的线程并未意识到reset的发生（可以这么表述），依然进入阻塞，如果没有再次任务进入reset流程，程序很快将因为没有足够多的线程到达屏障而阻塞3。\n所以，上例引入一个原子变量，用于跟踪进入reset和已经退出的任务数，那么剩余的线程应该就是到达屏障的线程数，利用这个限制来保证所有的线程都得到处理，以简化问题的复杂性，一旦确定所有的线程都被处理，就可以执行reset()方法。同时reset()之后，barrierAction便无法执行。\n3 Semaphore 无论是显式锁还是通过synchronized关键字获取的隐式锁，其在任一时刻都只能让一个任务访问资源，而Semaphore（计数信号量）允许多个任务同时访问资源。可以把Semaphore看作是持有对象访问许可（permits）的“security”。访问对象时，须先通过acquire()获取许可，若此时没有许可可用，那么acquire()将阻塞，否则获取许可，可用许可数-1；使用完资源后，通过release()方法返还许可。事实上，并没有实际上的许可证对象，Semaphore通过协同各个线程工作，来达到目的。\nSemaphore的构造器接受一个“公平性参数”。不传入此参数或传入false时，线程获取许可的顺序无法保证，即使线程阻塞了很久，其仍然可能被刚调用acquire()方法的线程“抢走”许可，这可能会导致线程“饿死”。当传入true时，Semphore保证线程获取许可的顺序和其调用acquire()方法之后被执行的顺序一致4，也就是先执行的任务先获取许可（FIFO）。需要说明的是，tryAcquire()方法不遵循公平性原则，如果有许可可用，它直接获取之。在使用Semaphore时，一般将其设置为公平的\nSemaphore通常用于限制访问资源的线程数量，典型的例子就是控制“池”的并发访问量。下例中使用Semaphore控制池中的对象方法，当需要使用时，可以将它们“签出”（checkout），使用完毕之后再将其“签入”（checkin），使用泛型类封装功能5。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  class Pool\u0026lt;T\u0026gt; { private final int size; final List\u0026lt;T\u0026gt; items = new ArrayList\u0026lt;\u0026gt;(); private final boolean[] checkedOut; private final Semaphore available; public Pool(Class\u0026lt;T\u0026gt; classObject, int size) { this.size = size; checkedOut = new boolean[size]; available = new Semaphore(size, true); // Load pool with objects that can be checked out:  for (int i = 0; i \u0026lt; size; ++i) { try { // Assumes a default constructor:  items.add(classObject.newInstance()); } catch (Exception e) { throw new RuntimeException(e); } } } T checkOut() throws InterruptedException { available.acquire(); return getItem(); } void checkIn(T x) { if (releaseItem(x)) { available.release(); System.out.println(\u0026#34;release \u0026#34; + x); } } void checkAllIn() { available.release(releaseAll()); } private synchronized T getItem() { for (int i = 0; i \u0026lt; size; ++i) { if (!checkedOut[i]) { checkedOut[i] = true; return items.get(i); } } // Semaphore prevents reaching here  return null; } private synchronized boolean releaseItem(T item) { int index = items.indexOf(item); if (index == -1) { return false; // Not in the list  } if (checkedOut[index]) { checkedOut[index] = false; return true; } // Wasn\u0026#39;t checked out  return false; } private synchronized int releaseAll() { int r = 0; for (int i = 0; i \u0026lt; items.size(); i++) { if (checkedOut[i]) { checkedOut[i] = false; ++r; } } return r; } }   这个池使用checkout和checkIn方法来签出和签入对象，在签出对象之前调用acquire()，如果没有可用对象，那么checkOut将阻塞。由于Semaphore的机制，checkOut方法并不需要使用同步，但是getItem方法则需要同步了，Semaphore协同多线程对资源的访问，但是并不能保证多线程对资源修改的并发安全，这是两回事6。checkIn方法则判断给定对象是否被使用，是则签入之，否则不做任何操作，同样的，releaseItem方法也需要使用同步。\n The semaphore encapsulates the synchronization needed to restrict access to the pool, separately from\nany synchronization needed to maintain the consistency of the pool itself.\n 接下来我们可以测试这个池能否正常工作了:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129  public class SemaphoreDemo { private static class AcquireTask\u0026lt;T\u0026gt; implements Runnable { private static int counter = 0; private final int id = counter++; private final Pool\u0026lt;T\u0026gt; pool; public AcquireTask(Pool\u0026lt;T\u0026gt; pool) { this.pool = pool; } @Override public void run() { try { T item = pool.checkOut(); System.out.println(this + \u0026#34; acquire \u0026#34; + item); } catch (InterruptedException e) { // Acceptable way to terminate  } } @Override public String toString() { return \u0026#34;CheckoutTask-\u0026#34; + id; } } private static class ReleaseTask\u0026lt;T\u0026gt; implements Runnable { private static int counter = 0; private final int id = counter++; private final Pool\u0026lt;T\u0026gt; pool; public ReleaseTask(Pool\u0026lt;T\u0026gt; pool) { this.pool = pool; } @Override public void run() { try { List\u0026lt;T\u0026gt; items = pool.items; for (T item : items) { pool.checkIn(item); } } catch (Exception e) { // Acceptable way to terminate  } } @Override public String toString() { return \u0026#34;AcquireTask-\u0026#34; + id + \u0026#34; \u0026#34;; } } private static class Fat { private volatile double d; // Prevent optimization  private static int counter = 0; private final int id = counter++; public Fat() { // Expensive, interruptible operation:  for (int i = 1; i \u0026lt; 10000; i++) { d += (Math.PI + Math.E) / (double) i; } } @Override public String toString() { return \u0026#34;Fat-\u0026#34; + id; } } final static int SIZE = 5; private void test() throws InterruptedException { final Pool\u0026lt;Fat\u0026gt; pool = new Pool\u0026lt;\u0026gt;(Fat.class, SIZE); ExecutorService exec = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; SIZE; i++) { exec.execute(new AcquireTask\u0026lt;\u0026gt;(pool)); } exec.execute(new ReleaseTask\u0026lt;\u0026gt;(pool)); List\u0026lt;Fat\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; SIZE; i++) { Fat f = pool.checkOut(); System.out.println(i + \u0026#34;: main() acquire \u0026#34; + f); list.add(f); } Future\u0026lt;?\u0026gt; blocked = exec.submit(() -\u0026gt; { try { // Semaphore prevents additional checkout,  // so call is blocked:  pool.checkOut(); } catch (InterruptedException e) { System.out.println(\u0026#34;checkOut() Interrupted\u0026#34;); } }); TimeUnit.SECONDS.sleep(2); blocked.cancel(true); // Break out of blocked call  // release all items  pool.checkAllIn(); for (Fat f : list) { pool.checkIn(f); // Second checkIn ignored  } exec.shutdown(); } public static void main(String[] args) throws Exception { SemaphoreDemo semaphoreDemo = new SemaphoreDemo(); semaphoreDemo.test(); } } /* output(sample) AcquireTask-0 acquire Fat-0 AcquireTask-4 acquire Fat-4 AcquireTask-3 acquire Fat-3 AcquireTask-2 acquire Fat-2 AcquireTask-1 acquire Fat-1 release Fat-0 0: main() acquire Fat-0 release Fat-1 1: main() acquire Fat-1 release Fat-2 2: main() acquire Fat-2 release Fat-3 3: main() acquire Fat-3 release Fat-4 4: main() acquire Fat-4 checkOut() Interrupted *///:~   上例SemaphoreDemo有两个任务，分别用于签入签出对象，程序首先使用AcquireTask签出所有对象，接着使用ReleaseTask签入对象。主线程接着依次签出所有对象，可以看到，主线程的签出过程是被阻塞的，只有对象签入之后，才能被签出。主线程签出所有对象之后，由于没有签入任务，接着的签出任务一定是被阻塞的，主线程休眠2s后中断了阻塞的任务。\n4 Exchanger Exchanger是在两个任务之间交换对象的栅栏。当这些任务进入栅栏时，各自拥有一个对象，离开时交换它们拥有的对象。栅栏可以用来设计缓存对象，2个任务分别来使用和清空缓存，当缓存空间满时，则在Exchanger上交换缓存，缓存得以重复使用7。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  public class DataBuffer\u0026lt;T\u0026gt; { private Queue\u0026lt;T\u0026gt; buffer; /** 利用size构造一个有界队列 */ private final int size; public DataBuffer(Class\u0026lt;? extends Queue\u0026lt;T\u0026gt;\u0026gt; cls, int size) throws Exception { this(cls, size, null); } public DataBuffer(Class\u0026lt;? extends Queue\u0026lt;T\u0026gt;\u0026gt; cls, int size, Generator\u0026lt;T\u0026gt; gen) throws Exception { if (cls == null) throw new NullPointerException(); // 检查cls的类型，如果不是队列，则抛出异常  if (!Queue.class.isAssignableFrom(cls)) throw new ClassCastException(); if (size \u0026lt; 0) throw new IllegalArgumentException(); this.size = size; try { Constructor\u0026lt;? extends Queue\u0026lt;T\u0026gt;\u0026gt; c = cls.getConstructor(int.class); c.setAccessible(true); this.buffer = c.newInstance(size); } catch (NoSuchMethodException | SecurityException | InvocationTargetException e) { this.buffer = cls.newInstance(); } if (gen != null) { for (int i = 0; i \u0026lt; size; i++) buffer.offer(gen.next()); } } synchronized boolean isFull() { return buffer.size() \u0026gt;= size; } synchronized boolean isEmpty() { return buffer.isEmpty(); } synchronized int bufferSize() { return buffer.size(); } synchronized public Queue\u0026lt;T\u0026gt; getBuffer() { return buffer; } synchronized boolean addToBuffer(T t) { if (!isFull()) { return buffer.offer(t); } return false; } synchronized T takeFromBuffer() { if (!isEmpty()) { buffer.remove(); } return null; } }   DataBuffer接受一个Queue\u0026lt;T\u0026gt;类型参数，用来初始化缓存队列，并且利用size指定了缓存队列的容量，作为是“达到栅栏”的前置条件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112  public class BufferSwap { private class FillTask\u0026lt;T\u0026gt; implements Runnable { private DataBuffer\u0026lt;T\u0026gt; db; private final Exchanger\u0026lt;DataBuffer\u0026lt;T\u0026gt;\u0026gt; ex; private final Generator\u0026lt;T\u0026gt; gen; public FillTask(DataBuffer\u0026lt;T\u0026gt; db, Generator\u0026lt;T\u0026gt; gen, Exchanger\u0026lt;DataBuffer\u0026lt;T\u0026gt;\u0026gt; ex) { this.db = db; this.gen = gen; this.ex = ex; } @Override public void run() { try { while (db != null) { if (db.isFull()) { db = ex.exchange(db); } else { db.addToBuffer(gen.next()); } } } catch (InterruptedException e) { // right to exit here  } } } private class EmptyTask\u0026lt;T\u0026gt; implements Runnable { private DataBuffer\u0026lt;T\u0026gt; db; private final Exchanger\u0026lt;DataBuffer\u0026lt;T\u0026gt;\u0026gt; ex; private final int ecLimit; public EmptyTask(DataBuffer\u0026lt;T\u0026gt; db, Exchanger\u0026lt;DataBuffer\u0026lt;T\u0026gt;\u0026gt; ex, int limit) { this.db = db; this.ex = ex; this.ecLimit = limit; } @Override public void run() { try { while (ec.intValue() \u0026lt; ecLimit) { if (db.isEmpty()) { db = ex.exchange(db); ec.incrementAndGet(); } else { db.takeFromBuffer(); } } } catch (InterruptedException e) { // exit by interrupted  } } } /** 交换缓存的次数，用来限制程序的运行 */ private final AtomicInteger ec = new AtomicInteger(); /** * @param size the buffer size * @param limit the exchange time limit */ void test(int size, int limit) { Exchanger\u0026lt;DataBuffer\u0026lt;Fat\u0026gt;\u0026gt; xh = new Exchanger\u0026lt;\u0026gt;(); Generator\u0026lt;Fat\u0026gt; generator = BasicGenerator.create(Fat.class); // ignore class check  // can not solve the issue actually...  DataBuffer\u0026lt;Fat\u0026gt; fullBuffer, emptyBuffer; try { fullBuffer = new DataBuffer(ArrayBlockingQueue.class, size, generator); emptyBuffer = new DataBuffer(ArrayBlockingQueue.class, size); } catch (Exception e) { System.out.println(\u0026#34;initialization failure\u0026#34;); return; } ExecutorService pool = Executors.newCachedThreadPool(); Future\u0026lt;?\u0026gt; t1 = pool.submit(this.new FillTask(fullBuffer, generator, xh)); Future\u0026lt;?\u0026gt; done = pool.submit(this.new EmptyTask\u0026lt;\u0026gt;(emptyBuffer, xh, limit)); for (; ; ) { if (done.isDone()) { t1.cancel(true); break; } } pool.shutdown(); Queue\u0026lt;Fat\u0026gt; full = fullBuffer.getBuffer(); System.out.print(\u0026#34;fullTask\u0026#39;s buffer: \u0026#34;); for (Fat fat : full) { System.out.printf(\u0026#34;%s\\t\u0026#34;, fat); } System.out.println(); System.ocvnut.println(\u0026#34;++++++++++++++++++++++++++++++++\u0026#34;); Queue\u0026lt;Fat\u0026gt; empty = emptyBuffer.getBuffer(); System.out.print(\u0026#34;emptyTask\u0026#39;s buffer:\u0026#34;); for (Fat fat : empty) { System.out.printf(\u0026#34;%s\\t\u0026#34;, fat); } } public static void main(String[] args) { BufferSwap bs = new BufferSwap(); bs.test(10, 100); } } /* output fillTask\u0026#39;s buffer: Fat-1000\tFat-1001\tFat-1002\tFat-1003\tFat-1004\tFat-1005\tFat-1006\tFat-1007\tFat-1008\tFat-1009 ++++++++++++++++++++++++++++++++ emptyTask\u0026#39;s buffer: Fat-990\tFat-991\tFat-992\tFat-993\tFat-994\tFat-995\tFat-996\tFat-997\tFat-998\tFat-999 *///:~   BufferSwap中有2个任务，FillTask用来使用缓存，当缓存队列未满时，一直向缓存中添加对象，一旦缓存已满，则进入“栅栏”；而EmptyTask用来清空已满的缓存队列，知道缓存队列为空进入”栅栏”，同时为了限制缓存交换的次数，我们在缓存交换达到限制时停止EmptyTask。在test()方法中，我们初始化了2个缓存对象fullBuffer和emptyBuffer，前者会初始化一个满的缓存，后者则会初始化一个空的缓存。本例中传入的类型参数是ArrayBlockingQueue.class，并且忽略了类型检查8。\n之后提交这2个缓存任务，使用Future\u0026lt;?\u0026gt;来检查EmptyTask的状态并适时取消FillTask。这样做时可行的，因为FillTask一定会在最后一次交换之后继续使用而占满缓存空间进入“栅栏”处阻塞，使用Future.cancel()可以中断其阻塞并抛出中断异常，从而结束运行。随后重看2个任务阻塞队列中的对象，输出符合期望9。\n5 PriorityBlockingQueue 就是一个基础的可阻塞的优先级队列，当队列为空时，从队列中获取元素时被阻塞。其余特性和优先级队列是一致的。\n下例展示了如何构建一个可以放入优先级队列的任务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  public class PrioritizedTask implements Runnable, Comparable\u0026lt;PrioritizedTask\u0026gt; { protected static List\u0026lt;PrioritizedTask\u0026gt; sequence = new ArrayList\u0026lt;\u0026gt;(); private Random rand = new Random(47); private static int counter = 0; private final int id = counter++; private final int priority; public PrioritizedTask(int priority) { this.priority = priority; sequence.add(this); } @Override public int compareTo(PrioritizedTask arg) { return priority \u0026lt; arg.priority ? 1 : (priority \u0026gt; arg.priority ? -1 : 0); } @Override public void run() { try { TimeUnit.MILLISECONDS.sleep(rand.nextInt(250)); } catch (InterruptedException e) { // Acceptable way to exit  } System.out.println(this); } @Override public String toString() { return String.format(\u0026#34;[%1$-3d]\u0026#34;, priority) + \u0026#34; Task \u0026#34; + id; } public String summary() { return \u0026#34;(\u0026#34; + id + \u0026#34;:\u0026#34; + priority + \u0026#34;)\u0026#34;; } public static class EndSentinel extends PrioritizedTask { private ExecutorService exec; public EndSentinel(ExecutorService e) { super(-1); // Lowest priority in this program  exec = e; } @Override public void run() { int count = 0; for (PrioritizedTask pt : sequence) { System.out.print(pt.summary()); if (++count % 5 == 0) System.out.println(); } System.out.println(); System.out.println(this + \u0026#34; Calling shutdownNow()\u0026#34;); exec.shutdownNow(); } } }   PrioritizedTask实现了Runnable和Comparable接口，有一个int型priority域，用来表示任务的优先级，在compareTo方法中的逻辑表示，优先级高的将会优先出队。其还有一个静态域，用来记录所有任务被置入队列的顺序。PrioritizedTask有一个静态内部类，也是其子类，它被称作“结束哨兵”，它的优先级为-1，代表它会最后出队，当执行这个任务时，代表任务所有的任务执行完毕，可以关闭线程池资源。\n在接下来的示例中，将模拟生产者和消费者，执行PriorityBlockingQueue中的任务，我们可以从程序的输出观察优先级队列的出队（被执行）的顺序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  public class PriorityBlockingQueueDemo { static class PrioritizedTaskProducer implements Runnable { private Random rand = new Random(47); private Queue\u0026lt;Runnable\u0026gt; queue; private ExecutorService exec; public PrioritizedTaskProducer( Queue\u0026lt;Runnable\u0026gt; q, ExecutorService e) { queue = q; exec = e; // Used for EndSentinel  } @Override public void run() { // Unbounded queue; never blocks.  // Fill it up fast with random priorities:  for (int i = 0; i \u0026lt; 20; i++) { queue.add(new PrioritizedTask(rand.nextInt(10))); Thread.yield(); } // Trickle in highest-priority jobs:  try { for (int i = 0; i \u0026lt; 10; i++) { TimeUnit.MILLISECONDS.sleep(250); queue.add(new PrioritizedTask(10)); } // Add jobs, lowest priority first:  for (int i = 0; i \u0026lt; 10; i++) queue.add(new PrioritizedTask(i)); // A sentinel to stop all the tasks:  queue.add(new PrioritizedTask.EndSentinel(exec)); } catch (InterruptedException e) { // Acceptable way to exit  } System.out.println(\u0026#34;Finished PrioritizedTaskProducer\u0026#34;); } } static class PrioritizedTaskConsumer implements Runnable { private PriorityBlockingQueue\u0026lt;Runnable\u0026gt; q; public PrioritizedTaskConsumer( PriorityBlockingQueue\u0026lt;Runnable\u0026gt; q) { this.q = q; } @Override public void run() { try { while (!Thread.interrupted()) // Use current thread to run the task:  q.take().run(); } catch (InterruptedException e) { // Acceptable way to exit  } System.out.println(\u0026#34;Finished PrioritizedTaskConsumer\u0026#34;); } } public static void main(String[] args) throws Exception { ExecutorService exec = Executors.newCachedThreadPool(); PriorityBlockingQueue\u0026lt;Runnable\u0026gt; queue = new PriorityBlockingQueue\u0026lt;\u0026gt;(); exec.execute(new PrioritizedTaskProducer(queue, exec)); exec.execute(new PrioritizedTaskConsumer(queue)); } } /* output(partial) [9 ] Task 5 [9 ] Task 13 [9 ] Task 14 [8 ] Task 10 ... other 15 tasks [0 ] Task 18 [10 ] Task 20 ... other 7 tasks [10 ] Task 28 Finished PrioritizedTaskProducer [10 ] Task 29 ... other 9 tasks [0 ] Task 30 (0:8)(1:5)(2:3)(3:1)(4:1) (5:9)(6:8)(7:0)(8:2)(9:7) (10:8)(11:8)(12:1)(13:9)(14:9) (15:8)(16:8)(17:1)(18:0)(19:8) (20:10)(21:10)(22:10)(23:10)(24:10) (25:10)(26:10)(27:10)(28:10)(29:10) (30:0)(31:1)(32:2)(33:3)(34:4) (35:5)(36:6)(37:7)(38:8)(39:9) (40:-1) [-1 ] Task 40 Calling shutdownNow() Finished PrioritizedTaskConsumer *///:~   PrioritizedTaskProducer任务负责向队列添加40个任务，前20个任务不间断地添加进队，且随机0-10的优先级；后10个任务是间隔固定时间添加优先级为10的任务，最后10个任务不间断添加优先级递增到9的任务，最后添加\u0026quot;结束哨兵\u0026quot;任务，其将打印所有任务添加到队列的顺序。PrioritizedTaskConsumer则是不间断的尝试从队列中取出任务执行。从输出可以看到，队列中如果有优先级高的任务，它一定是先出队的。\n这个例子不需要任何显式同步，因为阻塞队列提供了所需的同步。\n6 DelayQueue DelayQueue是一个无界的阻塞队列，利用PriorityQueue实现，用于存放实现Delay接口10的对象，队列中的对象只能在其到期之后才能被取出。同时其还是一个有序队列，即队头的元素将最先到期，若没有任何元素到期，就不会有队头元素，poll()方法将返回null，因此DelayQueue不接受null作为元素。\n实际上，在了解了ScheduledThreadPoolExecutor.ScheduledFutureTask的出队规则之后，DelayQueue的出队的实现也就不言自明了——当leader被设置时，表明有任务即将出队，其他任务进入等待，该任务出队之后重置leader：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  // Delayqueue.take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { for (;;) { E first = q.peek(); if (first == null) available.await(); else { long delay = first.getDelay(NANOSECONDS); if (delay \u0026lt;= 0) return q.poll(); first = null; // don\u0026#39;t retain ref while waiting  if (leader != null) available.await(); else { Thread thisThread = Thread.currentThread(); leader = thisThread; try { available.awaitNanos(delay); } finally { if (leader == thisThread) leader = null; } } } } } finally { if (leader == null \u0026amp;\u0026amp; q.peek() != null) available.signal(); lock.unlock(); } }   下例展示了如何构造一个可以放入DelayQueue中的任务，这个示例的基本逻辑和PrioritizedTask相当：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102  public class DelayQueueDemo { private static class DelayedTask implements Runnable, Delayed { protected static List\u0026lt;DelayedTask\u0026gt; sequence = new ArrayList\u0026lt;\u0026gt;(); private static int counter = 0; private final int id = counter++; private final int delta; /** 到期时间 */ private final long trigger; public DelayedTask(int delayInMilliseconds) { delta = delayInMilliseconds; trigger = System.nanoTime() + NANOSECONDS.convert(delta, MILLISECONDS); sequence.add(this); } @Override public long getDelay(TimeUnit unit) { return unit.convert(trigger - System.nanoTime(), NANOSECONDS); } @Override public int compareTo(Delayed arg) { DelayedTask that = (DelayedTask) arg; if (trigger \u0026lt; that.trigger) return -1; if (trigger \u0026gt; that.trigger) return 1; return 0; } @Override public void run() { System.out.print(this + \u0026#34; \u0026#34;); } @Override public String toString() { return String.format(\u0026#34;[%1$-4d]\u0026#34;, delta) + \u0026#34; Task \u0026#34; + id; } public String summary() { return \u0026#34;(\u0026#34; + id + \u0026#34;:\u0026#34; + delta + \u0026#34;)\u0026#34;; } static class EndSentinel extends DelayedTask { private ExecutorService exec; public EndSentinel(int delay, ExecutorService e) { super(delay); exec = e; } @Override public void run() { System.out.println(); for (DelayedTask pt : sequence) { System.out.print(pt.summary() + \u0026#34; \u0026#34;); } System.out.println(); System.out.println(this + \u0026#34; Calling shutdownNow()\u0026#34;); exec.shutdownNow(); } } } static class DelayedTaskConsumer implements Runnable { private DelayQueue\u0026lt;DelayedTask\u0026gt; q; public DelayedTaskConsumer(DelayQueue\u0026lt;DelayedTask\u0026gt; q) { this.q = q; } @Override public void run() { try { while (!Thread.interrupted()) // Run task with the current thread  q.take().run(); } catch (InterruptedException e) { // Acceptable way to exit  } System.out.println(\u0026#34;Finished DelayedTaskConsumer\u0026#34;); } } public static void main(String[] args) { Random rand = new Random(47); ExecutorService exec = Executors.newCachedThreadPool(); DelayQueue\u0026lt;DelayedTask\u0026gt; queue = new DelayQueue\u0026lt;\u0026gt;(); // Fill with tasks that have random delays:  for (int i = 0; i \u0026lt; 20; i++) queue.put(new DelayedTask(rand.nextInt(5000))); // Set the stopping point  queue.add(new DelayedTask.EndSentinel(5000, exec)); exec.execute(new DelayedTaskConsumer(queue)); } } /* output（sample） [128 ] Task 11 [200 ] Task 7 [429 ] Task 5 [520 ] Task 18 [555 ] Task 1 [961 ] Task 4 [998 ] Task 16 [1207] Task 9 [1693] Task 2 [1809] Task 14 [1861] Task 3 [2278] Task 15 [3288] Task 10 [3551] Task 12 [4258] Task 0 [4258] Task 19 [4522] Task 8 [4589] Task 13 [4861] Task 17 [4868] Task 6 (0:4258) (1:555) (2:1693) (3:1861) (4:961) (5:429) (6:4868) (7:200) (8:4522) (9:1207) (10:3288) (11:128) (12:3551) (13:4589) (14:1809) (15:2278) (16:998) (17:4861) (18:520) (19:4258) (20:5000) [5000] Task 20 Calling shutdownNow() Finished DelayedTaskConsumer *///:~   从输出可以看到，任务入队的顺序和任务出队的顺序没有任何关系，任务是按照超时先后出队的。\n 这个示例演化自《Java并发编程的艺术》方腾飞等.著，第八章8.2节代码清单8-4。不过该书中关于这段代码的运行解释是不正确的，本例也证明了这一点。 \u0026#x21a9;\u0026#xfe0e;\n 《Thinking in Java》 4th Edition, 第21章21.7.2示例代码。 \u0026#x21a9;\u0026#xfe0e;\n 就算有任务再次进入了reset流程，也依然可能存在上面描述的问题，这仅仅增加了程序运行的不稳定性。 \u0026#x21a9;\u0026#xfe0e;\n 并不能保证先调用acquire()方法的线程就能先获得许可，而是先调用方法的线程先执行内部逻辑的线程优先获取许可。所以有可能线程a先于线程b调用acquire()方法，但是却晚于线程b到达“等待点”。 \u0026#x21a9;\u0026#xfe0e;\n 这个示例演化自Semaphore的javaDoc：https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Semaphore.html。 \u0026#x21a9;\u0026#xfe0e;\n 如果使用是个“许可证数”为1的Semaphore，其作用相当于一个独占锁，任意时刻只有一个任务能够获取许可并且对资源进行修改，此时，getItem方法可以不使用同步。 \u0026#x21a9;\u0026#xfe0e;\n 这个示例演化自Exchanger的javaDoc：https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Exchanger.html。 \u0026#x21a9;\u0026#xfe0e;\n 忽略类型检查的原因是因为尚不能处理泛型编程的所有问题。理论上这里传入任意Queue实现类都是可以的，但是由于示例中所用的实例Fat并没有实现Comparable接口，所以当传入优先级队列时，构造器会抛出初始化异常。 \u0026#x21a9;\u0026#xfe0e;\n 这里还存在一个潜在问题：EmptyTask完成时取消FillTask，FillTask的状态会影响程序的结果，若后者是在Exchanger处被阻塞时取消，那将抛出中断异常，程序输出如示例中说的那样；若后者在向缓存中添加对象时被中断，shutdown()方法无法立刻中止FillTask的运行，它将继续运行至进入栅栏而抛出异常，但是，主线程中的遍历(在使用普通队列时)就可能会抛出ConcorrentModificationException。解决此问题的方法是在FillTask中分别处理2种取消的情况，或者在主线程中使用awaitTermination等待FillTask抛出异常而终结。 \u0026#x21a9;\u0026#xfe0e;\n Delay接口实际上继承了Comparable接口。 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文介绍了juc包中其他常用的并发组件，包括倒计时门闩，信号量，交换器等。","id":18,"section":"posts","tags":["信号量","交换器"],"title":"倒计时门闩、信号量、交换器及其他","uri":"http://wangy325.top/zh/posts/java/concurrency/%E5%85%B6%E4%BB%96%E9%87%8D%E8%A6%81%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BB%84%E4%BB%B6/"},{"content":"除了ThreadPoolExecutor之外，Java执行器（Executor）框架还提供了可以在指定延迟之后执行一次或周期执行任务的接口ScheduledExecutorService，较java.util.Timer而言，它是更好的选择\n与线程池不同的是，用于计划执行的ScheduledThreadPoolExecutor使用ScheduledFutureTask作为任务，使用DelayedWorkQueue作为任务队列，以实现计划（周期）执行的目的\nScheduledThreadPoolExecutor继承关系图\n从ScheduledThreadPoolExecutor的继承关系图可以看到，其是ThreadPoolExecutor的导出类，其提交任务和执行任务以及关闭线程池的逻辑应和线程池相差无几，其重点差别在于任务对象以及任务队列的封装上，后文将会详述ScheduledThreadPoolExecutor的任务计划执行以及周期执行机制\n1 ScheduledExecutorService 继承自ExecutorService接口，其方法定义了一个可以用于在指定延迟之后执行一次或周期执行的ExecutorService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  // 继承自ExecutorService 和Executor的方法被省略  /* 在给定的延迟之后执行Callable任务，立即返回ScheduledFuture\u0026lt;V\u0026gt;，其可以获取任务的结果或者取消任务*/ \u0026lt;V\u0026gt; ScheduledFuture\u0026lt;V\u0026gt; schedule(Callable\u0026lt;V\u0026gt; callable, long delay, TimeUnit unit) /* 在给定的延迟之后执行Runnable任务，立即返回ScheduledFuture\u0026lt;?\u0026gt;，其get()方法返回null*/ ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit) /* 在给定的初始延迟initialDelay之后执行Runnable任务，接着在给定的时间间隔period之后再次执行任务， 接着再间隔period之后再次执行任务... 如果某次任务的执行耗时 \u0026gt; period，下次的计划执行将被延后，并不会同时执行多个任务 如果某次执行抛出异常，那么接下来的执行将被中止。周期执行的任务只有线程池终止之后才会停止执行，也 就是说周期任务永远不会主动完成 返回值ScheduledFuture\u0026lt;?\u0026gt;代表将要执行的任务，取消任务时，其get()方法会抛出异常*/ ScheduledFuture\u0026lt;?\u0026gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) /* 在给定的初始延迟之后执行Runnable任务，接着在任务完成之后延迟delay之后再次执行，接着在上一个 任务完成之后延迟delay再次执行... 如果某次执行抛出异常，那么接下来的执行将被中止。周期执行的任务只有线程池终止之后才会停止执行，也 就是说周期任务永远不会主动完成 返回值ScheduledFuture\u0026lt;?\u0026gt;代表将要执行的任务，取消任务时，其get()方法会抛出异常*/ ScheduledFuture\u0026lt;?\u0026gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)   2 ScheduledThreadPoolExecutor 由于其是ThreadPoolExecutor的导出类，故其主要逻辑和其父类一致，本节的讨论着重于二者差异的部分\n2.1 构造器 ScheduledThreadPoolExecutor的构造器就不再赘述了，基本上是父类的构造参数中抽取了几个便于理解的构造器，将其分列如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); } public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory); } public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler); } public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler); }   ScheduledThreadPoolExecutor的实例均使用Integer.MAX_VALUE作为最大线程池数，这是否意味着其可以使用无限制的线程去运行任务呢？答案是否定的，ScheduledThreadPoolExecutor保证了其池中的线程数不会超过corePoolSize1\n2.2 域 除了构造器中指定的参数之外，ScheduledThreadPoolExecutor还有一些其他参数，这些参数都可以在ScheduledThreadPoolExecutor初始化完成之后再进行动态配置\n1 2 3 4 5 6 7 8 9 10 11  /** 线程池shutdown之后是否继续执行周期任务，true执行，默认为false*/ private volatile boolean continueExistingPeriodicTasksAfterShutdown; /** 线程池shutdown之后是否继续执行计划任务，true执行，默认为true*/ private volatile boolean executeExistingDelayedTasksAfterShutdown = true; /** 取消任务时是否将任务从队列中移除，true移除，默认false*/ private volatile boolean removeOnCancel = false; /** 任务添加的顺序，初始化ScheduledFutureTask时使用*/ private static final AtomicLong sequencer = new AtomicLong();   2.3 方法 ScheduledThreadPoolExecutor使用最多的还是实现自ScheduledExecutorService接口的4个方法，用于计划（周期）执行任务，其中，作为线程池的execute和submit方法全部直接调用了scheduleXX方法。值得一提的是，ScheduledThreadPoolExecutor覆盖了ThreadPoolExecutor的onShutdown()方法，用于关闭线程池时的额外操作，该方法在父类中是空方法\n2.4 由Executors构造的ScheduledThreadPoolExecutor 一般地，我们会使用Executors来获取线程池，Executors提供了2个基本方法(不包括重载方法)来获取计划执行任务的线程池\n1 2 3 4 5 6 7 8 9 10  /** 构造一个不可动态配置的ScheduledThreadPoolExecutor，其核心线程池数量为1*/ public static ScheduledExecutorService newSingleThreadScheduledExecutor() { return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); } /** 构造一个核心线程池为1的ScheduledThreadPoolExecutor*/ public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize); }   我们可以自定义线程工厂(ThreadFactory)来调用其重载方法以自定义线程信息\n3 内部结构 3.1 ScheduledFutureTask 1 2 3  private class ScheduledFutureTask\u0026lt;V\u0026gt; extends FutureTask\u0026lt;V\u0026gt; implements RunnableScheduledFuture\u0026lt;V\u0026gt; {...}   提交给ScheduledExecutorService的任务都被包装成ScheduledFutureTask实例，相较FutureTask，其还实现了RunnableScheduledFuture接口，这个接口是RunnableFuture，ScheduledFuture的子接口，也就是Runnable，Future和Delay的实现类\n实现Delay接口是关键，它保证计划任务能够按时（周期）执行，并且任务能够按照执行顺序或者添加顺序被取出执行\n3.1.1 域 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // 每一个实例都有一个“序号”，用来维持其在队列中的位置 private final long sequenceNumber; // 任务下一次执行的时间，纳秒表示 private long time; // 任务周期执行的“周期”，纳秒表示，正数表示固定频率执行； // 负数表示固定延迟执行，0表示不是周期执行的任务 private final long period; // 用来重新插入队列中的任务 （周期执行的任务） RunnableScheduledFuture\u0026lt;V\u0026gt; outerTask = this; // 任务在队列中的索引（看出来是一个树） int heapIndex;   3.1.2 构造器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  // 构造一个单次执行的任务 ScheduledFutureTask(Runnable r, V result, long ns) { super(r, result); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement(); } // 构造单次执行的任务 ScheduledFutureTask(Callable\u0026lt;V\u0026gt; callable, long ns) { super(callable); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement(); } // 构造周期执行的任务 ScheduledFutureTask(Runnable r, V result, long ns, long period) { super(r, result); this.time = ns; this.period = period; this.sequenceNumber = sequencer.getAndIncrement(); }   前2个构造器构造单次执行的任务，不过使用的任务不同罢了；第三个构造器构造周期执行的任务。每构造一个任务，任务的sequenceNumber便自增1\n3.1.3 方法 1 compareTo 由于Delay接口实现了Comparable接口，因此实现此方法对任务进行排序，其排序规则是：\n 先比较time，先执行的任务在前 若time相等，再比较sequenceNumber，先添加的任务在  2 setNextRunTime 设置周期任务下一次执行的时间\n1 2 3 4 5 6 7 8 9  private void setNextRunTime() { long p = period; if (p \u0026gt; 0) // 固定周期执行，上一次执行时间+period即可  time += p; else // 固定delay执行  time = triggerTime(-p); }   3 run 执行任务的核心方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public void run() { // 检查是否周期任务  boolean periodic = isPeriodic(); if (!canRunInCurrentRunState(periodic)) // 当前状态不允许运行任务  cancel(false); else if (!periodic) // 执行单次任务  ScheduledFutureTask.super.run(); // 执行周期任务使用了runAndReset方法  else if (ScheduledFutureTask.super.runAndReset()) { // 周期任务执行完毕一次  // 设置下次执行的时间  setNextRunTime(); // 将任务添加到队列  reExecutePeriodic(outerTask); } } // 将已经执行的任务再次放入任务队列中 void reExecutePeriodic(RunnableScheduledFuture\u0026lt;?\u0026gt; task) { if (canRunInCurrentRunState(true)) { // 再次入队  super.getQueue().add(task); // double check  if (!canRunInCurrentRunState(true) \u0026amp;\u0026amp; remove(task)) // 取消任务  task.cancel(false); else // 创建（如果需要）worker，保证有线程执行任务  ensurePrestart(); } }   3.2 DelayedWorkQueue ScheduledThreadPoolExecutor使用DeleyedWorkQueue作为任务队列，它是一个特殊的delay queue，其维护一个有序的ScheduledFutureTask任务队列。在本节中，限于数据结构相关知识尚缺，将跳过叙述队列中的元素如何调整其在树中的位置，着重叙述任务入队及出队的逻辑\n1 2 3  static class DelayedWorkQueue extends AbstractQueue\u0026lt;Runnable\u0026gt; implements BlockingQueue\u0026lt;Runnable\u0026gt; { }   该类中，有一个核心概念，它用一个私有域表示\n1 2  // 这个域用来等待队列的队首元素出现 private Thread leader = null;   在delay queue 中，如果没有元素的delay超时，那么你将无法从队列中取出元素。当某个任务A的delay最先超时时，其将优先出队并执行，那么leader将被声明为执行任务A的线程TA，在该任务A超时之前，leader不会被重置，在这一段时间内，其他线程只能等待；若任务A超时出队，leader将被重置，此时线程TA将唤醒等待的其他线程，然后重复重置leader的过程。我们将在任务入队和出队时看到leader域的作用\n4 任务执行流程 前面介绍了ScheduledFutureTask和DeleyedWorkQueue这么多，都是为了更好地理解任务执行的流程，在这之前，我们不妨先看如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  public class TestScheduledPoolExecutor { private AtomicInteger sequence = new AtomicInteger(0); private ScheduledThreadPoolExecutor service; public TestScheduledPoolExecutor(int poolSize) { this.service = new ScheduledThreadPoolExecutor(poolSize); } private void s() { System.out.println(Thread.currentThread() + \u0026#34; \u0026#34; + sequence.getAndIncrement()); } private void c() { System.out.println(Thread.currentThread() + \u0026#34; c running\u0026#34;); while (true) { // never finish loop unless interrupted  if (Thread.interrupted()) { break; } } System.out.println(Thread.currentThread() + \u0026#34;c interrupted\u0026#34;); } @SneakyThrows void basicTest() { service.schedule(this::s, 2, TimeUnit.SECONDS); service.schedule(this::c, 1, TimeUnit.SECONDS); // shutdown无法终止线程池  service.shutdown(); TimeUnit.SECONDS.sleep(5); System.exit(0); } public static void main(String[] args) { TestScheduledPoolExecutor ts = new TestScheduledPoolExecutor(0); ts.basicTest(); } }   在上例中，我们创建了2个任务s和c，前者简单地获取并递增sequence，后者则是一个响应中断的死循环。当我们使用不同数量的corePoolSize去运行任务时，得到的结果不一样:\n 当corePoolSize = 0时，输出为\n Thread[pool-1-thread-1,5,main] c running   当corePoolSize = 1时，输出为\n Thread[pool-1-thread-1,5,main] c running   当corePoolSize \u0026gt; 1时，输出为\n Thread[pool-1-thread-1,5,main] c running Thread[pool-1-thread-2,5,main] 1 4.1 提交任务 这种差异驱使我们去探索计划任务的提交与执行方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70  // 提交单次执行的任务 public ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); // t = new ScheduledFutureTask(..)  RunnableScheduledFuture\u0026lt;?\u0026gt; t = decorateTask(command, new ScheduledFutureTask\u0026lt;Void\u0026gt;(command, null, triggerTime(delay, unit))); // 执行任务的核心方法  delayedExecute(t); return t; } // 提交周期执行的任务 public ScheduledFuture\u0026lt;?\u0026gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); if (delay \u0026lt;= 0) throw new IllegalArgumentException(); ScheduledFutureTask\u0026lt;Void\u0026gt; sft = new ScheduledFutureTask\u0026lt;Void\u0026gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(-delay)); // t = sft  RunnableScheduledFuture\u0026lt;Void\u0026gt; t = decorateTask(command, sft); // 任务执行后将再次入队  sft.outerTask = t; delayedExecute(t); return t; } private void delayedExecute(RunnableScheduledFuture\u0026lt;?\u0026gt; task) { if (isShutdown()) // ctl \u0026gt; running，不接受任务提交  reject(task); else { // 非空任务入队  super.getQueue().add(task); // double check  if (isShutdown() \u0026amp;\u0026amp; !canRunInCurrentRunState(task.isPeriodic()) \u0026amp;\u0026amp; remove(task)) // 如果任务入队之后，线程池关闭  // 且关闭策略不允许关闭之后继续执行  // 且任务从队列中移除  // 则取消任务  task.cancel(false); else // add worker  ensurePrestart(); } } // 此方法保证了即使corePoolSize = 0的情况下也创建worker void ensurePrestart() { // 获取当前工作线程数  int wc = workerCountOf(ctl.get()); if (wc \u0026lt; corePoolSize) // 尚可以新建核心线程  addWorker(null, true); else if (wc == 0) // 新建非核心线程  addWorker(null, false); }    ![xx](/img/scheduledThreadPool_submit_flow.png) ScheduledThreadPoolExecutor任务提交流程图\n 我们可以从ScheduledThreadPoolExecutor的任务提交过程中总结几点规律：\n 任务一定是先放入任务队列中的 活动线程不可能超过核心线程池大小 若corePoolSize \u0026gt; 0，则池中不可能存在非核心线程 非核心线程只有在corePoolSize = 0且当前工作线程数为0时才可以创建，并且活动的非核心线程只能存在一个  上述规律的第4点容易得出线程池中非核心线程数至多为1的结论，这似乎是很合理的，因为想要创建非核心线程，wc必须为0。结合线程池的相关知识，我们知道非核心线程超时是会被销毁的，我们可以看看非核心线程在执行计划任务时的行为\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  @SneakyThrows void howManyThreads() { for (; ; ) { ScheduledFuture\u0026lt;?\u0026gt; schedule = service.schedule(this::s, 0, TimeUnit.MILLISECONDS); // TimeUnit.MILLISECONDS.sleep(5); // uncomment this to create new worker  for (; ; ) { if (schedule.isDone()) break; } if (sequence.get() \u0026gt;= 10) { schedule.cancel(false); break; } } System.out.println(\u0026#34;largest pool size: \u0026#34; + service.getLargestPoolSize()); service.shutdown(); } /* output(sample) Thread[pool-1-thread-1,5,main] 1 Thread[pool-1-thread-1,5,main] 2 Thread[pool-1-thread-1,5,main] 3 Thread[pool-1-thread-2,5,main] 4 Thread[pool-1-thread-3,5,main] 5 Thread[pool-1-thread-4,5,main] 6 Thread[pool-1-thread-5,5,main] 7 Thread[pool-1-thread-7,5,main] 8 Thread[pool-1-thread-8,5,main] 9 Thread[pool-1-thread-10,5,main] 10 largest pool size: 2 *///:~   在上例中，我们保证当前提交的任务在执行完成之后再进行下一次提交，那么下一次的任务应该新建线程执行才对。但实际的情况并非如此，执行上个任务的线程仍然有机会继续执行接下来提交的任务，这是由于任务的执行以及线程的销毁都是耗时操作，可能在线程销毁（执行CP1）之前新的任务已经添加到队列中了。除此之外，在所有任务执行完成之后，我们获取了线程池中同时执行任务的最大线程数，按照逻辑，这个值应该始终是1，实际的运行过程中却是一个不确定的数。这让人费解，新线程的创建前提是workerCount==0，即表明了池中是没有正在运行的线程，不过，可以猜测池中出现2个线程的过程大概出现在线程1即将销毁，执行processWorkerExit方法之前，将要销毁的worker还未从set中移除，而此时addworker读取到的size \u0026gt; 1，于是出现了largestPoolSie\u0026gt;1的情形\n如果取消上例中的休眠注释，就能规避上述的各种不确定情况，足够时长的休眠可以保证执行任务的线程执行任务并销毁\n4.2 任务入队 由于任务提交之后一定是先放入任务队列的，而基于DelayedWorkQueue的任务队列和普通的阻塞队列有些区别。任务队列通过调用offer(Runnable x)方法将任务放入队列中，只有在获取锁的情况下才能调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public boolean offer(Runnable x) { if (x == null) throw new NullPointerException(); RunnableScheduledFuture\u0026lt;?\u0026gt; e = (RunnableScheduledFuture\u0026lt;?\u0026gt;)x; final ReentrantLock lock = this.lock; lock.lock(); try { int i = size; if (i \u0026gt;= queue.length) // 队列扩容 （grow 50%）  grow(); size = i + 1; if (i == 0) { queue[0] = e; setIndex(e, 0); } else { siftUp(i, e); } // 入队之前，若队列为空，且没有线程在超时等待  if (queue[0] == e) { leader = null; // 唤醒等待的线程去获取任务执行（并非一定有线程等待）  available.signal(); } } finally { lock.unlock(); } return true; }   由于使用无界队列实现，DelayedWorkQueue任务入队的阻塞不会阻塞；但如果入队时队列为空，那么意味着：\n 首个任务入队 所有任务都已经出队  成功入队之后，将会唤醒一个阻塞的线程(可能没有阻塞的线程)去获取任务执行\n4.3 执行任务 与ThreadPoolExecutor不同的是，ScheduledThreadPoolExecutor所有任务都是先添加到任务队列中的，并且任务队列是delay queue，从delay queue中取出任务比简单的阻塞队列稍显复杂。不过其执行任务的基本逻辑和ThreadPoolExecutor的任务执行过程是一致的\n而关于任务周期执行的机制，前文在阐述ScheduledFutureTask的run()方法时，已经提及，\n 它调用FutureTask.runAndReset方法执行任务，保证任务可以重复运行； 重新计算任务的下一次运行时间，并且将任务重新入队  4.4 任务出队 任务出队有主要两个方法，poll(long timeout)和take()，前者用于非核心线程，后者用于核心线程；同样地，只有在获取锁的时候才能出队\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  public RunnableScheduledFuture\u0026lt;?\u0026gt; take() throws InterruptedException { final ReentrantLock lock = this.lock; // 注意此处可以被中断  lock.lockInterruptibly(); try { // 循环执行  for (;;) { // queue[0]是最先超时的任务  RunnableScheduledFuture\u0026lt;?\u0026gt; first = queue[0]; if (first == null) // 队列为空，无限期等待，会被offer()方法唤醒  available.await(); else { long delay = first.getDelay(NANOSECONDS); if (delay \u0026lt;= 0) // 任务已超时，返回该任务  return finishPoll(first); first = null; // don\u0026#39;t retain ref while waiting  // 任务未超时  if (leader != null) // 当leader已设置时，当前线程只能无限期等待  // 因为在其之前还有任务未执行  available.await(); else { // 否则将leader设置为当前（执行任务的）线程  Thread thisThread = Thread.currentThread(); leader = thisThread; try { // 等待任务超时  available.awaitNanos(delay); } finally { // 任务超时之后，将leader置空，再次进入循环  // 之后将获取任务并返回  // 此时其他的线程将可以设置leader并进入超时等待  if (leader == thisThread) leader = null; } } } } } finally { if (leader == null \u0026amp;\u0026amp; queue[0] != null) //唤醒其他的线程去获取任务  available.signal(); lock.unlock(); } } public RunnableScheduledFuture\u0026lt;?\u0026gt; poll(long timeout, TimeUnit unit) throws InterruptedException { // nanos如果不进行动态配置，就是0  long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { for (;;) { RunnableScheduledFuture\u0026lt;?\u0026gt; first = queue[0]; if (first == null) { if (nanos \u0026lt;= 0) // 若队列为空，且keepAliveTime\u0026lt;=0，直接返回null  return null; else // 否则限时等待之后进入下次循环  nanos = available.awaitNanos(nanos); } else { long delay = first.getDelay(NANOSECONDS); if (delay \u0026lt;= 0) // 运气好正好有任务到期，返回任务  return finishPoll(first); if (nanos \u0026lt;= 0) // 任务未到期且keepAliveTime\u0026lt;=0，返回null  return null; first = null; // don\u0026#39;t retain ref while waiting  // 以下是设置keepAliveTime的情形  if (nanos \u0026lt; delay || leader != null) // 将nanos置0  nanos = available.awaitNanos(nanos); else { Thread thisThread = Thread.currentThread(); leader = thisThread; try { // 分段等待  long timeLeft = available.awaitNanos(delay); nanos -= delay - timeLeft; } finally { // 重重leader  if (leader == thisThread) leader = null; } } } } } finally { if (leader == null \u0026amp;\u0026amp; queue[0] != null) // 唤醒其他线程  available.signal(); lock.unlock(); } }    ![xx](/img/delayed_worker_queue_take.jpg) ScheduledThreadPoolExecutor任务出队流程图\n 理解了任务的入队与出队，我们就可以解释本节开头示例中不同corePoolSize引发的差异：\n在分析任务的执行时，要始终留意getTask()方法中的这一段代码，为了方便描述，将其记为CP1\n  1 2 3 4 5 6  if ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; }     当corePoolSize为0时\n 首次提交一个延迟2s的任务a，创建线程t1，显然a超时之前t1无法获取任务，但t1并不会因为keepAlive超时而在CP1处被结束（因为任务队列不为空），它只是一直在循环； 接着提交一个延迟1s的任务b，由于t1未被销毁，所以提交任务b时并未新建线程，池中仍只有一个工作线程t1； 任务b会先于a出队，故1s后b超时执行，由于b是死循环，无法结束，因此没有线程去执行超时的任务a    当corePoolSize为1时，虽然输出结果与corePoolSize为0时一致，但是其执行过程却有很大差别\n 首次提交一个延迟2s的任务a，创建线程t1，t1会在take()获取队列时设置leader并进入超时等待状态； 接着提交一个延迟1s的任务b，由于corePoolSize的限制，并未能创建新线程，池中仍只有一个工作线程t1。在任务b入队后，会唤醒阻塞的t1线程； t1被唤醒之后清空leader，重新去队列中获取任务，由于b要比a先出队，此时t1会接着设置leader并在任务b的时间上超时等待； 任务b超时之后开始执行，由于b是死循环，无法结束，因此没有线程去执行超时的任务a    当corePoolSize\u0026gt; 1时，情况又有所不同\n 首次提交一个延迟2s的任务a，创建线程t1，t1会在take()获取队列时设置leader并进入超时等待状态； 接着提交一个延迟1s的任务b，创建线程t2，池中有2个工作线程t1、t2。同样地，b入队后，会唤醒阻塞的t1； t1被唤醒之后清空leader，重新去队列中获取任务，由于b要比a先出队，此时t1会接着设置leader并在任务b的时间上超时等待； t1在超时等待时，由于leader已经被设置，t2只能无限阻塞； t1超时后，执行任务b，同时清空leader并唤醒t2，t2设置leader并在任务a的时间上超时等待； t2超时后，执行任务a    5 取消任务 默认情况下，如果取消一个任务的执行，该任务不会从队列中移除，不过我们可以动态地配置removeOnCancel域，在取消任务时同时将任务从队列中移除。被取消的任务不能继续执行,在线程池关闭的时候将从队列中移除\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  void cancelSchedule() { // default false  service.setRemoveOnCancelPolicy(false); // task to cancelled  service.schedule(this::s, 10, TimeUnit.SECONDS); BlockingQueue\u0026lt;Runnable\u0026gt; queue = service.getQueue(); Runnable task = queue.peek(); if (task instanceof RunnableScheduledFuture) { ((FutureTask\u0026lt;?\u0026gt;) task).cancel(false); } service.schedule(this::s, 1, TimeUnit.SECONDS); TimeUnit.SECONDS.sleep(2); // should be 1  System.out.println(\u0026#34;queue size: \u0026#34; + queue.size()); service.shutdown(); // removed by onShutdown hook method  System.out.println(\u0026#34;queue size: \u0026#34; + queue.size()); } public static void main(String[] args) { TestScheduledPoolExecutor ts = new TestScheduledPoolExecutor(0); ts.cancelSchedule(); } /* output Thread[pool-1-thread-1,5,main] 1 queue size: 1 queue size: 0 *///:~   上例中，可以看到提交了2个任务，只有一个任务执行。首先提交的任务随即被取消了，第一次获取队列大小时，执行完一个任务，但是队列不为空，被取消的任务还在队列中，在线程池shutdown之后，任务随即被移除。如果使用service.setRemoveOnCancelPolicy(true)替换示例中的设置，那么两次获取的队列大小都是0\n这样的设计有一个好处，如果刻意取消一个任务，特定条件下可以避免重复的销毁和创建工作线程。在前面的讨论中，我们知道，核心线程空闲时是不会被销毁的，它会在任务队列上阻塞；但是非核心线程就不同了，如果队列为空，非核心线程会在CP1处结束运行，但是如果取消一个任务，并且任务没有从队列中移除的话，那么这个非核心线程就不会被销毁\n6 关闭线程池 除了继承ThreadPoolExecutor的线程池关闭的逻辑之外，ScheduledThreadPoolExecutor关闭线程池和其基类还有些许差异，主要是其通过实现onShutdown方法，实现了新的关闭策略\n6.1 onShutDown方法 调用shutdown和shutdownNow方法的基本逻辑和基类一致，不过shutdown过程中的onShutdown方法引入了新的关闭策略\n关闭策略由2个布尔值域控制，分别是\n executeExistingDelayedTasksAfterShutdown = true; shutdown之后默认执行计划（单次）任务 continueExistingPeriodicTasksAfterShutdown;shutdown之后默认不执行周期任务  这两个域可以在线程池初始化之后进行动态配置，默认情况下，调用shutdown方法之后，\n 计划的（one-shot）任务将继续执行； 如果是周期任务，将从任务队列中移除； 已经取消的任务将会从队列中移除  调用shutdownNow方法的逻辑则完全和基类一致，其会中断所有任务，返回丢弃的任务列表\n以下是onShutdown方法的具体实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  @Override void onShutdown() { BlockingQueue\u0026lt;Runnable\u0026gt; q = super.getQueue(); boolean keepDelayed = getExecuteExistingDelayedTasksAfterShutdownPolicy(); boolean keepPeriodic = getContinueExistingPeriodicTasksAfterShutdownPolicy(); // 如果shutdown之后既不执行计划任务也不执行周期任务  if (!keepDelayed \u0026amp;\u0026amp; !keepPeriodic) { // 那么取消所有任务的执行，并清空队列  for (Object e : q.toArray()) if (e instanceof RunnableScheduledFuture\u0026lt;?\u0026gt;) ((RunnableScheduledFuture\u0026lt;?\u0026gt;) e).cancel(false); q.clear(); } else { // Traverse snapshot to avoid iterator exceptions  for (Object e : q.toArray()) { if (e instanceof RunnableScheduledFuture) { RunnableScheduledFuture\u0026lt;?\u0026gt; t = (RunnableScheduledFuture\u0026lt;?\u0026gt;)e; // 不管是在shutdown之后执行计划任务或者周期任务，都移除已经取消的任务  // 但是不移除计划执行的任务  if ((t.isPeriodic() ? !keepPeriodic : !keepDelayed) || t.isCancelled()) { // also remove if already cancelled  if (q.remove(t)) t.cancel(false); } } } } tryTerminate(); }   下面的示例中，我们重新设置了线程池的关闭策略，以观察线程池在关闭时候的行为\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  @SneakyThrows void shutdownPolicy() { // 如果任务在shutdown()之后仍在delay，那么将值设置为false可以取消任务的执行  // 其默认值为true  service.setExecuteExistingDelayedTasksAfterShutdownPolicy(false); service.schedule(this::s, 1, TimeUnit.MILLISECONDS); // 如果是周期执行的任务，将此值设置为true可以在调用shutdown()之后让其继续执行，否则结束执行  // 其默认值为false  service.setContinueExistingPeriodicTasksAfterShutdownPolicy(true); service.scheduleWithFixedDelay(this::s, 2, 1, TimeUnit.SECONDS); service.shutdown(); TimeUnit.SECONDS.sleep(10); // shutdownNow interrupt all tasks  service.shutdownNow(); // could be true or false  System.out.println(service.isTerminated()); }   在shutDown之后，周期任务仍会一直执行，所以要使用shutDownNow来中止任务的执行\n 特殊地，当corePoolSize = 0时，池中仅可允许一个线程执行任务 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文结合源码，分析了Java并发框架中用于执行计划任务的执行器(ScheduledThreadPoolExecutor)的运行机制。是执行器的姊妹篇。","id":19,"section":"posts","tags":["线程池","执行器"],"title":"计划执行任务","uri":"http://wangy325.top/zh/posts/java/concurrency/%E8%AE%A1%E5%88%92%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1/"},{"content":"Java并发系列的文章到目前为止，虽然没有特别说明，但是使用执行器(Executor(s))的次数已经难以计数了，Executors提供了一些非常方便的静态方法，可以根据需要创建不同的ExecutorService，然后调用其execute(Runnable)或submit(Callable\u0026lt;T\u0026gt;)方法。在多线程的条件下，执行器还有一个非常明显的优势，它使用线程池管理线程，避免了系统创建和销毁线程的开销。在一般的Java并发过程中，也建议使用执行器完成任务而非显式地创建线程。\n本文将从执行器开始，阐述Java中的线程池。\n1 Executors java.util.concurrent.Executors类提供了许多静态方法来获取不同类型的 线程池，下表列出其常用方法1：\n   方法 概要     newFixedThreadPool 创建固定大小的线程池，线程会一直保留   newCachedThreadPool 创建线程池，该线程池在必要时创建新线程，旧线程也会被重用，线程空闲60s被销毁   newSingleThreadExecutor 相当于newFixedThreadPool(1)，其能保证任务顺序执行   newScheduledThreadPool 用于预定执行一次或周期执行的线程池   newSingleThreadScheduledExecutor 用于预定执行一次或周期执行的单线程池    Executors用于构造线程池的部分方法\n上表中的前3个方法返回ThreadPoolExecutor实例，后面2个方法返回ScheduledExecutorService接口的实例，不管是ThreadPoolExecutor或是ScheduledExecutorService，都是ExecutorService的实现，ExecutorService接口是设计用来处理任务的接口，其顶层接口是java.util.concurrent.Executor，该接口简单地定义了一个执行任务的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command); }   因此对执行器的讨论最终要回到对Executor及其实现上来。\n2 Executor 框架 前文就已经提过，Executors构建的线程池包括不同实现，可以应对不同的场景，那么Java中包含哪些实现呢？\nExecutor框架组成:   ![xx](/img/executor_execution.jpg)  Executor框架执行图\n-- 从上面的框架组成图中，可以清晰的看到使用Executors能够构建所有线程池实例，ExecutorService接口定义了一系列和线程池以及任务相关的基本方法，用于检查关闭/关闭线程池，提交任务，执行任务等。\nAbstractExecutorService直接实现了ExecutorService的invokeAny/invokeAll方法。此外，从该类的源码可以清晰地看到，所有的任务都是通过转化为RunnableFuture(FutureTask)而后通过execute(Runnable)方法执行的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  protected \u0026lt;T\u0026gt; RunnableFuture\u0026lt;T\u0026gt; newTaskFor(Callable\u0026lt;T\u0026gt; callable) { return new FutureTask\u0026lt;T\u0026gt;(callable); } public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;T\u0026gt; ftask = newTaskFor(task); execute(ftask); return ftask; } protected \u0026lt;T\u0026gt; RunnableFuture\u0026lt;T\u0026gt; newTaskFor(Runnable runnable, T value) { return new FutureTask\u0026lt;T\u0026gt;(runnable, value); } public Future\u0026lt;?\u0026gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;Void\u0026gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; } public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;T\u0026gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; }   ScheduledExecutorService接口继承自ExecutorService，定义了用于计划执行或周期执行的线程池方法。\nThreadPoolExecutor继承自AbstractExecutorService，是线程池重要的实现之一。\nScheduledThreadPoolExecutor继承自ScheduledExecutorService，是线程池重要的实现之二。\nForkJoinPool继承自AbstractExecutorService，是线程池的重要实现之三，关于它的内容将单独展开。\nDelegatedExecutorService继承自AbstractExecutorService，它是Executors的内部类，是一个仅仅实现了ExecutorService方法的包装类，其有两个子类分别是DelegatedScheduledExecutorServide和FinalizableDelegatedExecutorService。\nCompletionService接口有一个子类ExecutorCompletionService，该类由执行器实例化，用来管理执行器执行的任务的结果。\n2.1 ExecutorService ![xx](/img/executor_service_method_table.png)  ExecutorService方法表\n-- ExecutorService是次顶层接口，定义了线程池操作任务的基本方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  // 继承自Executor的方法 void execute(Runnable command); void shutdown(); /*有序地关闭线程池，已经提交（在运行或已经在队列中）的任务不会受到影响，将继续执行， 但线程池不接受新任务的提交 此法不会在当前线程上等待线程池后台任务的执行结果（或者任务执行后的作用），换言之， 如果想要获取任务执行之后的结果，调用此法无法达到目的*/ List\u0026lt;Runnable\u0026gt; shutdownNow(); /*尝试去停止(stop)所有活动的任务，已提交且队列中的中的任务将取消执行，并返回取消的任务队列。 向正在执行的任务发送中断命令，那些无法响应中断命令的任务将无法中止 和shutdown()方法一样，此法不会等待正在执行的任务终止*/ boolean isShutdown(); // 如果线程池已经关闭，返回true  boolean isTerminated(); /*如果所有的任务都完成（中止运行或正常运行完成），则返回true 注意，若没有先调用shutdown()或shutdownNow()，此方法不可能返回true*/ boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; /*线程池shutdown请求之后，阻塞当前线程，等待任务执行。当超时，任务执行完毕，或当前线程被中断 任一情况发生时，终止阻塞*/ \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task); // 提交一个有返回结果的Callable任务  \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result); // 提交一个Runnable并指定其返回result  Future\u0026lt;?\u0026gt; submit(Runnable task); /*提交一个Runnable，返回的Future\u0026lt;?\u0026gt;的get方法将返回null，其主要目的是利用Future的其他 方法控制任务的执行*/ \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException; /*执行集合中包含的任务，并返回一个Future\u0026lt;T\u0026gt;集合，Future\u0026lt;T\u0026gt;集合包含各个任务的执行状态及结果 Future\u0026lt;T\u0026gt;集合中的的顺序和任务集合中的迭代顺序是一致的 这个方法会等待所有的任务执行完成（正常执行或抛出异常），如果任务集合在执行过程中被修改，那么 任务的结果将会变为undefined*/ \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; /* 执行集合中包含的任务，在所有任务执行完成或超时之前返回一个Future\u0026lt;T\u0026gt;集合。在返回之前， 未能执行的任务将被取消 其他的特征和重载方法一致*/ \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException, ExecutionException; /* 执行给定的任务集合中的任务，返回任何一个成功执行的任务的结果，其他未完成的任务被取消 如果任务集合在执行过程中被修改，那么任务的结果将会变为undefined*/ \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; /* 执行给定的任务集合中的任务，在超时之前返回任何一个成功执行的任务的结果， 其他未完成的任务被取消 如果任务集合在执行过程中被修改，那么任务的结果将会变为undefined*/   如上所示，ExecutorService定义了线程池的基本方法，其中invokeAny和invokeAll方法在AbstractExecutorService中实现。\n2.2 ThreadPoolExecutor 该类是执行器(线程池)的核心类，一般来讲，Java的线程池，指的就是ThreadPoolExecutor实例。\n2.2.1 构造器 ThreadPoolExecutor提供了4个构造器用来构造线程池实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize \u0026lt; 0 || maximumPoolSize \u0026lt;= 0 || maximumPoolSize \u0026lt; corePoolSize || keepAliveTime \u0026lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; }   从构造器来看呢，要构建一个线程池实例，至少需要提供5个参数，另外2个参数不提供则可以使用默认配置2，这些参数分别是：\n   参数 描述     corePoolSize 核心线程池大小   maximumPoolSize 最大线程池大小   keepAliveTime 非核心线程执行完任务后最长的空间等待时间，超时则销毁线程   unit keepAliveTime的单位   workQueue 用于保存待执行任务的队列   threadFactory 用于创建线程的线程工厂   handler 线程池满载（队列无空间，且不能新建线程）后，处理新提交任务的拒绝策略    这些构造器参数就是线程池的核心概念，理解这几个参数在线程池运行过程中的意义便理解了线程池的大半。\n2.2.2 核心概念 核心线程池与最大线程池 线程池的getPoolSize()方法返回的线程数不应该超过线程池的核心线程池大小（corePoolSize）或 最大线程池大小（maximumPoolSize）。线程池中的工作线程数不可能超过最大线程池大小。若想获得当前的正在执行任务的线程数，需使用getActiveCount()方法。\n当一个任务被提交至线程池后3，若：\n 当前工作线程数 \u0026lt; corePoolSize，新建一个线程来完成任务——尽管可能有空闲核心线程\n(当工作线程数 \u0026lt; corePoolSize时，任务队列一定是空的) corePoolSize \u0026lt; 当前工作线程数 \u0026lt; maximumPoolSize，并且任务队列已满，那么新建一个非核心线程来完成任务  当设置corePoolSize=maximumPoolSize时，你将获得一个固定容量的线程池；当将maxPoolSize设置为Integer.MAX_VALUE时，线程数没有限制，这有可能造成内存泄漏。\n尽管在构建线程池实例时要指定corePoolSize和maximumPoolSize，在获得实例之后还可以通过setCorePoolSize(int)和setMaximumPoolSize(int)来对其进行修改4。\n默认情况下，当线程池初始化成功之后，池中是没有任何线程的。不过，可以调用prestartCoreThread()和prestartAllCoreThreads()来向线程池中添加一个或所有核心线程。如果你使用一个非空的任务队列初始化线程池，这样做是有用的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  @SneakyThrows void initPoolWithNonEmptyQueue() { BlockingQueue\u0026lt;Runnable\u0026gt; queue = new ArrayBlockingQueue\u0026lt;Runnable\u0026gt;(2) {{ add(() -\u0026gt; { System.out.println(\u0026#34;1st task done\u0026#34;); }); add(()-\u0026gt;{ System.out.println(\u0026#34;2nd task done\u0026#34;); }); }}; ThreadPoolExecutor.AbortPolicy abortPolicy = new ThreadPoolExecutor.AbortPolicy(); ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(1, 1, 0, TimeUnit.MILLISECONDS, queue, abortPolicy); poolExecutor.prestartCoreThread(); poolExecutor.shutdown(); } /* output 1st task done 2nd task done *///:~   使用prestartCoreThread()还有一个好处，它可以保证队列中的任务顺序执行。\n创建新线程 线程池中的线程使用线程工厂ThreadFactory创建，如果没有指定，将使用Executors.defaultThreadFactory。如果线程工厂在创建线程时失败而返回null，那么线程池将无法执行任何任务。\n存活时间 keepAliveTime针对的是非核心线程，非核心线程处理完任务后，若在keepAliveTime内没有新任务添加到队列并被其获取并运行，其将被销毁。这是一种资源保护策略，如果线程池的任务突然增多，可能又会创建非核心线程来完成任务。当corePoolSize = maximumPoolSize时，线程池无法创建非核心线程，此时keepAliveTime参数可能没有意义，一般将其设置为0。\n但凡事并非绝对，ThreadPoolExecutor维护一个布尔型变量allowCoreThreadTimeOut，其默认值是false，用来控制核心线程池的“生命”：\n1 2 3 4 5 6  /** * If false (default), core threads stay alive even when idle. * If true, core threads use keepAliveTime to time out waiting * for work. */ private volatile boolean allowCoreThreadTimeOut;   这个变量的值由allowCoreThreadTimeOut(boolean value)方法修改\n1 2 3 4 5 6 7 8 9  public void allowCoreThreadTimeOut(boolean value) { if (value \u0026amp;\u0026amp; keepAliveTime \u0026lt;= 0) throw new IllegalArgumentException(\u0026#34;Core threads must have nonzero keep alive times\u0026#34;); if (value != allowCoreThreadTimeOut) { allowCoreThreadTimeOut = value; if (value) interruptIdleWorkers(); } }   可以看到，如果将变量allowCoreThreadTimeOut的值设置为true，那么空闲的核心线程池也将会在keepAliveTime超时之后被销毁(如果没有任务让其执行)。\n任务队列 任务队列是一个阻塞队列，一个线程池中只有一个任务队列。任务队列用于缓存当前尚没有线程可执行之的任务，其和线程池之间存在如下的交互关系：\n 如果当前工作线程 \u0026lt; corePoolSize，线程池将创建新线程执行任务而非将任务放入队列 如果当前工作线程 \u0026gt; corePoolSize，线程池倾向于将任务放入队列而非创建新线程执行之 如果任务无法放入队列（满），并且当前工作线程 \u0026lt; maximumPoolSize，将创建新线程执行之，否则任务将被拒绝  任务队列有3种常见实现：\n  直接运行(direct handoffs)，这种情形的任务队列一般由SynchronousQueue实现，这种队列的实现对线程池的要求严苛，如果没有可用的线程即刻执行任务，那么将任务放入队列将失败。在此情形下，一般将maximumPoolSize设置为Integer.MAX_\nVALUE以防止线程池拒绝任务。这种实现可能会导致内存泄漏。\n  无界任务队列， 一般由LinkedBlockingQueue实现，这种情形下，当当前工作线程达到corePoolSize之后，所有新提交的任务都会放入队列中，由于队列无界，就不会再创建新线程了，也不会拒绝任务。因此maximumPoolSize这一设置将无意义。如果任务源源不断地提交，有可能任务积压导致内存泄漏。\n  有界队列，一般由ArrayBlockingQueue实现，使用有界队列可以避免资源耗尽，但是也增加了配置的难度，是应该配置更多的线程数更小的队列还是应该配置更大的队列更少的线程数，往往需要根据具体的任务来考量。\n  拒绝策略 前面提到，如果线程池满载，新提交的任务就会被线程池拒绝执行；同样的，如果线程池关闭了，提交任务也会被拒绝。线程池通过调用RejectedExecutionHandler.rejectedExecution(Runnable, ThreadPoolExecutor)来拒绝任务，ThreadPoolExecutor内建了4种不同的拒绝策略：\n1） ThreadPoolExecutor.AbortPolicy，也是默认的拒绝策略，该策略直接抛出RejectedExecutionException的运行时异常\n1 2 3 4 5  public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(\u0026#34;Task \u0026#34; + r.toString() + \u0026#34; rejected from \u0026#34; + e.toString()); }   2） ThreadPoolExecutor.CallerRunsPolicy，如果线程池未关闭，该策略直接在执行execute()方法的线程上运行任务，否则该任务被丢弃\n1 2 3 4 5  public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { r.run(); } }   3）ThreadPoolExecutor.DiscardPolicy，该策略直接丢弃不能被执行的任务\n1 2  public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { }   4）ThreadPoolExecutor.DiscardOldestPolicy，如果线程池未关闭，则将队列头部的任务丢弃，然后继续执行execute(Runnable)方法\n1 2 3 4 5 6  public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { e.getQueue().poll(); e.execute(r); } }   2.2.3 工厂方法构建的实例 Executors的三个方法(没有包含重载方法)返回该类的实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } /* 构建一个固定容量的线程池，该线程池的线程都是核心线程，任务队列使用无界队列；当线程数达到 corePoolSize时，新提交的任务都将放入队列，这个线程池不会拒绝任务*/ public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;()); } /* 构建一个corePoolSize为0，maximumPoolSize无限制的线程池，线程池中的线程都是非核心线程， 当线程空闲超过60s后即被销毁，这个线程池的任务队列使用的是SynchronousQueue，因此一旦提交任务， 即会创建一个线程去执行之*/ public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); } /* 构建一个corePoolSize = maximumPoolSize = 1的线程池，该线程池只有一个核心线程，任务 队列为无界队列，因此当核心线程已被创建后，所有提交的任务都放入队列，这个线程池不会拒绝任务。与 第一个静态方法不同的是，由于其使用FinalizableDelegatedExecutorService包装 ThreadPoolExecutor，这个线程池一旦初始化，不允许再进行动态配置*/   如上所示，前2个静态方法构造的都是特殊的ThreadPoolExecutor实例，初始化成功之后，都是可以通过ThreadPoolExecutor的实例方法进行动态配置的。\n第3个静态方法有所不同，其生成了一个容量为1且不可改变的线程池，严格来说，它返回的不是ThreadPoolExecutor实例，而是由ThreadPoolExecutor包装的FinalizableDelegatedExecutorService实例，FinalizableDelegatedExecutorService是Executors类（仅具有包访问权限）的内部类，FinalizableDelegatedExecutorService类继自DelegatedExecutorService，这是一个仅仅有ExecutorService接口方法的包装类，因此，当我们调用newSingleThreadExecutor()方法时，仅可以将其声明为ExecutorService。\n1 2 3 4  ExecutorService service = Executors.newSingleThreadExecutor(); // ！非法，不能强制类型转换 ThreadPoolExecutor pool = (ThreadPoolExecutor)Executors.newSingleThreadExecutor();   正因为其是一个仅仅可以执行ExecutorService接口方法的包装类，其无法在线程池初始化之后再动态配置。\n扩展阅读: ThreadPoolExecutor jdk1.8 Javadoc\n2.4 CompletionService 在提交单个任务时，使用submit()或者execute()方法或许能够满足要求，但如果需要控制多个任务时，依次提交的操作看起来“有些繁琐”，此时我们可以使用ExecutorService提供的invokeAny/invokeAll方法，在介绍CompletionService接口时，我们不妨先看看这两个方法。\n之前介绍AbstractExecutorService时提到，这两个方法是在这个抽象类中实现的，其中前者在获取到一个任务的返回值时便取消其他（未执行或正在执行的任务）任务，而后者需要等待所有的任务执行完成之后才能对任务的返回进行处理，接下来我们分别来看：\ninvokeAll会阻塞等待所有的任务执行完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114  public \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException { if (tasks == null) throw new NullPointerException(); ArrayList\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt;(tasks.size()); boolean done = false; try { for (Callable\u0026lt;T\u0026gt; t : tasks) { RunnableFuture\u0026lt;T\u0026gt; f = newTaskFor(t); futures.add(f); execute(f); } // 有序迭代  for (int i = 0, size = futures.size(); i \u0026lt; size; i++) { Future\u0026lt;T\u0026gt; f = futures.get(i); if (!f.isDone()) { try { // 阻塞等待任务执行完成  f.get(); } catch (CancellationException ignore) { } catch (ExecutionException ignore) { } } } done = true; return futures; } finally { if (!done) // 处理因异常而未正常执行的任务  for (int i = 0, size = futures.size(); i \u0026lt; size; i++) futures.get(i).cancel(true); } } // invokeAny public \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException, ExecutionException { try { return doInvokeAny(tasks, false, 0); } catch (TimeoutException cannotHappen) { assert false; return null; } } private \u0026lt;T\u0026gt; T doInvokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException { if (tasks == null) throw new NullPointerException(); int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); ArrayList\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt;(ntasks); ExecutorCompletionService\u0026lt;T\u0026gt; ecs = new ExecutorCompletionService\u0026lt;T\u0026gt;(this); try { // Record exceptions so that if we fail to obtain any  // result, we can throw the last exception we got.  ExecutionException ee = null; final long deadline = timed ? System.nanoTime() + nanos : 0L; Iterator\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; it = tasks.iterator(); // Start one task for sure; the rest incrementally  futures.add(ecs.submit(it.next())); --ntasks; int active = 1; for (;;) { // 并没阻塞第一个任务，此时可能第一个任务还未执行完  Future\u0026lt;T\u0026gt; f = ecs.poll(); if (f == null) { if (ntasks \u0026gt; 0) { --ntasks; // 不等待上一个任务的结果，直接新执行一个任务  futures.add(ecs.submit(it.next())); ++active; } else if (active == 0) break; else if (timed) { f = ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); } else // 没有可执行的任务了，则等待一个结果  f = ecs.take(); } // 有结果则返回  if (f != null) { --active; try { return f.get(); } catch (ExecutionException eex) { ee = eex; } catch (RuntimeException rex) { ee = new ExecutionException(rex); } } } if (ee == null) ee = new ExecutionException(); throw ee; } finally { for (int i = 0, size = futures.size(); i \u0026lt; size; i++) // 取消还未执行或者执行中的任务  // 中断任务  futures.get(i).cancel(true); } }   可以看到，与invokeAll不同的是，invokeAny方法是在循环的启动任务，直到获取到任一任务的返回值为止，而未执行或正在执行的任务则会被中断。\n下面的示例中，我们修改了阻塞队列-查找关键字应用，让任务在成功搜寻到含有关键字的文件时就视为任务完成，取消其他任务的执行，这样一种场景之下，我们可以使用invokeAny方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109  public class Search1Keyword extends SearchKeyword { String empty = \u0026#34;\u0026#34;; public static void main(String[] args) { Search1Keyword s1k = new Search1Keyword(); s1k.find(); } @Override void find() { // 带资源的try块  try (Scanner in = new Scanner(System.in)) { System.out.print(\u0026#34;Enter keyword (e.g. volatile): \u0026#34;); keyword = in.nextLine(); Producer p = new Producer(); List\u0026lt;Callable\u0026lt;String\u0026gt;\u0026gt; tasks = new ArrayList\u0026lt;\u0026gt;(); ExecutorService pool = Executors.newCachedThreadPool(); for (int i = 1; i \u0026lt;= 10; i++) { // run consumer  tasks.add(new Consumer1()); } pool.execute(p); // 此方法并不那么单纯，其结果只取一个，但是任务可能执行了多个  String res = pool.invokeAny(tasks); System.out.println(res); pool.shutdown(); } catch (Exception e) { e.printStackTrace(); } } class Consumer1 implements Callable\u0026lt;String\u0026gt; { @Override public String call() throws Exception { try { while (!done) { File file = queue.take(); if (file == DUMMY) { done = true; } else { String s = search1(file, keyword); if (s.length() \u0026gt; 0) { return s; } } } } catch (Exception e) { // ignore  } return empty; } } public String search1(File file, String keyword) throws FileNotFoundException { StringBuilder sb = new StringBuilder(\u0026#34;\u0026#34;); try (Scanner in = new Scanner(file, \u0026#34;UTF-8\u0026#34;)) { int lineNumber = 0; while (in.hasNextLine()) { if (!Thread.interrupted()) { lineNumber++; String line = in.nextLine(); if (line.contains(keyword)) { sb.append(\u0026#34;[\u0026#34;).append(Thread.currentThread().getName()).append(\u0026#34;]: \u0026#34;) .append(file.getPath()).append(lineNumber).append(line).append(\u0026#34;\\n\u0026#34;); } } else { // thread interrupted by future.cancel()  System.out.printf(\u0026#34;[%s] %s%n\u0026#34;, Thread.currentThread().getName(), \u0026#34; interrupted\u0026#34;); return empty; } } } return sb.toString(); } } /* output (sample1) Enter keyword (e.g. volatile): take [pool-1-thread-5]: TestBlockingQueue.java39 LiftOff take() throws InterruptedException { [pool-1-thread-5]: TestBlockingQueue.java40 return rockets.take(); [pool-1-thread-5]: TestBlockingQueue.java65 LiftOff rocket = take(); [pool-1-thread-5]: TestBlockingQueue.java78 System.out.println(\u0026#34;Interrupted during take()\u0026#34;); [pool-1-thread-11] interrupted [pool-1-thread-10] interrupted [pool-1-thread-6] interrupted [pool-1-thread-4] interrupted [pool-1-thread-9] interrupted [pool-1-thread-3] interrupted [pool-1-thread-7] interrupted [pool-1-thread-8] interrupted (sample2) Enter keyword (e.g. volatile): take [pool-1-thread-4]: Search1Keyword.java66 File file = queue.take(); [pool-1-thread-2] interrupted [pool-1-thread-10] interrupted [pool-1-thread-8] interrupted [pool-1-thread-5] interrupted [pool-1-thread-11] interrupted [pool-1-thread-7] interrupted [pool-1-thread-9] interrupted */   我们将对一个包含关键字的文件进行的完整搜寻视为任务结束，虽然还可能有其他文件还有关键字，但是搜寻任务不再执行。从输出可以看到，输出的只包含一个文件的关键字信息。另外，我们使用10个任务，其中sample1中其他9个任务都被中断，而sample2中只有7个任务被interrupt，说明情况1中，所有的任务都开始执行了，而情况2中，还有未开始执行的任务(其永远不能执行了)。\n试着思考一个问题，既然invokeAny只需要获取一个任务的返回值即可，那为什么不直接启动第一个任务然后阻塞获取其返回值，而要启动（那么）多任务呢？启动一个任务不是更加简单么？\n我们分析源码时，发现invokeAny使用了ExecutorCompletionService，这个类继承自接口CompletionService，可以用来管理任务提交之后的Future\u0026lt;T\u0026gt;对象——将已经完成的Future其放在一个阻塞队列中取用，这样我们就可以回答上面的问题了：\ninvokeAny利用ExecutorCompletionService提交任务，并管理任务的返回，这样可以避免单独启动一个任务而需要阻塞很长时间的弊端，启动的多个任务只要有一个任务完成，其放置已完成Future的阻塞队列将变得可用而使invokeAny快速结束。\nExecutorCompletionService的快速用法为:\n1 2 3 4 5 6 7 8  ExecutorCompletionService\u0026lt;T\u0026gt; ecs = new ExecutorCompletionService\u0026lt;\u0026gt;(executor) ; for(Callable\u0026lt;T\u0026gt; task : tasks){ ecs.submit(task); } for (int i = 0; i \u0026lt; tasks.size() ; i++ ) { // get return value  ecs.take().get(); }   3 线程池 前文说过，ThreadPoolExecutor实例代表了Java线程池，前面我们介绍了ThreadPoolExecutor的构造器和几个核心概念，在本节中，我们着重介绍线程池的执行过程以及线程池的关闭。\n3.1 线程池的运行状态 线程池的运行状态表示了线程池的生命周期，在代码实现中它们使用用一个整数表示：\n   状态 描述     RUNNING 接受新任务的提交，执行队列中的任务   SHUTDOWN 不接受新任务的提交，执行队列中的任务   STOP 不接受新任务的提交，不执行队列中的任务，中断正在执行的任务   TIDYING 所有任务终止，workerCount = 0 ，执行terminated()方法   TERMINATED terminated()方法执行完毕    为了方便地判断线程池的运行状态，给上述线程池状态约定了单调的演化关系：\n   状态变化 条件     RUNNING -\u0026gt; SHUTDOWN 调用shutdown()方法，或者隐式调用了finalize()5   (RUNNING或SHUTDOWN) -\u0026gt; STOP 调用shutdownNow()方法   SHUTDOWN -\u0026gt; TIDYING 当线程池和任务队列都为空时   STOP -\u0026gt; TIDYING 线程池为空   TIDYING -\u0026gt; TERMINATED 当terminated()方法执行完成    可以看到，线程池的状态是单调演化的，除了RUNNING状态可以接受任务并执行外，其他的状态都将导致线程池资源关闭。ThreadPoolExecutor类中有几个获取线程池状态的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  /** 若线程池的状态不是RUNNING，那么该方法就返回true*/ public boolean isShutdown() { return ! isRunning(ctl.get()); } /** 若线程池的状态不是RUNNING，并且状态没有还没有切换到TERMINATED，该方法就返回true 这个方法返回true说明线程池正处于terminae的过程中*/ public boolean isTerminating() { int c = ctl.get(); return ! isRunning(c) \u0026amp;\u0026amp; runStateLessThan(c, TERMINATED); } /** 若线程的状态为TERMINATED，该方法返回true*/ public boolean isTerminated() { return runStateAtLeast(ctl.get(), TERMINATED); }   3.2 线程池中任务的执行过程 了解了线程池的工作状态，接下来我们尝试去深入任务是如何在线程池中被执行的，以及线程池中核心线程，任务队列以及非核心线程之间是如何协同工作的。\n在任务队列中，我们阐述了任务队列与线程池之间存在交互关系，这种交互关系体现了线程池执行任务的重要过程。\n -- 线程池执行流程图:   上面的流程图展示了任务提交到线程池到执行或被拒绝的过程，和在任务队列中的描述相当，接下来我们从源码的角度阐述这一过程。\n3.2.1 提交任务 在介绍ExecutorService时我们提到了AbstractExecutorService基类，它有两个重要的作用：\n 将所有的任务提交转变为执行一个FutureTask 实现了invokeAny/invokeAll方法  了解到这一点之后，我们将线程池的任务执行重心放在ThreadPoolExecutor的execute(Runnable)方法上：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125  public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // 当前工作线程数 \u0026lt; corePoolSize  if (workerCountOf(c) \u0026lt; corePoolSize) { // 直接添加新的工作线程执行之  if (addWorker(command, true)) return; // 若新建失败，则表示rs \u0026gt;= shutdown，任务将会被拒绝  c = ctl.get(); } // 否则将任务放入队列  if (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) { // 线程状态RUNNING，任务已放入队列  // double check  int recheck = ctl.get(); // 这里double-check的原因是：  if (! isRunning(recheck) \u0026amp;\u0026amp; remove(command)) // 1. 线程池可能被shutdown了，这时候直接从队列移除任务并拒绝之  reject(command); else if (workerCountOf(recheck) == 0) // 2. 若corePoolSize = 0，而非核心线程都完成了任务  // 空闲线程超时被销毁之后，就可能出现workerCount = 0 的情况  // 此时添加一个非核心线程去执行队列中的任务  addWorker(null, false); } // 队列满了，则尝试新建一个非核心线程执行任务，否则拒绝之  else if (!addWorker(command, false)) reject(command); } /**使用Worker包装线程来执行任务*/ private boolean addWorker(Runnable firstTask, boolean core) { // 循环判断，直到满足新建Worker的条件为止  retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary.  // 解释一下这个return false的逻辑  /* 1. 若rs = runnning，继续添加worker * 2. 若rs \u0026gt;= shutdown * 2.1 rs \u0026gt;= stop 不新建worker(return false) * 2.2 rs = shutdown，firstTask != null，不新建worker (shutdown之后不接受新任务提交) * 2.3 rs = shutdown，firstTask = null，workQueue为空，不新建worker */ if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; ! (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null \u0026amp;\u0026amp; ! workQueue.isEmpty())) return false; for (;;) { int wc = workerCountOf(c); if (wc \u0026gt;= CAPACITY || wc \u0026gt;= (core ? corePoolSize : maximumPoolSize)) // 线程数量超限  return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl  if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop  } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); /* Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } */ final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock.  // Back out on ThreadFactory failure or if  // shut down before lock acquired.  int rs = runStateOf(ctl.get()); // 状态为RUNNING时可以新建Worker执行任务  // 状态为SHUTDOWN时，任务必须为空(不可提交任务)  if (rs \u0026lt; SHUTDOWN || (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable  throw new IllegalThreadStateException(); // 调整字段值  workers.add(w); int s = workers.size(); if (s \u0026gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } // 运行任务  if (workerAdded) { // 从Worker的构造器来看，线程t的构造器参数是Worker  // 因此start()实际上执行的是Worker的run()方法  t.start(); workerStarted = true; } } } finally { // 线程池创建线程失败，清理资源  if (! workerStarted) addWorkerFailed(w); } // 返回true表示线程已创建并启动  // 根据调用参数的不同，启动的线程可能直接执行任务  // 也可能从队列中获取任务执行  return workerStarted; }   线程池添加worker的流程:   3.2.2 创建空线程 前面介绍核心概念的时候说到，线程池初始化成功之后，池中是没有活动线程的，不过线程池具有很好的灵活性，可以进行动态配置。使用prestartCoreThread()和prestartAllCoreThreads()方法可以向线程池中添加核心线程，这些线程并没有使用任务初始化，不过其会尝试去队列中获取任务执行，若队列为空，这些线程就会挂起(waiting)6。\n1 2 3 4 5 6 7 8 9 10 11 12  /** 创建一个核心线程*/ public boolean prestartCoreThread() { return workerCountOf(ctl.get()) \u0026lt; corePoolSize \u0026amp;\u0026amp; addWorker(null, true); } /** 创建所有核心线程*/ public int prestartAllCoreThreads() { int n = 0; while (addWorker(null, true)) ++n; return n; }   3.2.3 执行任务 线程池创建线程是为了执行任务，addWorker()方法成功时会启动线程，线程则会调用Worker的run()方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  public void run() { runWorker(this); } /**该方法会循环进行，并且在getTask()方法处阻塞*/ final void runWorker(Worker w) { Thread wt = Thread.currentThread(); // 任务即为创建Worker的入参  Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts  boolean completedAbruptly = true; try { // 只要有任务提交或队列不为空，则一直执行  while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted;  // if not, ensure thread is not interrupted. This  // requires a recheck in second case to deal with  // shutdownNow race while clearing interrupt  // 如果线程池状态为STOP（调用shutdownNow()），则中断线程  if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() \u0026amp;\u0026amp; runStateAtLeast(ctl.get(), STOP))) \u0026amp;\u0026amp; !wt.isInterrupted()) wt.interrupt(); try { // 可扩展方法  beforeExecute(wt, task); Throwable thrown = null; try { task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { // 可扩展方法  afterExecute(task, thrown); } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { // while循环结束后的动作  processWorkerExit(w, completedAbruptly); } } /** 该方法从队列中获取任务，方法会被阻塞(核心线程)或超时阻塞（非核心线程）*/ private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out?  for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary.  // 如果状态为SHUTDOWN，但队列不为空，仍从队列中执行任务  // 如果状态为STOP，则直接return null  if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; (rs \u0026gt;= STOP || workQueue.isEmpty())) { // workerCount - 1  decrementWorkerCount(); return null; } int wc = workerCountOf(c); // Are workers subject to culling?  // 当allowCoreThreadTimeOut被设置时，核心线程超时阻塞  boolean timed = allowCoreThreadTimeOut || wc \u0026gt; corePoolSize; if ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { // 阻塞队列获取队头任务  Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; // 超时未获取到任务 --\u0026gt; line 79 --\u0026gt; return null  timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } }   线程池执行任务的流程:   可以看到，线程池中的线程初始化之后，其执行任务的过程是阻塞的，也就是说，线程池中的线程一直处于“stand by”状态，除此之外，我们还可以得到以下信息：\n 如果没有设置allowCoreThreadTimeOut，核心线程执行任务的过程将一直进行 非核心线程的执行任务的过程将在超时之后，方法不返回，循环再次进行，将在try块之前的if语句块中返回null 当线程池状态为SHUTDOWN时，若队列不为空，仍会去队列中获取任务执行；若状态为STOP，将不会从队列中获取任务  当出现下列任一情况时，getTask()会返回null结束线程运行：\n workerCount \u0026gt; maximumPoolSize，一般在动配置maximumPoolSize之后出现 线程池状态为STOP 线程池状态为SHUTDOWN，且队列为空 当线程获取队列中的任务超时，且该线程不是队列中的唯一线程或队列为空  前面3点都比较好理解，第4点有点难以理解，我们使用一个corePoolSize=0的线程池特例加以说明：\n1 2 3 4 5 6 7 8 9  void cachedPool(){ ThreadPoolExecutor service = (ThreadPoolExecutor) Executors.newCachedThreadPool(); // service 5秒之后即关闭  service.setKeepAliveTime(5,TimeUnit.SECONDS); service.submit(()-\u0026gt;{ System.out.println(\u0026#34;task done\u0026#34;); }); }   我们知道，newCachedThreadPool构建一个corePoolSize=0的线程池，因此池中所有的任务在空闲超时都会被超时销毁，我们不妨来看看这一过程是如何发生的；我们将keepAliveTime重新设置为5s，并且向线程池中提交一个任务。\n 线程池首先会新建一个线程执行任务，调用的是addWorker(firstTask, false)方法；\n在runWorker的第二次循环时，由于firstTask已经被执行，将调用getTask()方法去队列中获取任务。我们知道队列中没有任务，超时时间为5s，5s之后getTask()方法将timeout置为true后进入第二次循环；\n注意此次循环：\n1 2 3 4 5 6  if ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; }   不难看出来，第一次wc =1 并且timeout=false，显然是不满足if的条件；第二次则不同，timeout此时为true，workQueue.isEmpty为true，if条件满足；\n此时将 wc-1，并且返回null\n 返回null之后，runWorker()方法的while循环也会结束，接下来会执行processWorkerExit(w, completedAbruptly)方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  /**while循环正常结束，completedAbruptly为false*/ private void processWorkerExit(Worker w, boolean completedAbruptly) { if (completedAbruptly) // If abrupt, then workerCount wasn\u0026#39;t adjusted  decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 统计已经完成的任务数  completedTaskCount += w.completedTasks; // 将Worker从HashSet中移除  workers.remove(w); } finally { mainLock.unlock(); } // 正如其名，「尝试」终止线程池  tryTerminate(); int c = ctl.get(); // 若线程池状态为RUNNING or SHUTDOWN  if (runStateLessThan(c, STOP)) { if (!completedAbruptly) { // 线程池中的最小线程数  int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 \u0026amp;\u0026amp; ! workQueue.isEmpty()) //队列非空时，要保证池中有线程运行任务  min = 1; if (workerCountOf(c) \u0026gt;= min) // 池中还有线程，可以安心返回  return; // replacement not needed  } // 否则，向池中加入一个线程  addWorker(null, false); } }   在上面方法的最后if条件中，wc=min=0，池中没有线程并且任务队列为空，线程成功完成使命，结束运行。\n综上所述，被创建的线程除了执行被提交的任务之外，还会被阻塞执行队列中的任务，而核心线程和非核心线程在空闲时又会存在处理方式的差异。\n值得一提的是，在上面的newFixedThreadPool()的例子中，线程池提交完任务之后，并没有调用关闭方法，那么线程池能关闭么？\n通过上面的分析，例子中的线程在执行完任务后超时被销毁，此时池中没有线程在运行，队列中也没有任务，那么就意味着所有的逻辑都已经完成，并没有发生阻塞，线程池中的线程数为0，任务队列为空，虽然如此，线程池的状态还是RUNNING！线程池并没有终止，其还可以继续提交任务运行，实际上，线程池回到了初始化 时的状态。\n3.3 如何合理地关闭线程池 ThreadPoolExecutor提供了2个关闭线程池的方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 检查权限  checkShutdownAccess(); // 修改线程池状态为SHUTDOWN  advanceRunState(SHUTDOWN); // 中断所有空闲（waiting）的线程  // 在condition.await()上阻塞的线程能够响应中断，这就是线程池能够关闭而不阻塞的原因  // 阻塞的线程被中断唤醒后继续在getTask()上继续执行，在线程池状态判断时return null而结束  interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor  } finally { mainLock.unlock(); } // 执行terminated()（空）方法，将线程状态设置为TERMINATED  tryTerminate(); } public List\u0026lt;Runnable\u0026gt; shutdownNow() { List\u0026lt;Runnable\u0026gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 权限检查  checkShutdownAccess(); // 修改线程池状态为STOP  advanceRunState(STOP); // 中断所有线程  interruptWorkers(); // 队列中未执行的任务  tasks = drainQueue(); } finally { mainLock.unlock(); } tryTerminate(); return tasks; } final void tryTerminate() { for (;;) { int c = ctl.get(); /*直接返回的条件： * 1. 线程池状态为RUNNING * 2. 线程池状态为 TIDYING 或 TERMINATED * 3. 线程状态为 SHUTDOWN， 且队列不为空 */ if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN \u0026amp;\u0026amp; ! workQueue.isEmpty())) return; // 若工作线程数 \u0026gt; 0 , 中断一个空闲线程并返回  if (workerCountOf(c) != 0) { // Eligible to terminate  interruptIdleWorkers(ONLY_ONE); return; } final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 设置线程池状态为TIDYING  if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { // 运行terminated()方法  terminated(); } finally { // 设置线程状态为TERMINATED  ctl.set(ctlOf(TERMINATED, 0)); // 唤醒awaitTermination方法  termination.signalAll(); } return; } } finally { mainLock.unlock(); } // else retry on failed CAS  } }   从上面的分析，我们可以清晰地看到shutdown()和shutdownNow()的区别，前者只中断了空闲线程，后者中断了所有线程；结合前文getTask()方法的表述，前者未被中断的线程还可继续执行并从任务队列中获取任务执行，而后者已经无法从队列中获取任务执行了，这与本节开头对线程池的运行状态的描述一致。\nshutdown()和shutdownNow()方法都不能中断正在执行的任务，不过后者对正在执行的任务发送了中断命令，如果任务能够响应中断，即可以作出相应操作。如果想在shutdown()或shutdownNow()执行之后继续获取任务的返回值，只能使用awaitTermination()方法愚蠢地等待。awaitTermination()方法阻塞当前调用该方法的线程，直到任务执行完毕、超时、调用线程被中断3者任一条件发生。\n需要说明的是，如果awaitTermination()阻塞过程中线程池的状态变为TERNMINATD，说明任务执行完毕，返回true；否则返回false或抛出中断异常。\n下面的示例代码演示了shutdown()和shutdownNow()方法的区别：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102  public class ExecutorShutdown { static int pointer = 0; /** 容量为1的线程池，其能保证提交的任务都是序列化执行的 */ ThreadPoolExecutor service = (ThreadPoolExecutor) Executors.newFixedThreadPool(1); @SneakyThrows public static void main(String[] args) { ExecutorShutdown es = new ExecutorShutdown(); es.shutdown(); // es.awaitTermination(1, TimeUnit.SECONDS);  } void shutdown() { service.execute(new ComplexTask()); // 对于newFixedThreadPool(1),EasyTask在任务队列中  service.execute(new EasyTask()); service.shutdown(); // shutdown之后，任务并没有执行完成，pointer的值还是0  System.out.println(\u0026#34;pointer:\u0026#34; + pointer); // 获取待任务队列  System.out.println(\u0026#34;workQueue: \u0026#34; + service.getQueue()); // 判断该执行器是否被关闭  System.out.println(\u0026#34;is executor shutdown? \u0026#34; + service.isShutdown()); // 执行器关闭之后所有任务是否都完成  // 如果没有调用shutdown()或shutdownNow()就直接调用isTerminated()，该方法必返回false  System.out.println(\u0026#34;is executor terminated? \u0026#34; + service.isTerminated()); System.out.println(\u0026#34;pointer:\u0026#34; + pointer); } void awaitTermination(int timeout, TimeUnit unit) { service.execute(new ComplexTask()); service.execute(new EasyTask()); List\u0026lt;Runnable\u0026gt; tasks; try { if (service.awaitTermination(timeout, unit)) { service.shutdown(); } else { if(!(tasks = service.shutdownNow()).isEmpty()){ System.out.println(\u0026#34;丢弃任务\u0026#34; + tasks); } } } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;workQueue: \u0026#34; + service.getQueue()); System.out.println(\u0026#34;is executor shutdown? \u0026#34; + service.isShutdown()); System.out.println(\u0026#34;is executor terminated? \u0026#34; + service.isTerminated()); } abstract class Task { @Override public String toString() { return getClass().getSimpleName() + \u0026#34;@\u0026#34; + Integer.toHexString(hashCode()); } } class ComplexTask extends Task implements Runnable { @Override public void run() { // 响应中断，调用shutdownNow()可以结束任务  System.out.println(\u0026#34;[\u0026#34; + Thread.currentThread() + \u0026#34;@\u0026#34; + this + \u0026#34;]，开始执行\u0026#34;); // never finish unless interrupted  for (; ; ) { if (!Thread.interrupted()) { pointer++; } else { System.out.println(\u0026#34;[\u0026#34; + Thread.currentThread() + \u0026#34;@\u0026#34; + this + \u0026#34;]，被中断\u0026#34;); break; } } } } class EasyTask extends Task implements Runnable { @Override public void run() { System.out.println(\u0026#34;[\u0026#34; + Thread.currentThread() + \u0026#34;@\u0026#34; + this + \u0026#34;]，开始执行\u0026#34;); pointer++; System.out.println(\u0026#34;[\u0026#34; + Thread.currentThread() + \u0026#34;@\u0026#34; + this + \u0026#34;]，执行完成\u0026#34;); } } } /* output 调用shutdown： [Thread[pool-1-thread-1,5,main]@ComplexTask@48d82c9c]，开始执行 pointer:0 workQueue: [EasyTask@14ae5a5] is executor shutdown? true is executor terminated? false pointer:813 调用awaitTermination： [Thread[pool-1-thread-1,5,main]@ComplexTask@7ac59a98]，开始执行 [Thread[pool-1-thread-1,5,main]@ComplexTask@7ac59a98]，被中断 丢弃任务[EasyTask@7f31245a] workQueue: [] is executor shutdown? true is executor terminated? true *///:~   上例中我们设计了一个可以正常执行的任务EasyTask和一个无限循环执行的任务ComplexTask，后者响应中断，如果不中断线程，ComplexTask将一直运行下去。我们使用一个固定容量为1的线程池运行任务，并且先提交ComplexTask，ComplexTask无法结束运行，那么EasyTask将会放入队列中。\n从运行的结果上来看，使用shutdown()无法结束线程池的运行，虽然主线程结束，但线程池一直在后台运行，同时EasyTask也还在任务队列中，主线程结束后线程池的还没有终止，程序会一直在后台运行。\n当调用awaitTermination(timeout, unit)时，很明显这个方法将超时并返回false，最终执行shutdownNow()，shutdownNow给ComplexTask任务发送中断命令，其在下一次循环检查到中断，结束执行。同时任务队列中的EasyTask被丢弃，任务队列为空，主线程结束后，线程池也成功终止。\n如果ComplexTask在设计时，没有响应中断，而使用死循环执行任务，那么shutdownNow()方法仍然无法终止线程池，这就是官方文档中关于shutdownNow()方法描述的语义：\n There are no guarantees beyond best-effort attempts to stop\nprocessing actively executing tasks. This implementation\ncancels tasks via {@link Thread#interrupt}, so any task that\nfails to respond to interrupts may never terminate.\n  表中没有提及关于构建Fork/Join线程池的方法，这部分内容将在后续补全 \u0026#x21a9;\u0026#xfe0e;\n 须调用合适的构造器，实际上所有参数必须提供，不过有些由构造器默认提供了 \u0026#x21a9;\u0026#xfe0e;\n 本文约定当前工作线程指代线程池中存在的线程（getPoolSize()方法的返回值），其中可能存在部分空闲线程。当工作线程数小于核心线程数时：1）当前线程池中的线程全是核心线程；2）任务队列一定是空的；3）当前某个线程可能是空闲的(执行完任务，在等待队列中的任务（runWorker方法阻塞）) \u0026#x21a9;\u0026#xfe0e;\n 类似地，存活时间，线程工厂，拒绝策略都可以在线程池初始化之后再进行设置 \u0026#x21a9;\u0026#xfe0e;\n 目前作者还未找到隐式调用finalize()方法导致线程池关闭的例证 \u0026#x21a9;\u0026#xfe0e;\n 若corePoolSize=0，这些方法不会创建线程 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文详细介绍了Java并发框架中的执行器和线程池，是线程池系列的第一篇。","id":20,"section":"posts","tags":["执行器","线程池"],"title":"执行器与线程池","uri":"http://wangy325.top/zh/posts/java/concurrency/%E6%89%A7%E8%A1%8C%E5%99%A8%E4%B8%8E%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"content":"Java有能力使任务为等待某些条件成立而进入阻塞状态，所以就有可能出现这样一种情况：某个任务在等待另一个任务，而后者又在等待其他的任务，这样一直等待下去，直到等待链上的最后一个任务又在等待第一个任务释放锁，这样就出现了任务之间相互等待的连续循环现象，这种情况出现之后，没有哪个任务能够执行，于是 死锁 出现\n死锁之所以难以规避，其重要的原因就在于其不确定性，可能程序运行良好，但是有潜在的死锁风险，这个风险在某些域的初始条件变化时，变得特别大，导致程序很快死锁。同时，死锁的出现也很难复现，它就像埋在程序里的地雷\n我们不妨回顾在转账问题中使用的等待条件——如账户余额不足时使任务等待，在余额足够的时候再进行转账。这个程序没有问题，因为有100个账户每个账户初始金额1000元，而转账金额不大于初始金额，所以任一时刻都会有账户的金额满足转账条件。但是如果去除转账金额不大于1000的限制，死锁就会发生，这很容易理解\n比如有2个账户\n账户1 余额200元 账户2 余额300元  账户1向账户2转账300元，余额不足，等待；账户2向账户1转账400，余额不足等待；程序就进入死锁\n抢票问题 下面的示例模拟一个放票与抢票的场景，单线程的放票任务与多线程的抢票任务同时执行，直到停止放票并且所有票售罄程序结束。为了尽可能让更多的任务抢到票，任务中做了特殊处理\n程序使用了Callable接口和ThreadLocal来获取每个任务抢到的票数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156  public class TicketIssue { protected final Tick tick = new Tick(0); private final List\u0026lt;Future\u0026lt;TV\u0026gt;\u0026gt; resultList = new ArrayList\u0026lt;\u0026gt;(); static class Tick { // 一般将共享资源设置为私有以降低同步问题的复杂性  int tickCount; boolean isTickSupply = true; public Tick(int tick) { this.tickCount = tick; } boolean getTick() { if (isTick()) { tickCount--; if (getTickCount() \u0026lt; 0) { System.out.println(\u0026#34;余票数 \u0026#34; + tickCount + \u0026#34;不合法，系统错误！\u0026#34;); System.exit(0); } return true; } return false; } // 检查余票  boolean isTick() { return tickCount \u0026gt; 0; } // 获取余票  int getTickCount() { return tickCount; } // 停止放票  void cancelSupply() { isTickSupply = false; } } @Setter @Getter static class TV { Thread t; Integer v = 0; } static class Purchase implements Callable\u0026lt;TV\u0026gt; { // 线程抢到的票计数器  // 线程内部存储一般声明为static  private static final ThreadLocal\u0026lt;TV\u0026gt; tl = ThreadLocal.withInitial(TV::new); private final Tick tick; Purchase(Tick tick) { this.tick = tick; } /* 此处在run/call方法里同步 */ @Override public TV call() { while (true) { synchronized (tick) { TV tv = tl.get(); tv.setT(Thread.currentThread()); if (tick.getTick()) { tv.setV((tv.getV() == null ? 0 : tv.getV()) + 1); tl.set(tv); // System.out.println(Thread.currentThread().getName() + \u0026#34; 抢到票, 余票数: \u0026#34; + tick.getTickCount());  try { // 给其他线程机会  tick.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } else { tick.notifyAll(); if (!tick.isTickSupply) break; } } } return tl.get(); } } void multiPurchase(int threadCount) throws InterruptedException, ExecutionException { ExecutorService pool = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; threadCount; i++) { Future\u0026lt;TV\u0026gt; future = pool.submit(new Purchase(tick)); resultList.add(future); } pool.shutdown(); int sum = 0; for (int i = 0; i \u0026lt; resultList.size(); i++) { TV tv = resultList.get(i).get(); System.out.println(tv.getT().getName() + \u0026#34; 抢到票：\u0026#34; + tv.getV() + \u0026#34;张\u0026#34;); sum = sum + tv.getV(); } System.out.println(\u0026#34;已购票数：\u0026#34; + sum); } /** 放票 */ void singleSupply(int count) { new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; count; i++) { // 此处不使用同步不影响最终结果，线程会一直抢票  // 即使某刻读取到了未刷新的tickCount数值，最终都会抢到票  tick.tickCount++; // 降低出票速率  try { TimeUnit.MILLISECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } // 停止放票  tick.cancelSupply(); }).start(); } public static void main(String[] args) throws Exception { TicketIssue ti = new TicketIssue(); int count = 10 , threadHold = 10; if (args.length \u0026gt; 1){ count = Integer.parseInt(args[0]); } if (args.length \u0026gt; 2){ threadHold = Integer.parseInt(args[1]); } ti.singleSupply(count); ti.multiPurchase(threadHold); } } /* output (sample) pool-1-thread-1 抢到票：2张 pool-1-thread-2 抢到票：2张 pool-1-thread-3 抢到票：2张 pool-1-thread-4 抢到票：0张 pool-1-thread-5 抢到票：0张 pool-1-thread-6 抢到票：0张 pool-1-thread-7 抢到票：0张 pool-1-thread-8 抢到票：1张 pool-1-thread-9 抢到票：0张 pool-1-thread-10 抢到票：3张 已购票数：10 *///:~   程序接受2个参数1，第一个为放票数，第二个为抢票线程数，这两个参数的默认值都是10，运行程序我们可以看到每个线程所抢到的票数\n在call()方法中，为了避免某一任务独占cpu时间，我们让每个抢到票的线程进入等待，若某个线程没有抢到票，则唤醒之。因为放票是有时间间隔的，所以肯定存在某个没有抢到票的线程能够唤醒之前抢到票的线程\n到目前位置，程序看起来都运行正常。但是，如果线程数远小于票数，或者放票间隔很小(甚至没有间隔)的情况下，死锁很快就会发生。比如我们使用2个线程抢10张票，那么很快将会看到死锁，这是一个很明显的因逻辑漏洞而出现死锁的情况\n破坏这个死锁的方法也很简单，不让获得票的任务进入永久等待，使用带参数的wait(timeout)方法或者使用休眠即可\n哲学家就餐问题 这个问题2的描述是指定5个哲学家，他们将花部分时间思考，花部分时间就餐。当他们思考的时候，不需要任何共享资源；但当他们就餐时，将使用有限数量的餐具。哲学家们围坐在桌子周围，每人之间放一支筷子（总之筷子和哲学家数量相同），当哲学家想要就餐时，他必须同时获得左边和右边的筷子，如果这个哲学家的左边或者右边已经有人使用筷子了，那么哲学家必须等待，直到他可以获得筷子\n代码片段1:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  public class PhilosopherDeadLocking { protected final int id; protected final int ponderFactor; public PhilosopherDeadLocking(int id, int ponderFactor) { this.id = id; this.ponderFactor = ponderFactor; } protected void pause() throws InterruptedException { Random rand = new Random(47); if (ponderFactor == 0) { return; } TimeUnit.MILLISECONDS.sleep(rand.nextInt(ponderFactor * 250)); } @Override public String toString() { return \u0026#34;Philosopher \u0026#34; + id; } static class Chopstick { private boolean taken; private synchronized void take() throws InterruptedException { while (taken) { wait(); } taken = true; } private synchronized void drop() { taken = false; notifyAll(); } }   哲学家有一个构造参数ponderFactor，用来控制哲学家思考的时间；当调用take()方法拿起筷子时，它要先判断筷子是否已经被使用，如果是则进入等待，否则获得筷子并将taken置为true；当调用drop()方法放下筷子时，将taken置为false并唤醒所有在等待使用这个筷子的哲学家\n代码片段2:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  static class Dinner implements Runnable { private Chopstick left; private Chopstick right; private PhilosopherDeadLocking philosopherDeadLocking; public Dinner(Chopstick left, Chopstick right, PhilosopherDeadLocking phi) { this.left = left; this.right = right; this.philosopherDeadLocking = phi; } @Override public void run() { try { while (!Thread.interrupted()) { System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;thinking\u0026#34;); philosopherDeadLocking.pause(); // Philosopher becomes hungry  System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;grabbing right\u0026#34;); right.take(); System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;grabbing left\u0026#34;); left.take(); System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;eating\u0026#34;); philosopherDeadLocking.pause(); System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;drop right\u0026#34;); right.drop(); System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;drop left\u0026#34;); left.drop(); } } catch (InterruptedException e) { System.out.println(philosopherDeadLocking + \u0026#34; \u0026#34; + \u0026#34;exiting via interrupt\u0026#34;); } } }   在哲学家就餐的run()方法中，哲学家只是不停的思考和吃饭，如果ponderFactor不为0，那么哲学家先会思考一会儿，然后拿起右边的筷子，再拿起左边的筷子，然后在吃饭上花掉一会时间，然后放下筷子，之后重复此过程\n代码片段3:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public static void main(String[] args) throws Exception { ExecutorService pool = Executors.newCachedThreadPool(); int size = 5, ponder = 0; if (args.length \u0026gt; 0) { ponder = Integer.parseInt(args[0]); } if (args.length \u0026gt; 1) { size = Integer.parseInt(args[1]); } Chopstick[] chopsticks = new Chopstick[size]; for (int i = 0; i \u0026lt; size; i++) { chopsticks[i] = new Chopstick(); } for (int i = 0; i \u0026lt; size; i++) { pool.execute(new Dinner(chopsticks[i], chopsticks[(i + 1) % size], new PhilosopherDeadLocking(i, ponder))); } if (args.length \u0026gt; 2) { TimeUnit.SECONDS.sleep(Integer.parseInt(args[2])); } else { System.out.println(\u0026#34;Press \u0026#39;q\u0026#39; to quit\u0026#34;); System.in.read(); } pool.shutdownNow(); } }   main()方法接受3个命令行参数，分别是ponderFactor，筷子数，以及程序结束前运行的时间（程序需要主动结束运行）。这个程序的特别之处在于，它大部分时间是正常运行的——如果哲学家花在思考上的时间足够长，那么死锁可能永远不可能发生，但是如果将ponderFactor设置为0，那么死锁将很快会发生\n因为每个哲学家都是先拿右边的筷子，后拿左边的筷子，如果哲学家思考的时间很短，就会出现所有的哲学家都拿到了右边的筷子，并等待左边的筷子的情况，如此一来，所有的哲学家都陷入了“等待的陷阱”，这就是循环等待的情形，此时程序的死锁就发生了。如果让最后一位哲学家先拿左边的筷子而非右边的筷子，那么就可以破坏循环等待的条件，阻止死锁的发生：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public static void main(String[] args) throws Exception { ExecutorService pool = Executors.newCachedThreadPool(); int size = 5, ponder = 0; if (args.length \u0026gt; 0) { ponder = Integer.parseInt(args[0]); } if (args.length \u0026gt; 1) { size = Integer.parseInt(args[1]); } Chopstick[] chopsticks = new Chopstick[size]; for (int i = 0; i \u0026lt; size; i++) { chopsticks[i] = new Chopstick(); } for (int i = 0; i \u0026lt; size - 1; i++) { pool.execute(new Dinner(chopsticks[i], chopsticks[(i + 1) % size], new PhilosopherDeadLocking(i, ponder))); } // 让最后一位哲学家先拿左边的筷子，破坏可能发生的循环等待  pool.execute(new Dinner(chopsticks[0],chopsticks[size -1], new PhilosopherFixDeadLocking(size-1, ponder))); if (args.length \u0026gt; 2) { TimeUnit.MILLISECONDS.sleep(Integer.parseInt(args[2])); } else { System.out.println(\u0026#34;Press \u0026#39;q\u0026#39; to quit\u0026#34;); System.in.read(); } pool.shutdownNow(); }   就死锁而言，Java并没有就此提供语言上的支持，能否通过仔细地设计程序逻辑来避免死锁，取决于你\n 这个程序使用同步的方式只是为了说明问题，并不是最好的同步方式 \u0026#x21a9;\u0026#xfe0e;\n 这是由Edsger Dijkstra提出的一个经典的死锁例证，参考自《Java编程思想 第四版》 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文借助两个经典的并发问题阐述了Java并发的死锁问题。","id":21,"section":"posts","tags":["死锁","线程本地存储"],"title":"死锁","uri":"http://wangy325.top/zh/posts/java/concurrency/%E6%AD%BB%E9%94%81/"},{"content":"本文转自Matrix海子，是描述volatile关键字非常好的一篇文章，从Java的内存模型开始，归本溯源的阐述了volatile关键字在并发中的作用与局限\n此文部分内容参照了《深入理解Java虚拟机》\n1 内存模型的相关概念 　大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。\n　也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：\n1  i = i + 1;   　当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。\n　这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。\n　比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？\n　可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。\n　最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。\n　也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。\n　为了解决缓存不一致性问题，通常来说有以下2种解决方法：\n　1）通过在总线加LOCK#锁的方式\n　2）通过缓存一致性协议\n　这2种方式都是硬件层面上提供的方式。\n　在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。\n　但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。\n　所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。\n2 并发编程中的三个概念 　在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念：\n2.1 原子性 　原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。\n　一个很经典的例子就是银行账户转账问题：\n　比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。\n　试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。\n　所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。\n　同样地反映到并发编程中会出现什么结果呢？\n　举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？\n1  i = 9;   　假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。\n　那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。\n2.2 可见性 　可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。\n　举个简单的例子，看下面这段代码：\n1 2 3 4 5 6  //线程1执行的代码 int i = 0; i = 10; //线程2执行的代码 j = i;   　假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。\n　此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.\n　这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。\n2.3 有序性 　有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：\n1 2 3 4  int i = 0; boolean flag = false; i = 1; //语句1 flag = true; //语句2   　上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。\n　下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。\n　比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。\n　但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子：\n1 2 3 4  int a = 10; //语句1 int r = 2; //语句2 a = a + 3; //语句3 r = a*a; //语句4   　这段代码有4个语句，那么可能的一个执行顺序是：\n语句2 -\u0026gt; 语句1 -\u0026gt; 语句3 -\u0026gt; 语句4\n　那么可不可能是这个执行顺序呢： 语句2 -\u0026gt; 语句1 -\u0026gt; 语句4 -\u0026gt; 语句3\n　不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。\n　虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子：\n1 2 3 4 5 6 7 8 9  //线程1: context = loadContext(); //语句1 inited = true; //语句2  //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context);   　上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。\n　从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。\n　也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。\n3 Java内存模型 　在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。\n　在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。\n　Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。\n　举个简单的例子：在java中，执行下面这个语句：\n1  i = 10;   　执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。\n　那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？\n3.1 原子性 　在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。\n　上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i：\n　请分析以下哪些操作是原子性操作：\n1 2 3 4  x = 10; //语句1 y = x; //语句2 x++; //语句3 x = x + 1; //语句4   　咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。\n　语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。\n　语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。\n　同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。\n　所以上面4个语句只有语句1的操作具备原子性。\n　也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。\n　不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。\n　从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。\n3.2 可见性 　对于可见性，Java提供了volatile关键字来保证可见性。\n　当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。\n　而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。\n　另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。\n3.3 有序性 　在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\n　在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。\n　另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。\n　下面就来具体介绍下happens-before原则（先行发生原则）：\n 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作\n  锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作\n  volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作\n  传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C\n  线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作\n  线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生\n  线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行\n  对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始\n 　这8条原则摘自《深入理解Java虚拟机》。\n　这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。\n　下面我们来解释一下前4条规则：\n　对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。\n　第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。\n　第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。\n　第四条规则实际上就是体现happens-before原则具备传递性。\n4 深入剖析volatile关键字 　在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。\n4.1 volatile关键字的两层语义 　一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：\n　1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。\n　2）禁止进行指令重排序。\n　先看一段代码，假如线程1先执行，线程2后执行：\n1 2 3 4 5 6 7 8  //线程1 boolean stop = false; while(!stop){ doSomething(); } //线程2 stop = true;   　这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。\n　下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。\n　那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。\n　但是用volatile修饰之后就变得不一样了：\n　第一：使用volatile关键字会强制将修改的值立即写入主存；\n　第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；\n　第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。\n　那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。\n　那么线程1读取到的就是最新的正确的值。\n4.2 volatile保证原子性吗？ 　从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？\n　下面看一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class Test { public volatile int inc = 0; public void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完  Thread.yield(); System.out.println(test.inc); } }   　大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。\n　可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。\n　这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。\n　在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：\n　假如某个时刻变量inc的值为10，\n　线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；\n　然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。\n　然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。\n　那么两个线程分别进行了一次自增操作后，inc只增加了1。\n　解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。\n　根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。\n　把上面的代码改成以下任何一种都可以达到效果：\n　采用synchronized：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class Test { public int inc = 0; public synchronized void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完  Thread.yield(); System.out.println(test.inc); } }   　采用Lock：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public class Test { public int inc = 0; Lock lock = new ReentrantLock(); public void increase() { lock.lock(); try { inc++; } finally{ lock.unlock(); } } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完  Thread.yield(); System.out.println(test.inc); } }   　采用AtomicInteger：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class Test { public AtomicInteger inc = new AtomicInteger(); public void increase() { inc.getAndIncrement(); } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完  Thread.yield(); System.out.println(test.inc); } }   　在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。\n4.3 volatile能保证有序性吗？ 　在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。\n　volatile关键字禁止指令重排序有两层意思：\n　1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；\n　2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。\n　可能上面说的比较绕，举个简单的例子：\n1 2 3 4 5 6 7 8  //x、y为非volatile变量 //flag为volatile变量  x = 2; //语句1 y = 0; //语句2 flag = true; //语句3 x = 4; //语句4 y = -1; //语句5   　由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。\n　并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。\n　那么我们回到前面举的一个例子：\n1 2 3 4 5 6 7 8 9  //线程1: context = loadContext(); //语句1 inited = true; //语句2  //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context);   　前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。\n　这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。\n4.4 volatile的原理和实现机制 　前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。\n　下面这段话摘自《深入理解Java虚拟机》：\n　“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”\n　lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：\n　1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；\n　2）它会强制将对缓存的修改操作立即写入主存；\n　3）如果是写操作，它会导致其他CPU中对应的缓存行无效。\n5 使用volatile关键字的场景 　synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：\n　1）对变量的写操作不依赖于当前值\n　2）该变量没有包含在具有其他变量的不变式中\n　实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。\n　事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。\n　下面列举几个Java中使用volatile的几个场景。\n5.1 状态标记量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  volatile boolean flag = false; while(!flag){ doSomething(); } public void setFlag() { flag = true; } // another demo volatile boolean inited = false; //线程1: context = loadContext(); inited = true; //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context);   5.2 双重检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Singleton{ private volatile static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if(instance==null) { synchronized (Singleton.class) { if(instance==null) instance = new Singleton(); } } return instance; } }   　至于为何需要这么写请参考：\n　《Java 中的双重检查（Double-Check）》\n本文完\n","description":"本文从内存模型开始，深入地阐述了volatile关键字的作用与局限。","id":22,"section":"posts","tags":["volatile"],"title":"Java内存模型与volatile关键字(转)","uri":"http://wangy325.top/zh/posts/java/concurrency/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8Evolatile%E5%85%B3%E9%94%AE%E5%AD%97/"},{"content":"在讨论线程协作的时候，已经讨论了生产者与消费者雏形，比如录音是生产者，而播放则是消费者；同样的，在汽车打蜡的模型中，打蜡可看作生产者，抛光可看作消费者；只是它们的关系是简单的生产-消费关系。\n除了简单的线程协同之外，Java提供了同步队列来解决线程的协同问题，本节重点讨论这部分的内容。\n1 线程协同 不妨继续查看一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112  public class Restaurant { private Meal meal; private volatile int count; static class Meal { int orderNum; public Meal(int orderNum) { this.orderNum = orderNum; } @Override public String toString() { return \u0026#34;Meal \u0026#34; + orderNum; } } static class Chef implements Runnable { final Restaurant rest; public Chef(Restaurant rest) { this.rest = rest; } @Override public void run() { while (!Thread.interrupted()) { synchronized (rest) { if (rest.meal != null) { try { rest.wait(); } catch (InterruptedException e) { System.out.println(\u0026#34;Exit Chef by Interrupted\u0026#34;); return; } } /* try { TimeUnit.MILLISECONDS.sleep(100); } catch (InterruptedException e) { System.out.println(\u0026#34;Exit Chef Sleep by Interrupted\u0026#34;); return; }*/ rest.meal = new Meal(++rest.count); rest.notifyAll(); } } System.out.println(\u0026#34;Exit Chef\u0026#34;); } } static class Waiter implements Runnable { final Restaurant rest; public Waiter(Restaurant rest) { this.rest = rest; } @Override public void run() { while (!Thread.interrupted()) { synchronized (rest) { if (rest.meal == null) { try { rest.wait(); } catch (InterruptedException e) { System.out.println(\u0026#34;Exit Waiter by Interrupted\u0026#34;); return; } } System.out.println(\u0026#34;order up: \u0026#34; + rest.meal); rest.meal = null; rest.notifyAll(); } } System.out.println(\u0026#34;Exit Waiter\u0026#34;); } } public static void main(String[] args) { ExecutorService pool = Executors.newCachedThreadPool(); Restaurant restaurant = new Restaurant(); pool.execute(new Waiter(restaurant)); pool.execute(new Chef(restaurant)); while (true) { synchronized (restaurant) { if (restaurant.count == 10) { pool.shutdownNow(); break; } } } // end  } } /*（sample） order up: Meal 1 order up: Meal 2 order up: Meal 3 order up: Meal 4 order up: Meal 5 order up: Meal 6 order up: Meal 7 order up: Meal 8 order up: Meal 9 order up: Meal 10 exit waiter by interrupted Exit Chef *///:~   主线程中的while循环必须使用同步块获取restaurant的锁，以保证其在获取count值的时候没有其他线程对其进行修改。可以看到输出结果满足预期，waiter任务执行10次之后程序退出。\n我们不妨关注一下任务结束的方式：在输出样例中，Waiter被中断，而Chef是正常退出1。中断的线程一定是wait状态，此时Waiter在wait，而Chef正好满足运行的条件，但此时主线程的线程池发出了interrupt()命令，所以Chef的while循环的判断条件不成立，不运行while语句而退出。\n如果我们取消Chef任务中的注释部分，那么任务结束的方式又会有所不同：\nExit Chef Sleep by Interrupted Exit Waiter by Interrupted  除此之外，关于此示例，还有一些特别说明：\n  可以使用try-catch块包含任务的while循环，这样保证任何时候出现异常都能结束任务；示例中对每个可能出现异常的地方使用try-catch主要是为了明确异常发生的地方罢了；\n  关于使任务进入等待的条件，示例中使用了if语句进行判断，实际上更通用的方法是使用while循环(虽然个人感觉没有实质上的差别)。\nsynchronized(monitor){ while(condition){ wait(); } }   2 阻塞队列 java.util.concurrent包中提供了 同步队列 来解决线程协作的问题，同步队列在任意时刻都只允许一个任务插入或移除元素，juc包中同步队列的顶级接口是BlockingQueue，其有大量实现，LinkedBlockingQueue是一个无界队列；ArrayBlockingQueue具有固定的尺寸，在其元素数达到容量限制时，再向其他插入元素则会阻塞；SynchronousQueue是一个没有容量的同步队列，仅当有任务从队列中移除元素时，另一任务才可以向队列中插入元素，反之亦然。\nJava中的阻塞队列:        抛出异常 返回特殊值 阻塞 超时阻塞     插入 add(e) offer(e) put(e) offer(e, time, unit)   移除 remove() poll() take() poll(time, unit)   检查 element() peek() \u0026mdash; \u0026mdash;     上表展示了阻塞队列的方法概要，与普通队列相比，阻塞队列添加了阻塞和超时阻塞的方法：\n1 2 3 4 5 6 7 8 9 10 11 12  void put(E e) throws InterruptedException 向队列中插入元素，队列中没有空间时一直等待 E take() throws InterruptedException 取出队首的元素，队列为空时一直等待 boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException 向队列中插入元素，超时等待队列中空间可用，超时之前插入则返回true，超时则返回false E poll(long timeout, TimeUnit unit) throws InterruptedException 取出队首的元素，超时等待队首元素可用，返回该元素或者null(超时)   下面我们以ArrayBlockingQueue和LinkedBlockingQueue为例，看看阻塞队列是如何阻塞和唤醒的：\n2.1 ArrayBlockingQueue 这是一个典型的FIFO队列，新的元素插到队尾，并从队头移除。ArrayBlockingQueue是有界队列，构造器带有一个初始容量参数，一旦初始化，这个容量不能改变。\n下面列出ArrayBlockingQueue的几个重要成员变量和构造器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  /** The queued items */ final Object[] items; // 可以看到是用对象数组实现  /** Main lock guarding all access */ final ReentrantLock lock; // 唯一的锁  /** Condition for waiting takes */ private final Condition notEmpty; // 条件1，非空  /** Condition for waiting puts */ private final Condition notFull; // 条件2， 非满  // constructor public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity \u0026lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); }   基本上，ArrayBlockingQueue类的所有同步方法锁使用的锁就是上面的锁及其条件，我们主要观察put(e)和take()方法是如何阻塞和唤醒的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  // put public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) // 没有空间时等待  notFull.await(); enqueue(e); } finally { lock.unlock(); } } private void enqueue(E x) { // assert lock.getHoldCount() == 1;  // assert items[putIndex] == null;  final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; // 唤醒一个等待的take()方法  notEmpty.signal(); } // take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) // 没有元素时等待  notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } private E dequeue() { // assert lock.getHoldCount() == 1;  // assert items[takeIndex] != null;  final Object[] items = this.items; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); // 唤醒一个等待的put()方法  notFull.signal(); return x; }   可以看到，阻塞队列的put(e)和take()方法是互相唤醒的，因此是生产——消费模式的绝佳实现。同时也注意到，方法中使用显式锁的可中断获取锁方法，以便在必要的时候中断，避免出现阻塞无法响应的情况。\n同时，ArrayBlockingQueue的put(e)和take()方法使用的是同一个锁对象，这就意味着同一时刻只能有一个任务执行插入或移除元素的操作。\nArrayBlockingQueue的put(e)和take()逻辑可以简单概括为：\nArrayBlockingQueue的put/take方法流程图\n2.2 LinkedBlockingQueue 这是一个基于 linked nodes 的FIFO队列，如果构造时不指定容量，其容量默认为Integer.MAX_VALUE。\n下面列出了LinkedBlockingQueue关于put(e)和take()的主要字段：\n1 2 3 4 5 6 7 8 9 10 11  /** Lock held by take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** Wait queue for waiting takes */ private final Condition notEmpty = takeLock.newCondition(); /** Lock held by put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** Wait queue for waiting puts */ private final Condition notFull = putLock.newCondition();   可以看到，LinkedBlockingQueue的put(e)和take()方法分别拥有一个锁对象，我们不妨看看它们在对应方法中的行为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82  // put public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var  // holding count negative to indicate failure unless set.  int c = -1; Node\u0026lt;E\u0026gt; node = new Node\u0026lt;E\u0026gt;(e); // 使用put锁  final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { while (count.get() == capacity) { // 满时在put锁上等待  notFull.await(); } enqueue(node); c = count.getAndIncrement(); if (c + 1 \u0026lt; capacity) // 再次检查，若不满，则唤醒其他等待的put任务  // 因为put和take使用的是不同的锁，可能t1在put时进入了等待，  // 而t2在put时运行到这一步时，线程t3已经take走了几个元素，  // 而此时队列中尚存在多个元素(t1不能被t3唤醒)  // 于是t2发现队列存在空间，则t1可以被唤醒  notFull.signal(); } finally { putLock.unlock(); } if (c == 0) // 若c=0，此时count=1，队列中有元素，唤醒等待的take任务  signalNotEmpty(); } private void signalNotEmpty() { final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { notEmpty.signal(); } finally { takeLock.unlock(); } } // take public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; // 使用take锁  final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { while (count.get() == 0) { // 空时等待  notEmpty.await(); } x = dequeue(); c = count.getAndDecrement(); if (c \u0026gt; 1) // 唤醒其他的take任务  // 若t1在take时发现队列为空进入等待，t2在take时运行到此时  // 发现队列已经被t3put了多个元素  // 那么t2就可以在此处直接唤醒t1  notEmpty.signal(); } finally { takeLock.unlock(); } if (c == capacity) // 此时已经移除队首元素，队列有1个空间，唤醒等待的put任务  signalNotFull(); return x; } private void signalNotFull() { final ReentrantLock putLock = this.putLock; putLock.lock(); try { notFull.signal(); } finally { putLock.unlock(); } }   相较ArrayBlockingQueue而言，LinkedBlockingQueue的put(e)和take()方法稍显复杂，因为后者使用了2个锁对象，put(e)和take()方法除了被对方唤醒之外，还会被自己唤醒，更为重要的是，使用2个锁对象允许在同一时刻有至多2个任务分别进行put(e)和take()操作。\nLinkedBlockingQueue的put/take方法流程图\n2.3 SynchronousQueue SynchronousQueue是一个比较特殊的阻塞队列，它没有容量，它更像是一种机制：当任务a试图向队列中插入元素时，必然要等待另一个任务b从队列中移除元素，反之亦然。\n2.4 了解不同的阻塞队列 下例展示了不同阻塞队列实例在同一应用中的不同行为2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130  public class TestBlockingQueue { private BlockingQueue\u0026lt;LiftOff\u0026gt; rockets; private TestBlockingQueue(BlockingQueue\u0026lt;LiftOff\u0026gt; rockets) { this.rockets = rockets; } static TestBlockingQueue getLinkedBlockingQueue() { return new TestBlockingQueue(new LinkedBlockingQueue\u0026lt;\u0026gt;()); } static TestBlockingQueue getArrayBlockedQueue(int capacity) { return new TestBlockingQueue(new ArrayBlockingQueue\u0026lt;\u0026gt;(capacity)); } static TestBlockingQueue getSynchronousQueue() { return new TestBlockingQueue(new SynchronousQueue\u0026lt;\u0026gt;()); } void add() throws InterruptedException { rockets.put(new LiftOff(1)); } LiftOff take() throws InterruptedException { return rockets.take(); } class LiftOffAdder implements Runnable { @Override public void run() { try { while (!Thread.interrupted()) { add(); Thread.yield(); } System.out.println(\u0026#34;Exiting LiftOffAdder\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Interrupted during add()\u0026#34;); } } } class LiftOffRunner implements Runnable { @Override public void run() { try { while (!Thread.interrupted()) { LiftOff rocket = take(); // 在此线程上运行  rocket.run(); try { TimeUnit.MILLISECONDS.sleep(100); } catch (InterruptedException e) { System.out.println(\u0026#34;Interrupted during sleep\u0026#34;); // return 语句是必须的，捕获异常后状态被清除了，while循环无法终止  return; } } System.out.println(\u0026#34;Exiting LiftOffRunner\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Interrupted during take()\u0026#34;); } } } @SneakyThrows void test(String msg) { System.out.println(msg); ExecutorService pool = Executors.newCachedThreadPool(); LiftOffRunner runner = this.new LiftOffRunner(); LiftOffAdder adder = this.new LiftOffAdder(); pool.execute(runner); pool.execute(adder); TimeUnit.SECONDS.sleep(1); pool.shutdownNow(); System.out.println(\u0026#34;rocket still in queue: \u0026#34; + rockets.size()); } public static void main(String[] args) { getLinkedBlockingQueue().test(\u0026#34;LinkedBlockingQueue\u0026#34;); getArrayBlockedQueue(1).test(\u0026#34;ArrayBlockingQueue\u0026#34;); getSynchronousQueue().test(\u0026#34;SynchronousQueue\u0026#34;); } }/* output(sample) LinkedBlockingQueue #0(LiftOff!), #1(LiftOff!), #2(LiftOff!), #3(LiftOff!), #4(LiftOff!), #5(LiftOff!), #6(LiftOff!), #7(LiftOff!), Exiting LiftOffAdder rocket still in queue: 2087449 Interrupted during sleep ArrayBlockingQueue #2087457(LiftOff!), #2087458(LiftOff!), #2087459(LiftOff!), #2087460(LiftOff!), #2087461(LiftOff!), #2087462(LiftOff!), #2087463(LiftOff!), #2087464(LiftOff!), #2087465(LiftOff!), #2087466(LiftOff!), rocket still in queue: 1 Interrupted during sleep Interrupted during add() SynchronousQueue #2087469(LiftOff!), #2087470(LiftOff!), #2087471(LiftOff!), #2087472(LiftOff!), #2087473(LiftOff!), #2087474(LiftOff!), #2087475(LiftOff!), #2087476(LiftOff!), #2087477(LiftOff!), #2087478(LiftOff!), rocket still in queue: 0 Interrupted during sleep Interrupted during add() *///:~   在上面的示例中，有一个待发射的“火箭队列”，另有2个任务分别向队列中添加火箭和取出火箭执行发射，其中添加火箭的任务是以无限循环的形式进行的，只有当任务阻塞或者中断时添加任务才结束，而发射火箭的任务每100ms会从队列中取出火箭并发射。示例中有3个不同的阻塞队列实现，除了上面提到的两种之外，还有一个SynchronousQueue，主线程执行1s后通过执行器向所有任务执行中断命令，通过输出观察3个阻塞队列的行为。\n首先是LinkedBlockingQueue，它是一个无界(Integer.MAX_VALUE)队列，我们看到它1s内完成了8次发射任务，这也是符合预期的，因为除了CPU休眠的时间，线程的上下文切换也会消耗部分时间，同时我们可以看到，由于没有容量限制，在短短的1s时间内，队列中的火箭实例竟然多达208万之多，队列的元素如此之多也会对性能有一定影响！最后发送中断命令之后，显而易见发射任务是在休眠时被中断退出的，而添加任务是正常退出的，这是由于没有容量限制，于是不存在让队列的put(e)方法阻塞的条件，添加任务没有被阻塞，而是检测到中断状态而退出。\n接着是一个固定容量为1ArrayBlockingQueue，我们看到其完成了10次发射任务，中断发生之前，队列中还有一个火箭实例，并且两个任务都是被中断的。在最后一次完成发射之后，添加任务被唤醒并执行并在再次执行时由于队列中元素数到达容量上限而进入等待，此时接收到中断命令，于是在休眠中的发射任务直接抛出中断异常，而添加任务也在等待中直接抛出中断异常。\n其次是SynchronousQueue，这是一个特殊的阻塞队列，我们看到它也执行了10次发射任务，中断发生时，队列中没有元素，并且2个任务都是被中断的。这个最容易理解：最后一次发射之后发射任务进入休眠的过程中，由于发射任务的take()方法没有运行，因此添加任务的put(e)也会被阻塞。\n关于其他的阻塞队列，参考其他重要的并发组件\n3 应用示例 3.1 查找关键字 下面的示例从目录及其子目录中查找指定关键字的文件并列出关键字所在的行的信息。我们使用阻塞队列存放目录及其子目录中所有文件，并且使用2个任务分别添加文件和查找文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106  public class SearchKeyword { private static final int FILE_QUEUE_SIZE = 10; private static final int SEARCH_THREADS = 100; private static final File DUMMY = new File(\u0026#34;\u0026#34;); /**有界阻塞队列*/ private final BlockingQueue\u0026lt;File\u0026gt; queue = new ArrayBlockingQueue\u0026lt;\u0026gt;(FILE_QUEUE_SIZE); private final static String DIR = \u0026#34;src\u0026#34;; private String keyword; private volatile boolean done = false; public static void main(String[] args) { SearchKeyword sk = new SearchKeyword(); sk.test(); } void test() { // 带资源的try块  try (Scanner in = new Scanner(System.in)) { System.out.print(\u0026#34;Enter keyword (e.g. volatile): \u0026#34;); keyword = in.nextLine(); Producer p = new Producer(); Consumer c = new Consumer(); ExecutorService pool = Executors.newCachedThreadPool(); pool.execute(p); for (int i = 1; i \u0026lt;= SEARCH_THREADS; i++) { // run consumer  pool.execute(c); } pool.shutdown(); } } class Producer implements Runnable { @Override public void run() { try { enumerate(new File(DIR)); // 空文件作为结束符  queue.put(DUMMY); } catch (InterruptedException e) { // ignore  } } } class Consumer implements Runnable { @Override public void run() { try { while (!done) { File file = queue.take(); if (file == DUMMY) { done = true; } else { search(file, keyword); } // Thread.yield();  } } catch (Exception e) { // ignore  } } } /** * Recursively enumerates all files in a given directory and its subdirectories. * * @param directory the directory in which to start */ public void enumerate(File directory) throws InterruptedException { File[] files = directory.listFiles(); for (File file : files) { if (file.isDirectory()) { enumerate(file); } else { queue.put(file); } } } /** * Searches a file for a given keyword and prints all matching lines. * * @param file the file to search * @param keyword the keyword to search for */ public void search(File file, String keyword) throws IOException { try (Scanner in = new Scanner(file, \u0026#34;UTF-8\u0026#34;)) { int lineNumber = 0; while (in.hasNextLine()) { lineNumber++; String line = in.nextLine(); if (line.contains(keyword)) { System.out.printf(\u0026#34;[%s] %s:%d:%s%n\u0026#34;, Thread.currentThread().getName(), file.getPath(), lineNumber, line); } } } } }   上例中用于存放文件的是有界的阻塞队列实现，并且代码没有任何的显式同步控制，程序是线程安全的，这就是阻塞队列在处理生产——消费模型时的优势。\n事实上，我们无需关注队列中元素的插入/移除、以及put/take方法的阻塞情况，阻塞队列会处理好一切。不过，我们可以简单分析程序可能的运行过程：\n 若p任务一直占用cpu时间，那么队列很快将到达容量上限，put方法阻塞 此时c任务获得cpu时间及锁，并且能够顺利的移除元素，此时take方法唤醒put方法 但是put方法并没有获取锁，c任务继续执行，由于c任务有很多线程，队列中的元素很快被消耗完，所有执行c任务的线程take方法阻塞 此时p任务重新获得锁，put方法插入元素后唤醒take方法，c任务得以继续执行 \u0026hellip; 插入dummy之后p任务完成 c任务的任一线程读取到dummy之后修改修改标记变量并在下一次循环退出 其他执行c任务的线程读取到标记量并相继退出  实际上程序运行的过程比上面的阐述要复杂的多，不过需要理解的就是阻塞队列在队列满或空的情况下的阻塞是被相互唤醒的。\n3.2 面包工厂的阻塞链 此节的内容关于阻塞链的描述部分可能有部分错误  假设一个面包工厂有两个加工线，分别加工黄油面包和果酱面包，现在将面包工厂作为生产者，另外我们需要一个消费者，来看看每次都会吃到什么口味的面包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193  public class ToastFactory { private volatile int count; static class Toast { enum Status {DRY, BUTTERED, JAMMED} private Status status = Status.DRY; private final int id; public Toast(int idn) { id = idn; } public void butter() { status = Status.BUTTERED; } public void jam() { status = Status.JAMMED; } public Status getStatus() { return status; } public int getId() { return id; } @Override public String toString() { return \u0026#34;Toast \u0026#34; + id + \u0026#34;: \u0026#34; + status; } } class ToastQueue extends LinkedBlockingQueue\u0026lt;Toast\u0026gt; { } class Toaster implements Runnable { private ToastQueue rawQueue; public Toaster(ToastQueue tq) { rawQueue = tq; } @Override public void run() { try { while (!Thread.interrupted()) { TimeUnit.MILLISECONDS.sleep(100); // Make toast  Toast t = new Toast(count++); System.out.println(t); // Insert into queue  rawQueue.put(t); } System.out.println(\u0026#34;Toaster off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Toaster interrupted\u0026#34;); } } } /** Apply butter to toast: */ class Butterer implements Runnable { private ToastQueue dryQueue, finishQueue; public Butterer(ToastQueue dry, ToastQueue buttered) { dryQueue = dry; finishQueue = buttered; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available:  Toast t = dryQueue.take(); t.butter(); System.out.println(t); finishQueue.put(t); } System.out.println(\u0026#34;Butterer off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Butterer interrupted\u0026#34;); } } } /** Apply jam to buttered toast: */ class Jammer implements Runnable { private ToastQueue dryQueue, finishQueue; public Jammer(ToastQueue raw, ToastQueue jam) { dryQueue = raw; finishQueue = jam; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available:  Toast t = dryQueue.take(); t.jam(); System.out.println(t); finishQueue.put(t); } System.out.println(\u0026#34;Jammer off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Jammer interrupted\u0026#34;); } } } /** Consume the toast: */ class Eater implements Runnable { private ToastQueue finishQueue; private int counter = 0; public Eater(ToastQueue finishQueue) { this.finishQueue = finishQueue; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available:  Toast toast = finishQueue.take(); // Verify that the toast is coming in order,  // and that all pieces are getting jammed:  if (toast.getId() != counter++ || toast.getStatus() == Toast.Status.DRY) { System.out.println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt; Error: \u0026#34; + toast); System.exit(1); } else { System.out.println(\u0026#34;Chomp! \u0026#34; + toast); } } System.out.println(\u0026#34;Eater off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Eater interrupted\u0026#34;); } } } public void test() throws InterruptedException { ToastQueue dryQueue = this.new ToastQueue(), finishQueue = this.new ToastQueue(); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(this.new Toaster(dryQueue)); exec.execute(this.new Butterer(dryQueue, finishQueue)); exec.execute(this.new Jammer(dryQueue, finishQueue)); exec.execute(this.new Eater(finishQueue)); while (true) { if (count \u0026gt; 4) { break; } } exec.shutdownNow(); System.out.println(\u0026#34;toast count: \u0026#34; + count); } public static void main(String[] args) throws Exception { ToastFactory tf = new ToastFactory(); tf.test(); } } /* Toast 0: DRY Toast 0: BUTTERED Chomp! Toast 0: BUTTERED Toast 1: DRY Toast 1: JAMMED Chomp! Toast 1: JAMMED Toast 2: DRY Toast 2: BUTTERED Chomp! Toast 2: BUTTERED Toast 3: DRY Toast 3: JAMMED Chomp! Toast 3: JAMMED Toast 4: DRY Toast 4: BUTTERED Chomp! Toast 4: BUTTERED toast count: 5 Eater interrupted Jammer interrupted Butterer interrupted Toaster interrupted *///:~   上例有4个任务，分别为生产干面包（记为T1），生产黄油面包（记为T2），生产果酱面包（记为T3），消费面包（记为T4）。黄油/果酱面包只能由干面包加工而成，而T4只能消费加工好的面包\ngraph LR A[开始] --\\\u0026gt;B(干面包T1) B --\\\u0026gt;|黄油T2| D[生产完成] B --\\\u0026gt;|果酱T3| D D --\\\u0026gt;|消费T4| E[结束] 程序执行流程\n从执行流程上来看，T1会阻塞T2和T3，而T2和T3会阻塞T4，而T4会阻塞T1，这样形成了一个阻塞链，从输出来看也正是如此，面包的生产和消费是有序的：被涂上黄油的面包0被消费，接着是被涂上果酱的面包1被消费\u0026hellip;等等如此有规律的输出。\n仔细想想，这种规律是怎么得到保证的呢？\n从代码来看， 程序使用了2个阻塞队列：rawQueue和finishQueue分别表示干面包和加工完成的面包（黄油/果酱），程序运行时，T1， T2，T3，T4全部是RUNNABLE状态。由于采用的实现是LinkedBlockingQueue，所以rowQueue的put(e)方法无法被阻塞，单从这一点看，就不能保证得到代码示例中的规律输出，此外，T2/T3会随机争用rowQueue的take锁，所以面包被涂黄油还是果酱是无法确定的，完全由cpu随机调度，因此也不可能出现上述示例的规律输出，至于T4就更不用说了，由于T2/T3的随机争用，那么T4的if判断必然会出现错误，从而退出程序，符合逻辑的输出应该是向下面这样的（当然，把主线程的count判断值改大以观察效果）：\n1 2 3 4 5 6 7 8 9 10 11 12  /* ... Chomp! Toast 51: BUTTERED Toast 54: BUTTERED Toast 59: DRY Toast 56: BUTTERED \u0026gt;\u0026gt;\u0026gt;\u0026gt; Error: Toast 53: BUTTERED Toast 55: JAMMED Toast 57: BUTTERED Toast 59: BUTTERED ... */   既然是rowQueue的put(e)方法无法被阻塞导致的问题，那么使用指定容量为1的ArrayBlockingQueue是否可以满足规律输出呢？\n遗憾的是，也不行3\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143  class ToastQueue extends ArrayBlockingQueue\u0026lt;Toast\u0026gt;{ public ToastQueue(int capacity) { super(capacity); } } class Toaster implements Runnable { private ToastQueue rawQueue; public Toaster(ToastQueue tq) { rawQueue = tq; } @Override public void run() { try { while (!Thread.interrupted()) { // 这句休眠是保证阻塞链的根本 // TimeUnit.MILLISECONDS.sleep(100);  // Make toast  Toast t = new Toast(count++); rawQueue.put(t); } System.out.println(\u0026#34;Toaster off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Toaster interrupted\u0026#34;); } } } /** Apply butter to toast: */ class Butterer implements Runnable { private ToastQueue dryQueue, finishQueue; public Butterer(ToastQueue dry, ToastQueue buttered) { dryQueue = dry; finishQueue = buttered; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available:  Toast t = dryQueue.take(); t.butter(); finishQueue.put(t); } System.out.println(\u0026#34;Butterer off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Butterer interrupted\u0026#34;); } } } /** Apply jam to buttered toast: */ class Jammer implements Runnable { private ToastQueue dryQueue, finishQueue; public Jammer(ToastQueue raw, ToastQueue jam) { dryQueue = raw; finishQueue = jam; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available:  Toast t = dryQueue.take(); t.jam(); finishQueue.put(t); } System.out.println(\u0026#34;Jammer off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Jammer interrupted\u0026#34;); } } } /** Consume the toast: */ class Eater implements Runnable { private ToastQueue finishQueue; private int counter = 0; public Eater(ToastQueue finishQueue) { this.finishQueue = finishQueue; } @Override public void run() { try { while (!Thread.interrupted()) { // Blocks until next piece of toast is available:  Toast toast = finishQueue.take(); System.out.println(\u0026#34;Chomp! \u0026#34; + toast); } System.out.println(\u0026#34;Eater off\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Eater interrupted\u0026#34;); } } } public void test() throws InterruptedException { ToastQueue dryQueue = this.new ToastQueue(1), finishQueue = this.new ToastQueue(1); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(this.new Toaster(dryQueue)); exec.execute(this.new Butterer(dryQueue, finishQueue)); exec.execute(this.new Jammer(dryQueue, finishQueue)); exec.execute(this.new Eater(finishQueue)); while (true) { if (count \u0026gt; 14) { break; } } exec.shutdownNow(); System.out.println(\u0026#34;toast count: \u0026#34; + count); } public static void main(String[] args) throws Exception { ToastFactory tf = new ToastFactory(); tf.test(); } /* output (partial sample) ... Chomp! Toast 18: JAMMED Chomp! Toast 20: JAMMED Chomp! Toast 19: BUTTERED Chomp! Toast 22: BUTTERED Chomp! Toast 21: JAMMED Chomp! Toast 24: JAMMED Eater off Butterer interrupted toast count: 28 Toaster interrupted Jammer interrupted *///:~   可以看到，还是T2/T3的争用问题没有解决，T1的阻塞之后，T2/T3获得运行权之后将面包放入finishQueue时又存在争用情况，尽管大多数情况下都是有序的，但是也存在少数情况下的乱序问题。\n同时，上述代码还暴露了一个问题： volatile变量的局限性，程序计划生产14块面包后结束，而最后的面包数却到了28！主线程和T1对共享变量count进行修改，应该使用同步4。\n实际上，在T1任务开始时使用 休眠来降低面包生产的速度，这样当程序运行时，T1处于休眠状态，/T2/T3/T4都是处于阻塞状态，这和前面讨论的无规律输出是完全不同的局面；当T1休眠超时之后，生产第一片面包并唤醒一个在rawQueue上等待的任务（可能是T2或T3）后又进入休眠（100ms），此时（假如）T2被唤醒，那么T2加工面包之后唤醒T4并随即进入等待（T1任务100ms的休眠足够长时间让rawQueue为空），T4完成之后随即进入等待(同理，100ms足够长)，这样就完成了一轮规律输出5：\n1 2 3 4 5  /* Toast 0: DRY Toast 0: BUTTERED Chomp! Toast 0: BUTTERED */   值得一提的是，关于上面提到的共享变量，并没有使用同步，但是却 意外地 没有出现问题4。这确实令人意外，明明是不满足happens-before原则的，但是却没有出现讹误（或许是测试少，讹误没有发生）。原因就出现在T1的休眠上，由于T1的休眠，T1有足够的时间来接收主线程“滞后”的中断命令，因此看起来就像是主线程的判断没有逻辑上的缺陷一样。\n这是我见过的最强休眠。\n 实际测试过程的结果往往相反，而Waiter和Chef同时被中断的情况很少 \u0026#x21a9;\u0026#xfe0e;\n LiftOff类参考本系列的第一个任务实例 \u0026#x21a9;\u0026#xfe0e;\n 这个代码还存在共享资源的访问讹误问题 \u0026#x21a9;\u0026#xfe0e;\n 这是由于在前文中提到的，在使用ArrayBlockingQueue测试时，volatile关键字的局限性显现时意识到的。将count设置为volatile，并且只有线程T1在对其进行修改，主线程读取count的值作为任务中断的依据，看起来似乎不需要额外的同步，即可不出现讹误，但是却出现了。实际上，虽然保证了可见性，但是没有保证有序性，即对count的判断和对count的修改不满足happens-before原则，只有当对count值的读取总是发生在对count值的修改之前时，主线程中对count值的判断逻辑才是可行的，事实上主线程中对count值的判断总是滞后于修改的 \u0026#x21a9;\u0026#xfe0e;\n 看起来100ms的休眠好像是一个不太安全的机制，因为不能保证100ms的时间T4一定在T1休眠的时间内完成任务并进入等待。但是在测试过程中将休眠时间设置为1ns(Java能够设置的最小休眠时间)，仍然得到了规律输出，这一点让人费解 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"","id":23,"section":"posts","tags":["阻塞队列"],"title":"生产者-消费者与阻塞队列","uri":"http://wangy325.top/zh/posts/java/concurrency/%E7%94%9F%E4%BA%A7%E8%80%85-%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"},{"content":"一般地，如果程序运行良好，任务执行完所需操作后自然结束，任务终结。\n如果任务执行时出现异常，任务也会终结。\n在设计多个线程协同工作的任务时，需要判断任务终结的条件，以便合适地终结任务，这点尤为重要。\n在本节中主要讨论在多线程协同工作的情况下，如何合适的终结任务。\n响应中断 在讨论Object超类的时候，我们曾通过“录音-播放”模型简单阐述线程之间的协同工作，在那个示例中，方便起见，我们通过System.exit(0);来粗暴地结束程序的运行。这种方式在并发编程实践中是不被允许的。\n接下来的示例中，我们再次以线程之间的协同工作为切点，讨论如何“合理地”终结任务的运行。\n下例模拟汽车的“打蜡-抛光”过程，抛光必须在打蜡完成之后，同样的，打蜡之前汽车必须是抛光过的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92  public class Wax { static class Car { private boolean waxOn = false; public synchronized void waxed() { waxOn = true; // Ready to buff  notifyAll(); } public synchronized void buffed() { waxOn = false; // Ready for another coat of wax  notifyAll(); } public synchronized void waitForWaxing() throws InterruptedException { // waxOn = false时一直等待  while (!waxOn) wait(); } public synchronized void waitForBuffing() throws InterruptedException { // waxOn = true时一直等待  while (waxOn) wait(); } } static class WaxOn implements Runnable { private Car car; public WaxOn(Car c) { car = c; } @Override public void run() { try { while (!Thread.interrupted()) { TimeUnit.MILLISECONDS.sleep(100); System.out.print(\u0026#34;Wax On! \u0026#34;); car.waxed(); car.waitForBuffing(); } } catch (InterruptedException e) { System.out.println(\u0026#34;WaxOn Exiting via interrupt\u0026#34;); } System.out.println(\u0026#34;Ending Wax On task\u0026#34;); } } static class BufferOn implements Runnable { private Car car; public BufferOn(Car c) { car = c; } @Override public void run() { try { while (!Thread.interrupted()) { // 任务直接进入等待直到被唤醒, waxOn = true时得以执行  car.waitForWaxing(); System.out.print(\u0026#34;Wax Off! \u0026#34;); TimeUnit.MILLISECONDS.sleep(100); car.buffed(); } } catch (InterruptedException e) { System.out.println(\u0026#34;BufferOn Exiting via interrupt\u0026#34;); } System.out.println(\u0026#34;Ending Buffer On task\u0026#34;); } } public static void main(String[] args) throws Exception { Car car = new Car(); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(new BufferOn(car)); exec.execute(new WaxOn(car)); TimeUnit.SECONDS.sleep(2); // Run for a while...  exec.shutdownNow(); // Interrupt all tasks  } } /* Output: (95% match) Wax On! Wax Off! Wax On! Wax Off! Wax On! Wax Off! Wax On! Wax Off! Wax On! Wax Off! Wax On! Wax Off! Wax On! Wax Off! Wax On! Wax Off! Wax On! Wax Off! Wax On! Wax Off! BufferOn Exiting via interrupt WaxOn Exiting via interrupt Ending Wax On task Ending Buffer On task *///:~   因为两个任务是交互等待-执行的，调用wait()方法而进入WAITING状态的线程可以被中断并抛出异常1，上面的输出显示BufferOn任务先响应中断，这只是可能的情况之一，因为输出 Wax Off! 之后BufferOn任务会进入等待，而正好被中断。\n调用执行器的shutdownNow()方法关闭提交的任务，shutdownNow()方法会立即给已经提交的任务发送一个中断interrupt()命令。调用shutdownNow()之后，可以看到两个任务都抛出InterruptedException。\n ⚠️注意： 两个任务都抛出中断异常和任务中的sleep方法有关，由于sleep和wait都可以被中断并抛出异常，所以异常的抛出是由谁引发的并不容易确定。虽然try块位于任务的最外层，但是Thread.interrupted()方法并不抛出异常。\n 上例实际上是利用了中断线程而出现的异常而终止线程的运行，然而，BLOCKED2状态下的线程无法响应中断。\n无法中断 Thread提供了interrupt()方法，用于设置线程的中断状态。为了调用此方法，你必须持有Thread对象。并发编程过程中一般避免显式创建线程，上例中使用了shutdownNow()向任务发送interrup()命令，同样地，Java提供一个带有类型参数的接口Future\u0026lt;V\u0026gt;，它具有取消任务执行的能力。\n但是，阻塞状态下的线程是否都能响应中断呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  public class Interrupting { private static ExecutorService exec = Executors.newCachedThreadPool(); static void test(Runnable r) throws InterruptedException { // 构造一个可中断的任务  Future\u0026lt;?\u0026gt; f = exec.submit(r); TimeUnit.MILLISECONDS.sleep(100); // 中断任务  System.out.println(r.getClass().getSimpleName() + \u0026#34; Interrupt: \u0026#34; + f.cancel(true)); } public static void main(String[] args) throws Exception { test(new SleepBlocked()); test(new IOBlocked(System.in)); // 不能中断  test(new SynchronizedBlocked()); // 不能中断  TimeUnit.SECONDS.sleep(3); System.exit(0); // ... since last 2 interrupts failed  } /** sleep可以被中断 */ static class SleepBlocked implements Runnable { @Override public void run() { try { TimeUnit.SECONDS.sleep(100); } catch (InterruptedException e) { System.out.println(\u0026#34;InterruptedException\u0026#34;); } System.out.println(\u0026#34;Exiting SleepBlocked.run()\u0026#34;); } } /** I/O不可被中断 */ static class IOBlocked implements Runnable { private InputStream in; public IOBlocked(InputStream is) { in = is; } @Override public void run() { try { System.out.println(\u0026#34;Waiting for read():\u0026#34;); in.read(); } catch (Exception e) { if (Thread.currentThread().isInterrupted()) { System.out.println(\u0026#34;Interrupted from blocked I/O\u0026#34;); } else { throw new RuntimeException(e); } } System.out.println(\u0026#34;Exiting IOBlocked.run()\u0026#34;); } } /** 不可被中断 */ static class SynchronizedBlocked implements Runnable { public synchronized void f() { while (true) // Never releases lock  Thread.yield(); } public SynchronizedBlocked() { // 构造之后就获取锁而不释放  new Thread(() -\u0026gt; { f(); // Lock acquired by this thread  }).start(); } /** run()方法将一直阻塞 */ @Override public void run() { System.out.println(\u0026#34;Trying to call f()\u0026#34;); f(); System.out.println(\u0026#34;Exiting SynchronizedBlocked.run()\u0026#34;); } } } /* output: InterruptedException SleepBlocked Interrupt: true Exiting SleepBlocked.run() Waiting for read(): IOBlocked Interrupt: true Trying to call f() SynchronizedBlocked Interrupt: true *///:~   由于Future的cancel(boolean)方法也是向执行任务的线程发送interrupt()命令，上例中3个任务，只有SleepBlocked在休眠时被中断并退出运行，其他的两个任务IOBlocked和SynchronizedBlocked均没有被中断。实际上，在编码过程中我们也可以发现，只有sleep()方法需要处理InterruptedException异常，而无论时I/O还是尝试调用synchronized方法，都不需要处理InterruptedException。\n对于I/O阻塞的情况，有一个简单的处理办法——即关闭任务在其上发生阻塞的资源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public class CloseResource { public static void main(String[] args) throws Exception { ExecutorService exec = Executors.newCachedThreadPool(); InputStream socketInput = new Socket(\u0026#34;localhost\u0026#34;, 8080).getInputStream(); exec.execute(new Interrupting.IOBlocked(socketInput)); exec.execute(new Interrupting.IOBlocked(System.in)); TimeUnit.MILLISECONDS.sleep(10); System.out.println(\u0026#34;Shutting down all threads\u0026#34;); // 两个任务都无法响应中断  exec.shutdownNow(); TimeUnit.SECONDS.sleep(1); System.out.println(\u0026#34;Closing \u0026#34; + socketInput.getClass().getName()); // 关闭资源可以使线程响应中断  socketInput.close(); // Releases blocked thread  TimeUnit.SECONDS.sleep(1); System.out.println(\u0026#34;Closing \u0026#34; + System.in.getClass().getName()); System.in.close(); // Releases blocked thread  } } /* Output: (85% match) Waiting for read(): Waiting for read(): Shutting down all threads Closing java.net.SocketInputStream Interrupted from blocked I/O Exiting IOBlocked.run() Closing java.io.BufferedInputStream Exiting IOBlocked.run() *///:~   上例中的2个任务都无法响应中断，但是一旦关闭资源，那么阻塞就被中断。\n对于因获取锁失败而阻塞的情况，实际上，上例中的情况可以看作是死锁，由于任务无法获取对象的锁而一直阻塞。幸运的是，Java提供ReentrantLock锁，其具备在因获取锁而阻塞但是又能响应中断的能力。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  public class LockingInterrupt { // 可重入锁获取锁的时候可以被中断  private Lock lock = new ReentrantLock(); public LockingInterrupt() { // lock the instance once constructed  lock.lock(); } void f() { try { // invoke can be interrupted  lock.lockInterruptibly(); System.out.println(\u0026#34;acquire lock in f() success\u0026#34;); }catch (InterruptedException e){ System.out.println(\u0026#34;Interrupted from acquire lock in f()\u0026#34;); } } static class MutexTask implements Runnable{ LockingInterrupt mbi = new LockingInterrupt(); @Override public void run() { System.out.println(\u0026#34;waiting for f()\u0026#34;); mbi.f(); System.out.println(\u0026#34;Broken out of blocked call\u0026#34;); } } public static void main(String[] args) throws InterruptedException { Thread t = new Thread(new MutexTask()); t.start(); // 中断t，若不中断，t会一直阻塞  t.interrupt(); } } /* waiting for f() Interrupted from acquire lock in f() Broken out of blocked call *///:~   上例中，LockingInterrupt初始化的时候就占用锁，并没有释放锁，而在运行f()方法的时候再去获取锁时任务就被阻塞了，在调用interrupt()方法中断的时候，lockInterruptibly()响应了中断，任务结束程序退出。\n惯用法 从上面的例子我们已经知道，可以通过检查线程的中断状态来结束任务的执行。下面的例子展示了一种惯用法，它使用try-finally块来紧跟资源，以应对任何时候任务出现中断时保证资源被释放：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  public class InterruptingIdiom { /** 需要清理的资源类 */ static class NeedsCleanup { private final int id; public NeedsCleanup(int ident) { id = ident; System.out.println(\u0026#34;NeedsCleanup \u0026#34; + id); } public void cleanup() { System.out.println(\u0026#34;Cleaning up \u0026#34; + id); } } static class Blocked3 implements Runnable { private volatile double d = 0.0; @Override public void run() { try { while (!Thread.interrupted()) { NeedsCleanup n1 = new NeedsCleanup(1); // 在n1之后紧跟try-finally块，保证资源被合理的清除  // node 1  try { System.out.println(\u0026#34;Sleeping\u0026#34;); TimeUnit.SECONDS.sleep(1); NeedsCleanup n2 = new NeedsCleanup(2); // 同理  // node2  try { System.out.println(\u0026#34;Calculating\u0026#34;); //耗时操作  for (int i = 1; i \u0026lt; 2500000; i++) { d = d + (Math.PI + Math.E) / d; } // node3  System.out.println(\u0026#34;Finished time-consuming operation\u0026#34;); } finally { n2.cleanup(); } } finally { n1.cleanup(); } } System.out.println(\u0026#34;Exiting via while() test\u0026#34;); } catch (InterruptedException e) { System.out.println(\u0026#34;Exiting via InterruptedException\u0026#34;); } } } public static void main(String[] args) throws Exception { if (args.length != 1) { System.out.println(\u0026#34;usage: java InterruptingIdiom delay-in-mS\u0026#34;); System.exit(1); } Thread t = new Thread(new Blocked3()); t.start(); TimeUnit.MILLISECONDS.sleep(new Integer(args[0])); t.interrupt(); } } /* Output: (Sample) NeedsCleanup 1 Sleeping NeedsCleanup 2 Calculating Finished time-consuming operation Cleaning up 2 Cleaning up 1 NeedsCleanup 1 Sleeping Cleaning up 1 Exiting via InterruptedException *///:~   上例接收一个参数，表示程序中断之前的运行时间(ms)，由于任务中有一段耗时的循环操作，当参数大小不同时，程序的输出会有所差异：\n任务可能在node1和node2之间中断，因此其输出为：\nNeedsCleanup 1 Sleeping Cleaning up 1 Exiting via InterruptedException  当任务在node2和node3之间设置中断状态，再次进入循环时中断被监测到，程序退出，此时的输出为：\nNeedsCleanup 1 Sleeping NeedsCleanup 2 Calculating Finished time-consuming operation Cleaning up 2 Cleaning up 1 Exiting via while() test  总之，无论任务在何时被释放，其创建的资源都会被合适地释放。\n TIJ第四版第21章并发（694页）在描述线程的状态时，将调用休眠/等待之后线程的状态称为阻塞。为避免混淆，本文采用Thread.State中关于线程的描述，并认为其不应该被称为阻塞状态 \u0026#x21a9;\u0026#xfe0e;\n 本博客约定此状态（等待锁）的线程才处于阻塞状态 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文讨论了在多线程协同工作的情况下，合理终结任务的惯用法。","id":24,"section":"posts","tags":["中断任务"],"title":"终结任务","uri":"http://wangy325.top/zh/posts/java/concurrency/%E7%BB%88%E7%BB%93%E4%BB%BB%E5%8A%A1/"},{"content":"要创建一个任务，通常实现Runnable接口。考虑一个经典的问题：用多线程分段计算0-100的加和，我们需要把每个线程计算的值汇总，然后再求和，那么应该怎样获取每个任务返回值呢？\nJava提供了Callable和Future接口，使任务有提供返回值的能力\n1 Callable 接口  V call() throws Exception\n Callable接口只有一个方法call()，和Runnable接口不同的是call方法有返回值并且抛出受查异常(checked exception)\n利用Callable接口，上述问题可以轻松解决:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  public class DividedCalculate { static class Task implements Callable\u0026lt;Integer\u0026gt; { int min; int max; public Task(int min, int max) { this.min = min; this.max = max; } @Override public Integer call() { int sum = 0; for (int i = min; i \u0026lt; max; i++) { sum += i; } return sum; } } @SneakyThrows public static void main(String[] args) { ExecutorService pool = Executors.newCachedThreadPool(); Future\u0026lt;Integer\u0026gt; s3 = pool.submit(new Task(51, 76)); Future\u0026lt;Integer\u0026gt; s2 = pool.submit(new Task(26, 51)); Future\u0026lt;Integer\u0026gt; s4 = pool.submit(new Task(76, 101)); Future\u0026lt;Integer\u0026gt; s1 = pool.submit(new Task(1, 26)); pool.shutdown(); System.out.printf(\u0026#34;%d + %d + %d + %d = %d\u0026#34;, s1.get(), s2.get(), s3.get(), s4.get(), s1.get() + s2.get() + s3.get() + s4.get()); } } /* output: 325 + 950 + 1575 + 2200 = 5050 *///：～   我们使用执行器提交任务，执行器的submit()方法返回一个带有返回值参数类型的Future对象\n \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task)\n 2 Future 接口  pubic interface Future\u0026lt;V\u0026gt;\n 上面的示例中我们使用Future来接收任务的返回值，由此可见接口声明的类型参数就是Callable接口的返回类型\nFuture代表了异步计算的返回结果。除此之外，Future还提供了一些实用方法来判断任务的执行状态：\n2.1 Future接口支持的方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  boolean cancel(boolean mayInterruptIfRunning) 尝试取消任务的执行，实际上是向任务发送一个中断（interrupt()）信号。布尔值参数为true表示向这个任务发送中断信号，false则不发送中断信号 这个方法返回之后调用isDone()总是返回true； 如果此方法返回true，调用isCanceled()总是返回true 返回false的情形： - 任务已经执行完毕 - 任务已经被取消 - 由于某些原因不能被取消 返回true表示任务被成功取消 boolean isCancelled() 如果任务**正常**完成之前被取消则返回true boolean isDone() 如果任务完成则返回true。 注意任务可能是正常执行完成，抛出异常而终止，或者通过isCancel()方法被取消 上述3种情况任意一种都会导致此方法返回true V get() throws InterruptedException,ExecutionException 等待任务执行完成并获取返回值 调用此方法会抛出异常 - 若方法被取消，抛出CancellationException - 若方法执行异常，抛出ExecutionException - 若方法在等待过程中被中断，则抛出InterruptedException V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException,TimeoutException 在指定超时限制内等待任务执行并获取返回值 抛出异常和get()方法一样，除外多了一个TimeOutException，超时异常   特别地，如果只想使用Future的可取消任务的特性，而不需要任务返回值，那么可以将Future声明为Future\u0026lt;?\u0026gt;并且将任务返回null\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  public class CancelableTask { static class Cancelable\u0026lt;V\u0026gt; implements Callable\u0026lt;V\u0026gt; { @Override public V call() throws Exception { System.out.println(\u0026#34;---\u0026#34;); int i = 0; while (true) { i++; if (i \u0026gt; 100000) { break; } } return null; } } public static void main(String[] args) { ExecutorService service = Executors.newSingleThreadExecutor(); Future\u0026lt;?\u0026gt; submit = service.submit(new Cancelable\u0026lt;\u0026gt;()); System.out.println(submit.cancel(true)); System.out.println(submit.isCancelled()); System.out.println(submit.isDone()); service.shutdown(); } } /* output: true true true *///~   由于Callable实例无法通过Thread类运行（Thread类实现了Runnable接口，并且只能通过Runnable初始化），于是我们在之前的分步计算中使用了执行器的submit()方法来获取任务的返回值\nJava提供了一个有用的类FutureTask，用来包装Callable或Runnable实例。由于其实现了Future接口，其能够实现Future接口的功能；又由于其实现了Runnable接口，其又能被显示线程或者执行器执行\n3 FutureTask 类  public class FutureTask\u0026lt;V\u0026gt; extends Object implements RunnableFuture\u0026lt;V\u0026gt;\n    public interface RunnableFuture\u0026lt;V\u0026gt; extends Runnable, Future\u0026lt;V\u0026gt;\n 从类继承关系可以看到FutureTask类同时实现了Future和Runnable接口，因此FutureTask实例是一个可以取消的异步任务，同步也能够使用Future获取任务返回值。从灵活性上来说，其可以用Thread类包装运行或者直接提交（submit）给执行器\n3.1 FutureTask构造器 1 2 3 4 5  FutureTask(Callable\u0026lt;V\u0026gt; callable) FutureTask(Runnable runnable, V result) result是返回类型，如果不需要，可以使用如下形式： Future\u0026lt;?\u0026gt; f = new FutureTask\u0026lt;Void\u0026gt;(runnable, null)   3.2 FutureTask方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  // 继承自Future的方法 public boolean isCancelled() public boolean isDone() public boolean cancel(boolean mayInterruptIfRunning) public V get() throws InterruptedException, ExecutionException public V get(long timeout,TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException // 继承自Runnable的方法 public void run() // protected方法 protected void done() 这个方法在任务执行（正常执行或抛出异常）完成之后被调用。默认实现不执行任何操作， 导出类可以覆盖这个方法并执行相关操作。覆盖方法可以查询任务状态去判断任务是否被取消 protected void set(V v) 若任务没有返回值或已取消执行，为Future设置返回值。这个方法在任务成功执行完成之前 被run()方法调用 protected void setException(Throwable t) 若任务没有设置异常或已取消执行，为任务设置任务执行时抛出的异常（ExecutionException）。 这个方法在任务执行失败时被run()方法调用 protected boolean runAndReset() 这个方法为那些需要多次执行的任务设计。此方法执行任务但是不设置返回值，并将Future设置 为初始状态。若任务出现异常或被取消或已经执行完成，则此方法执行失败   下面的代码示例展示了FutureTask类中run()和runAndReset()方法的区别\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101  public class FutureTaskImpl\u0026lt;V\u0026gt; extends FutureTask\u0026lt;V\u0026gt; { private int runTime = 0; private boolean isDone = false; public FutureTaskImpl(Callable\u0026lt;V\u0026gt; callable) { super(callable); } public FutureTaskImpl(Runnable runnable, V result) { super(runnable, result); } @Override protected void done() { if (isCancelled()) { System.out.println(\u0026#34;task is canceled\u0026#34;); return; } isDone = true; runTime++; } @Override protected boolean runAndReset() { if (super.runAndReset()) { runTime++; } else { return false; } return true; } static class Task implements Runnable { @Override public void run() { // do something  } } static class Task2 implements Callable\u0026lt;Integer\u0026gt; { @Override public Integer call() throws Exception { int sum = 0; for (int i = 0; i \u0026lt; 100; i++) { sum += i; } return sum; } } /** * 先执行{@link FutureTask#run()}再执行{@link #runAndReset()} * \u0026lt;p\u0026gt; * 任务不可执行 */ void resetAfterRun() { run(); System.out.println(runAndReset()); // false  System.out.println(\u0026#34;runTime:\u0026#34; + runTime); System.out.println(\u0026#34;isDone:\u0026#34; + isDone); } /** * 先执行{@link #runAndReset()}再执行{@link FutureTask#run()} * \u0026lt;p\u0026gt; * 任务可以再次执行 * * 对于有返回值的任务，执行{@link #runAndReset()}之后调用{@link FutureTask#get()} * 方法获取返回值会造成阻塞 */ @SneakyThrows void runAfterReset() { for (; ; ) { runAndReset(); if (runTime \u0026gt; 1) break; } // V v = get(); // blocked  System.out.println(\u0026#34;isDone: \u0026#34; + isDone); // false  run(); System.out.println(\u0026#34;runTime: \u0026#34; + runTime); V v1 = get(); System.out.println(\u0026#34;result: \u0026#34; + v1); System.out.println(\u0026#34;isDone: \u0026#34; + isDone); // true  } public static void main(String[] args) { // 构造一个没有返回值的FutureTask  FutureTaskImpl\u0026lt;?\u0026gt; ft = new FutureTaskImpl\u0026lt;\u0026gt;(new Task(), null); FutureTaskImpl\u0026lt;?\u0026gt; ft2 = new FutureTaskImpl\u0026lt;\u0026gt;(new Task2()); ft2.runAfterReset(); // ft.resetAfterRun();  } } /* output: isDone: false runTime: 3 result: 4950 isDone: true *///~   可以看到，我们计划在循环中让任务执行runAndReset()2次，之后尝试去调用get()方法，发现进程会一直阻塞，这也和api文档中描述的一致（without setting its result, and then resets this future to initial state），说明任务没有执行完成而且是处于初始状态。接下来的isDone()方法返回false也验证了这点，接着调用run()方法再次运行任务，最后获取任务的返回值，看到任务共执行了3次，最后的结果是最后一次run()方法返回的结果，接着的isDone()方法返回true，说明任务执行完成\n相反地，如果先运行run()方法，再尝试运行runAndReset()，后者直接返回false\n4 应用示例 在抢票问题中，为了获取每个线程抢到的票数，我们使用了ThreadLocal来存放当前线程和其抢到的票（自定义bean）的信息，并在任务执行完成之后将其返回，以便程序完成之后明确地知道每个线程抢到的票数\n之所以使用自定义bean使任务包含线程信息而不使任务直接返回其抢到的票数，是因为线程池无法操作线程，更加无法在线程池的维度获取当前运行任务的线程信息\n利用FutureTask对象，我们则可以通过显示的构造线程来简化任务的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  public class TicketIssueWithFutureTask extends TicketIssue { private final HashMap\u0026lt;Thread, Future\u0026lt;Integer\u0026gt;\u0026gt; resultMap = new HashMap\u0026lt;\u0026gt;(); static class Purchase implements Callable\u0026lt;Integer\u0026gt; { // 线程抢到的票计数器  // 线程内部存储一般声明为static  private static ThreadLocal\u0026lt;Integer\u0026gt; tl = ThreadLocal.withInitial(() -\u0026gt; 0); private final Tick tick; Purchase(Tick tick) { this.tick = tick; } @Override public Integer call() { while (true) { synchronized (tick) { if (tick.getTick()) { tl.set(tl.get() + 1); try { // 给其他线程机会  tick.wait(10); } catch (InterruptedException e) { e.printStackTrace(); } } else { if (!tick.isTickSupply) break; } } } return tl.get(); } } @Override void multiPurchase(int threadCount) throws ExecutionException, InterruptedException { for (int i = 0; i \u0026lt; threadCount; i++) { // FutureTask实现了Runnable，可以在显式线程执行之后再通过其获取返回值  // 当然，也可以通过执行器执行  FutureTask\u0026lt;Integer\u0026gt; ft = new FutureTask\u0026lt;\u0026gt;(new Purchase(tick)); Thread t = new Thread(ft); t.start(); resultMap.put(t, ft); } int sum = 0; for (Map.Entry\u0026lt;Thread, Future\u0026lt;Integer\u0026gt;\u0026gt; entry : resultMap.entrySet()) { System.out.println(entry.getKey().getName() + \u0026#34; 抢到票：\u0026#34; + entry.getValue().get() + \u0026#34;张\u0026#34;); sum = sum + entry.getValue().get(); } System.out.println(\u0026#34;已购票数：\u0026#34; + sum); } public static void main(String[] args) throws Exception { TicketIssueWithFutureTask ti = new TicketIssueWithFutureTask(); ti.singleSupply(10); ti.multiPurchase(12); } }   使用FutureTask之后，使用显式的线程对应每个线程的返回值，就可以获得想要的信息\n","description":"介绍了Java中获取任务的返回值的几种方法。","id":25,"section":"posts","tags":["Future","Callable","FutureTask"],"title":"获取任务的返回值","uri":"http://wangy325.top/zh/posts/java/concurrency/%E8%8E%B7%E5%8F%96%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%94%E5%9B%9E%E5%80%BC/"},{"content":"HashMap基于散列表，散列表中每一个Node节点（桶）是链表，当两个条目（entry）的key的hash值对桶数（capacity）取模的值相等时，这两个entry会存储在同一个链表中。但当链表中元素达到一定数目时，链表结构会转变为树结构。\n此文中没有讨论HashMap中涉及到树结构的源码。\n1.基础字段 HashMap中定义了如下字段：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  // 默认初始容量为16 static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; //最大容量为2^30 static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; //默认装载因子 0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f; //“树化”临界值，当链表数组中的条目数\u0026gt;=8时转变为树结构 static final int TREEIFY_THRESHOLD = 8; // static final int UNTREEIFY_THRESHOLD = 6; // static final int MIN_TREEIFY_CAPACITY = 64; //hashmap存放键值对的容器，Node[]数组的大小就是hashmap的容量大小 transient Node\u0026lt;K,V\u0026gt;[] table; //键值对集 transient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; entrySet; //键值对数目 transient int size; //hashmap发生结构变化的计数器 transient int modCount; //扩容临界键值对数临界值，当size\u0026gt;threshold时扩容 int threshold; //装载因子，初始化时不指定默认为0.75 final float loadFactor;   2.初始化 2.1 构造器 HashMap提供了以下几个构造器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  public HashMap(int initialCapacity, float loadFactor){ if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); // 字段初始化  this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } // 获取table size容量的方法，结果总是为2的幂 static final int tableSizeFor(int cap) { int n = cap - 1; n |= n \u0026gt;\u0026gt;\u0026gt; 1; n |= n \u0026gt;\u0026gt;\u0026gt; 2; n |= n \u0026gt;\u0026gt;\u0026gt; 4; n |= n \u0026gt;\u0026gt;\u0026gt; 8; n |= n \u0026gt;\u0026gt;\u0026gt; 16; return (n \u0026lt; 0) ? 1 : (n \u0026gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; // 0.75  putMapEntries(m, false); } // 使用已有Map初始化 final void putMapEntries(Map\u0026lt;? extends K, ? extends V\u0026gt; m, boolean evict) { int s = m.size(); if (s \u0026gt; 0) { if (table == null) { // pre-size  // 若无键值对在HashMap中，此处的计算出table size  float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft \u0026lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t \u0026gt; threshold) threshold = tableSizeFor(t); } //若参数集过大，先对原集合扩容  else if (s \u0026gt; threshold) resize(); // 将参数集中的键值对填入新的HashMap中  for (Map.Entry\u0026lt;? extends K, ? extends V\u0026gt; e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); } } }   可以看到，除了最后一个构造器额外调用了putVal()方法外，构造器都只做了一些字段初始化工作，那么HashMap的键值对是如何“放入”的呢？\n2.2 插入键值对 键值对的插入与扩容密不可分，接下来从这两个方法来阐述HashMap的键值对插入过程\n当使用put(K,V)向映射中插入键值对时，实际上调用的是putVal()方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } /** * Implements Map.put and related methods. 向HashMap中插入元素 * * @param hash 键的hash值 * @param key 键 * @param value 值 * @param onlyIfAbsent 若真，那么不修改原键的值（若原键值不为null） * @param evict if false, the table is in creation mode. * @return 之前键映射的值，若之前键不存在则返回null */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // HashMap字段拷贝一份  Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) /* * 若是第一次插入，则执行此操作 * 此操作调用了resize方法，实际上做的是初始化table的操作 */ n = (tab = resize()).length; if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) // (n-1) \u0026amp; hash == hash % n, 用于计算key-value放在哪个桶中  // 若桶中尚未有内容，则新建一节点  tab[i] = newNode(hash, key, value, null); else { // 若桶中有内容  Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) // 并且第一个节点和新节点的key值一样（更新值）  e = p; else if (p instanceof TreeNode) // 树  e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { //  for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { //遍历桶中的节点，若至链尾，则在链尾加入节点  p.next = newNode(hash, key, value, null); //同时判断此时链表中的node数，若 \u0026gt; 8，则由链表转化为二叉树  // binCount = 7时说明链表中已经有8个节点了，此时节点数已经 \u0026gt;8个了  if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st  //树化  treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) //同理，key已存在，跳出for循环  break; // 将p顺延  p = e; } } if (e != null) { // existing mapping for key  V oldValue = e.value; // 满足条件会更新  if (!onlyIfAbsent || oldValue == null) e.value = value; // LinkedHashMap中用到  afterNodeAccess(e); return oldValue; } } ++modCount; // 扩容判断  if (++size \u0026gt; threshold) resize(); // LinkedHashMap中用到  afterNodeInsertion(evict); //key不存在，插入新key，返回null  return null; }   3.扩容 由putVal()方法可知，resize()方法在初始化过程中也发挥了作用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103  /** * 初始化或扩容table * * @return the table */ final Node\u0026lt;K,V\u0026gt;[] resize() { /* * 初始化时，table == null， threshold=0或2^n，视构造器而定 */ Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u0026gt; 0) { if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold  } else if (oldThr \u0026gt; 0) // 有参构造使用传入值的2^n作为table size  newCap = oldThr; else { // 无参构造器初始化使用默认值作为table size  newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; //若table size \u0026gt; 2^30则使threshold为最大整数，扩容不再发生  newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; //以下是扩容之后的内容拷贝  @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K,V\u0026gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) //桶中只有一个元素，重新计算key值在桶中的位置  newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); else { // preserve order  //桶中有多个元素  //那么将桶中的元素分裂到2个链表里面去，然后分别放入新table  //比如原桶数是4，新桶数即为8，原3号桶中有3，7，11，15四个hash  //那么3\u0026amp;4和11\u0026amp;4为0，放在新桶的3号桶；7\u0026amp;4和15\u0026amp;4不为0，放在新桶的7号桶  //元素在新桶中保持原顺序不变，3的下一节点hash由7变成11  Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; // 此处的逻辑比较晦涩，需仔细推敲  if ((e.hash \u0026amp; oldCap) == 0) { /* * 此处的逻辑为： * 第一次循环将loTail和loHead均初始化为e * 第二次将loTail.next改为满足条件((e.hash \u0026amp; oldCap) == 0)的e的更新值 * 这一过程将跳过中间不满足条件的节点 * 由于loHead和loTail都是指向e的引用，loHead.next随之而变 * 接下来将loTail指向e的更新值 * 如此往复，loHead-loTail形成一个新链 */ if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { // 去尾  // 有可能loTail还有子节点，而子节点不应该出现在当前链中  loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; }   上述resize()方法的结论可以通过以下代码验证\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136  public class NodeTest\u0026lt;K, V\u0026gt; { final Node\u0026lt;K, V\u0026gt;[] table = new Node[4]; final Node\u0026lt;K, V\u0026gt;[] newtab = new Node[8]; // 构造代码块，构造NodeTest实例时执行  { Node node = new Node(5, \u0026#34;five\u0026#34;, null); Node node1 = new Node(3, \u0026#34;four\u0026#34;, null); Node node2 = new Node(7, \u0026#34;three\u0026#34;, node1); Node node3 = new Node(11, \u0026#34;two\u0026#34;, node2); Node node4 = new Node(15, \u0026#34;one\u0026#34;, node3); Node node5 = new Node(17, \u0026#34;six\u0026#34;, node4); Node node6 = new Node(21, \u0026#34;seven\u0026#34;, node5); Node node7 = new Node(22, \u0026#34;eight\u0026#34;, null); Node node8 = new Node(23, \u0026#34;nine\u0026#34;, null); table[0] = node; table[1] = node7; table[2] = node6; table[3] = node8; } public static void main(String[] args) { NodeTest\u0026lt;Integer, String\u0026gt; nt = new NodeTest\u0026lt;\u0026gt;(); // 看看HashMap源码的resize方法的复制部分究竟搞什么飞机  nt.resize(nt.table, nt.newtab); // 看看此时的newtab  nt.printTable(nt.newtab); } public void printTable(Node\u0026lt;K, V\u0026gt;[] newtab) { Node\u0026lt;K, V\u0026gt; g, h; for (int i = 0; i \u0026lt; newtab.length; i++) { if ((g = newtab[i]) != null) { if (g.next == null) { System.out.println(\u0026#34;newtab[\u0026#34; + i + \u0026#34;]\u0026#34; + g.getKey() + \u0026#34;, \u0026#34; + g.getValue()); } else { do { h = g.next; System.out.println(\u0026#34;newtab[\u0026#34; + i + \u0026#34;]\u0026#34; + g.getKey() + \u0026#34;, \u0026#34; + g.getValue()); } while ((g = h) != null); } } } } public void resize(Node\u0026lt;K, V\u0026gt;[] table, Node\u0026lt;K, V\u0026gt;[] newtab) { int oldcap = table.length; for (int j = 0; j \u0026lt; oldcap; ++j) { Node\u0026lt;K, V\u0026gt; e; if ((e = table[j]) != null) { table[j] = null; if (e.next == null) { newtab[j] = e; } else { // preserve order  Node\u0026lt;K, V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K, V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K, V\u0026gt; next; do { next = e.next; if ((e.key.hashCode() \u0026amp; oldcap) == 0) { if (loTail == null) { loHead = e; } else { loTail.next = e; } loTail = e; } else { if (hiTail == null) { hiHead = e; } else { hiTail.next = e; } hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newtab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newtab[j + oldcap] = hiHead; } } } } } static class Node\u0026lt;K, V\u0026gt; implements Map.Entry\u0026lt;K, V\u0026gt; { K key; V value; Node\u0026lt;K, V\u0026gt; next; public Node(K key, V value, Node\u0026lt;K, V\u0026gt; next) { this.key = key; this.value = value; this.next = next; } @Override public K getKey() { return key; } @Override public V getValue() { return value; } @Override public V setValue(V value) { return null; } } } /* newtab[0]5, five newtab[1]22, eight newtab[2]17, six newtab[2]11, two newtab[2]3, four newtab[3]23, nine newtab[6]21, seven newtab[6]15, one newtab[6]7, three *///:~   从输出可以看到，原table[2]的节点被拆分后分别放在newtab[2]和newtab[6]的桶里，并且节点的顺序没有变化\n4.获取键值对 一般使用get(K key)方法获取映射中指定键的值，get方法相较putVal()要简单许多\n public V get(Object key)\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public V get(Object key) { Node\u0026lt;K,V\u0026gt; e; //有key则返回对应value，否则返回null  return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; first, e; int n; K k; // 直接通过hash找到key值存放的桶  if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) { if (first.hash == hash \u0026amp;\u0026amp; // always check first node  // 先从第一个节点查看，如key相等则返回此节点  ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return first; if ((e = first.next) != null) { // 否则查找链表中的其他节点  if (first instanceof TreeNode) return ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key); do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; }   另外判断一个映射中是否存在某个键对应的值对应的方法\n public boolean containsKey(Object key) {return getNode(hash(key), key) != null;}\n 实际上也是调用的上面提到的getNode()方法\n5. 删除键值对 使用remove(K key)删除映射中的键值对\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  public V remove(Object key) { Node\u0026lt;K,V\u0026gt; e; //返回null或对应key的value  return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } /** * Implements Map.remove and related methods. * * @param hash hash for key * @param key the key * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */ final Node\u0026lt;K,V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, index; // 直接定位存放键值对的桶  if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null) { Node\u0026lt;K,V\u0026gt; node = null, e; K k; V v; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) // 若第一个节点就是，那就是它了  node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode\u0026lt;K,V\u0026gt;)p).getTreeNode(hash, key); else { // 遍历链表定位key  do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } // 调整链表  if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)node).removeTreeNode(this, tab, movable); else if (node == p) // 第一个节点  tab[index] = node.next; else // 非第一个节点  // else语句快的do循环保证了p一定是node的前一个节点  p.next = node.next; ++modCount; --size; // LinkedHashMap用到  afterNodeRemoval(node); return node; } } return null; }   ","description":"本文内容简单分析了JDK8中HashMap源码的几个重要方法，包括初始化，扩容，如何获取键值对等，便于理解散列表在Java集合框架中的具体应用。","id":26,"section":"posts","tags":["集合框架","HashMap"],"title":"HashMap的源码分析（一）","uri":"http://wangy325.top/zh/posts/java/collections/hashmap%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80/"},{"content":"在上一篇文章中，虽然创建了多线程，并且线程之间出现了一些不可预测的CPU调度，但是由于线程之间是相互隔离的——线程没有访问共同的资源，尽管在执行任务的过程可能被CPU剥夺运行权，但是当它们再次获得运行权时对运行结果并没有影响，它们是安全的。\n考虑一种情况，如果多个线程访问同一个资源，并对资源内容进行修改，会发生什么情况？\n对于非原子性操作，多线程下会出现竞争条件，accounts[to] += amount操作，可以被拆分为多个CPU指令：\n 加载accounts[to]到寄存器 增加amount 将结果写回acounts[to]  线程运行到任何一个步骤时都可能被剥夺运行权。\n1 引例 考虑一个经典的“转账”示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82  public class UnsynchronizedTransfer { public static void main(String[] args) { double INITIAL_MONEY = 1000; int ACCOUNTS = 100; Bank bank = new Bank(ACCOUNTS, INITIAL_MONEY); // 可以增加循环次数观察“出错”的概率提升  for (int i = 0; i \u0026lt; 2; i++) { // 多个线程使用同一个bank资源  Thread t = new Thread(new TransferTask(bank)); t.start(); } } static class TransferTask implements Runnable { private Bank bank; private int size; private double maxAmount = 1000; public TransferTask(Bank bank) { this.bank = bank; this.size = bank.size(); } @Override public void run() { try { int from = (int) (size * Math.random()); int to = (int) (size * Math.random()); double amount = maxAmount * Math.random(); bank.transfer(from, to, amount); Thread.sleep((long) (size * Math.random())); }catch (InterruptedException e){ // e.printStackTrace();  } } } static class Bank { private final double[] accounts; public Bank(int accountCount, double money) { // initialize bank account  accounts = new double[accountCount]; Arrays.fill(accounts, money); } public void transfer(int from, int to, double amount) { if (accounts[from] \u0026lt; amount) return; if (from == to) return; // transfer  accounts[from] -= amount; // 这句打印语句增加了调度器剥夺线程运行权的风险  System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); } private double totalBalance() { double sum = 0; for (double a : accounts) { sum += a; } return sum; } int size() { return accounts.length; } } } /* output（sample）: Thread[Thread-1,5,main] move away Thread[Thread-0,5,main] move away Thread[Thread-1,5,main]: 217.65 from 30 to 20, Total Balance: 99445.52 Thread[Thread-0,5,main]: 554.48 from 55 to 53, Total Balance: 100000.00 *///：～   上例中，使用多个线程访问了Bank类的资源，在Bank类的transfer()方法中，额外增加了一句控制台输出，这是为了增加线程被调度的可能性1 （如果注释这句，会发现程序异常的概率会变小）。Bank类初始化时分配100个“账户”，每个账户1000元，然后不断转账，观察所有账户总额的变化。\n仔细观察输出（循环2次，出现的概率较小），我们看到:\n  线程1在输出 move away 之后被剥夺运行权；\n  接着线程0在 move away 之后也被剥夺运行权；\n  线程1继续运行，此时问题就出现了，总金额不是100000：\n在计算总额时，线程1获取账户55的余额时少了554.48元，这正是第2步中线程0的accounts[from] -= amount将账户55的余额减少的金额。\n  实际上CPU的调度过程比上述分析复杂得多，在Bank类的transfer()方法中，每一行代码在运行时都可能被剥夺运行权，值得一提的是，上例输出操作的还不是相同的“账户”，若是操作同样的“账户”，情况将变得更复杂。\n所以说线程不安全是一种不确定性，在有限的线程时，它可能发生也可能不发生，比如main()方法里只循环1次时就不会发生，循环100次就极大概率会发生。并发编程就是要消除这种不确定性。\n在接下来的示例中，有一个生成偶数的工具类，在多线程条件下调用生成偶数的方法并加以判断，若发现不是偶数则退出程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  public class UnSynchronizedEvenGenerator { public static void main(String[] args) { System.out.println(\u0026#34;press Ctrl-C to exit\u0026#34;); EvenGenerator evenGenerator = new EvenGenerator(); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; 3; i++) { executorService.execute(new Thread(new EvenTask(evenGenerator))); } executorService.shutdown(); } static abstract class AbstractIntGenerator { // 此处使用了volatile  private volatile boolean canceled = false; public abstract int next(); public void cancel() { canceled = true; } public boolean isCanceled() { return canceled; } } static class EvenGenerator extends AbstractIntGenerator { private int even = 0; @Override public int next() { ++even; // danger here!  ++even; return even; } } static class EvenTask implements Runnable { private EvenGenerator evenGenerator; public EvenTask(EvenGenerator evenGenerator) { this.evenGenerator = evenGenerator; } @Override public void run() { while (!evenGenerator.isCanceled()) { int next = evenGenerator.next(); if (next % 2 != 0) { System.out.println(Thread.currentThread().toString() + next + \u0026#34; not even!\u0026#34;); evenGenerator.cancel(); } } } } } /* output: (sample) press Ctrl-C to exit Thread[pool-1-thread-2,5,main]1427 not even! Thread[pool-1-thread-1,5,main]1425 not even! Thread[pool-1-thread-3,5,main]1429 not even! *///:~   上例中，当循环次数只有1次时，程序会一直执行，直到按下Ctrl-C手动结束任务；而当循环次数大于1时，无论其运行多长时间，其总会结束。\nAbstractIntGenerator类中的canceled标志是基本数据类型，而Java内存模型规定，所有原始类型对象（除了double和long）的读写都是原子的2；并且由volatile修饰，说明其是可见的，因此当发生错误时，所有线程都能读取到cancel信息而退出。\n 这个表述没错，程序确实也退出了，但是不够严谨。\n查看示例输出可以看到，有3个线程的输出信息，按照输出顺序可以作如下推测：\n  线程2发现奇数，修改cancel为true\n  线程1发现奇数，修改cancel为true\n  嗯？为什么线程1还会执行？根据volatile的语义，线程1不是应该“发现”线程1对cancel的改动么？\n实际上volatile的语义只能保证在线程2之后执行的语句能够发现cancel的改动\n但是由于run()方法没有任何同步，所以线程2可能是在线程1while执行之后剥夺线程1的运行权而运行的\n这时线程2对cancel的修改是线程1while语句之后的语句可见\n EvenGenerator类中通过两次自增运算获取下一个偶数，这在单线程下是没问题的，但是自增运算也不是原子性操作，其仍可被拆分为多个CPU指令3，并且被调度器剥夺运行权，在多线程条件下问题就会显现。\n 如何确定自增运算不是原子性的呢？\n以下是javap -c -v UnSynchronizedEvenGenerator\\$EvenGenerator输出的字节码（部分）\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public int next(); descriptor: ()I flags: ACC_PUBLIC Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field even:I  5: iconst_1 6: iadd 7: putfield #2 // Field even:I  10: aload_0 11: dup 12: getfield #2 // Field even:I  15: iconst_1 16: iadd 17: putfield #2 // Field even:I  20: aload_0 21: getfield #2 // Field even:I  24: ireturn    可以看到，一个自增操作被拆分为至少43个步骤：\n get字段even add修改even put设置even  在未同步的情况下，其中执行到其中任何一步的时候都可能被CPU剥夺运行权\n 如何解决多线程下共享资源的竞争条件呢？\n基本上所有的并发模式在解决线程冲突问题时，都采用序列化访问共享资源的方式。即同一时刻只允许某一个线程访问资源，其他线程被阻塞。通常是通过在代码前面加上一条锁语句来实现的，由于锁产生了一种互斥的效果，这种机制也被称为互斥量（ mutex ）。\n2 可重入锁 Java SE 5之后提供了位于java.util.concurrent.locks包下的显式互斥机制——Lock对象（显式锁），Lock对象必须被显示的创建，锁定和释放。\n一般情况下 ，ReentrantLock保护代码块的基本结构是：\n1 2 3 4 5 6  myLock.lock(); // 可重入锁 try{ // 临界区代码 }finally{ myLock.unlock(); }   这个结构可以确保只有一个线程进入临界区( critical section )，其他线程调用lock()时会被阻塞，直到第一个线程释放锁。\n我们利用锁机制来修改之前的转账逻辑，看看会发生什么：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  static class Bank { private final double[] accounts; // lock  private Lock lock; public Bank(int accountCount, double money) { // initialize bank account  accounts = new double[accountCount]; Arrays.fill(accounts, money); // 使用可重入锁  lock = new ReentrantLock(); } public void transfer(int from, int to, double amount) throws InterruptedException { lock.lock(); try { if (accounts[from] \u0026lt; amount) return; if (from == to) return; // transfer  accounts[from] -= amount; System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); } finally { // 确保锁被释放  lock.unlock(); } } private double totalBalance() { //lock.lock();  //try {  double sum = 0; for (double a : accounts) { sum += a; } return sum; //} finally {  //\tlock.unlock();  //}  } int size() { return accounts.length; } } /* output: (partial) Thread[Thread-0,5,main] move away Thread[Thread-0,5,main]: 948.12 from 22 to 50, Total Balance: 100000.00 Thread[Thread-2,5,main] move away Thread[Thread-2,5,main]: 722.25 from 36 to 84, Total Balance: 100000.00 Thread[Thread-4,5,main] move away Thread[Thread-4,5,main]: 621.82 from 62 to 45, Total Balance: 100000.00 Thread[Thread-6,5,main] move away Thread[Thread-6,5,main]: 628.81 from 18 to 51, Total Balance: 100000.00 Thread[Thread-8,5,main] move away ... *///:~   上例中，我们只对transfer()方法进行加锁，任务执行完成之后释放锁。每个线程在执行任务时都会获取锁，此时其他任务被阻塞。从控制台输出来看，也是这样的：线程是有序执行的，下一个线程总是等待上一个线程执行完才开始执行，这样，无论多少次转账，总金额也不会变。\n 思考一个问题：totalBalance()方法是否需要加锁？\n 上面的示例使用了可重入锁5（ReentrantLock），可重入的意思是同一个线程可以重复获取锁，由一个计数器来记录锁获取的次数6，它实现了Lock接口的所有方法：\n   public void lock() {\u0026hellip;}\n若锁未被其他线程获取，获取锁，并将锁的计数器置为1，立即返回\n若当前线程已经获取锁，锁的计数器+1，立即返回\n若锁被其他线程占有，那么此线程休眠7\n  public void lockInterruptibly() throws InterruptedException {\u0026hellip;}\n同lock()，不过此法可以被中断（interrupted）\n  public boolean tryLock() {\u0026hellip;}\n尝试获取锁并立即返回，成功获取同lock()并返回true，失败则返回false\n  public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {\u0026hellip;}\n  带有超时机制的尝试获取锁，此法可被中断\n  public void unlock() {\u0026hellip;}\n若计数器\u0026gt;1，则计数器-1，不释放锁，否则计数器置为0并释放锁\n  public Condition newCondition() {\u0026hellip;}\n获取锁的条件对象\n   下例展示了尝试获取锁的情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  public class AttemptLocking { private Lock lock = new ReentrantLock(); public static void main(String[] args) throws InterruptedException { AttemptLocking al = new AttemptLocking(); al.untimed(); al.timed(); new Thread(() -\u0026gt; { al.lock.lock(); System.out.println(\u0026#34;fetched\u0026#34;); }).start(); // let thread-0 finish  Thread.sleep(100); al.untimed(); al.timed(); } void untimed() { boolean b = lock.tryLock(); try { System.out.println(\u0026#34;tryLock(): \u0026#34; + b); } finally { if (b) lock.unlock(); } } void timed() { boolean b = false; try { b = lock.tryLock(2, TimeUnit.SECONDS); System.out.println(\u0026#34;tryLock(2, TimeUnit.SECONDS): \u0026#34; + b); } catch (InterruptedException e) { // e.printStackTrace();  } finally { if (b) lock.unlock(); } } } /* output: tryLock(): true tryLock(2, TimeUnit.SECONDS): true fetched tryLock(): false tryLock(2, TimeUnit.SECONDS): false *///:~   可以看到，main()方法中使用新线程获取了锁而不释放，此时再使用方法获取锁时失败，注意timed()方法在2s等待之后才返回失败。\n 可重入锁可以构建公平锁或非公平锁，默认使用非公平锁（上下文切换少，吞吐量高）。\n 2.1 条件 思考转账的逻辑，当从from转帐amount到to账户时，若from余额不足，任务会直接返回。\n若想在from账户余额足够时再执行任务而不是直接退出，应该怎样做呢？\njava.util.concurrent.locks包下还提供了Condition对象，这个对象用来管理那些获得锁但是不能执行任务（条件不满足）的线程，条件可以这样使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public void transfer(int from, int to, double amount) throws InterruptedException { lock.lock(); try { if (accounts[from] \u0026lt; amount) { // could be interrupted  suficient.await(); }; if (from == to) return; // transfer  accounts[from] -= amount; System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); // invoke all waited condition  suficient.signalAll(); } finally { lock.unlock(); } }   此时，当余额不足时，线程不再退出，而时等待其他转账线程唤醒之，知道满足条件继续执行任务。\n   void await() throws InterruptedException;\n使当前线程等待，和条件相关的锁被释放。等待的线程可以被singal()或singalAll()唤醒；若线程被中断也会解除等待状态；解除状态的线程重新排队获取锁\n  void signalAll();\n唤醒所有在此条件上等待的线程，被唤醒的线程需要重新获取锁\n  void signal();\n选一个在此条件上等待的线程将其唤醒，此方法具有随机性\n   此外，Condition还有一些带有超时参数和阻止中断的方法，请参照Java SE API\n到此为止，我们可以利用锁和条件将转账任务改进为线程安全，功能更丰富类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109  public class SynchronizedTransfer { static double INITIAL_MONEY = 1000; public static void main(String[] args) { int ACCOUNTS = 100; Bank bank = new Bank(ACCOUNTS, INITIAL_MONEY); for (int i = 0; i \u0026lt; ACCOUNTS; i++) { Thread t = new Thread(new TransferTask(bank)); t.start(); // test thread  /* new Thread(new Runnable() { @Override public void run() { double v = bank.totalBalance(); BigDecimal bigDecimal = new BigDecimal(v).setScale(2,BigDecimal.ROUND_HALF_UP); if (bigDecimal.intValue() != 100000){ System.out.println(bigDecimal + \u0026#34; is not even!\u0026#34;); } } }).start();*/ } } static class TransferTask implements Runnable { private Bank bank; private int size; private double maxAmount = INITIAL_MONEY; public TransferTask(Bank bank) { this.bank = bank; this.size = bank.size(); } @Override public void run() { try { int from = (int) (size * Math.random()); int to = (int) (size * Math.random()); // int to = (from + 1 \u0026gt;= size) ? 0 : from + 1;  double amount = maxAmount * Math.random(); bank.transfer(from, to, amount); Thread.sleep((long) (size * Math.random())); } catch (InterruptedException e) { // e.printStackTrace();  } } } static class Bank { private final double[] accounts; // lock  private Lock lock; // condition  private Condition suficient; public Bank(int accountCount, double money) { // initialize bank account  accounts = new double[accountCount]; Arrays.fill(accounts, money); lock = new ReentrantLock(); suficient = lock.newCondition(); } public void transfer(int from, int to, double amount) throws InterruptedException { lock.lock(); try { if (accounts[from] \u0026lt; amount) { // could be interrupted  suficient.await(); }; if (from == to) return; // transfer  accounts[from] -= amount; System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); // invoke all waited condition  suficient.signalAll(); } finally { lock.unlock(); } } private double totalBalance() { // lock.lock(); // try {  double sum = 0; for (double a : accounts) { sum += a; } return sum; // } finally { // lock.unlock(); // }  } int size() { return accounts.length; } } }   实际上，上例在totalBalance()方法不加锁的情况下，转账任务也是安全的。\n回答之前提出的问题：totalBalance()方法究竟是否需要加锁？\n请注意main()方法中被注释的部分，它创建一个线程（记为T）去读取所有账户的余额，判断余额是否和初始化时相等。使用BigDecimal是为了处理Double数据类型的精度丢失。在totalBalance()不加锁的情况下，我们很容易看到这样的输出：\n1 2 3 4 5 6 7 8  /* Thread[Thread-0,5,main] move away Thread[Thread-0,5,main]: 793.81 from 86 to 37, Total Balance: 100000.00 99206.19 is not even! Thread[Thread-2,5,main] move away Thread[Thread-2,5,main]: 814.24 from 30 to 49, Total Balance: 100000.00 ... *///:~   这给出一个暗示：在有其他的线程访问totalBalance()方法时，totalBalance()不是线程安全的。尽管transfer()方法加锁了，任意时刻只有一个线程访问totalBalance()方法，但是T和转账线程不相关，它可被CPU调度与转账线程竞争对totalBalance()方法中的accounts资源的访问，正如上述输出所显示的那样。\n所以，是否加锁应该以资源是否共享为参照\n当没有被注释的部分时，由于transfer()方法加锁了，线程在transfer()方法中调用totalBalance()不会受到其他线程的影响；当被注释的线程运行时，这时totalBalance资源可能被共享访问了，为保证安全就必须加锁。\n3 synchronized关键字 自Java 1.0开始，每一个对象都有一个隐式内部锁（ intrinsic lock ），在Java API Specification中通常被称为监视器。这个内部锁由synchronized关键字提供支持。synchronized关键字的语义就是“同步的”，这意味着使用这个关键字可以处理共享资源的冲突。\n当访问被synchronized关键字保护的方法或代码块时，它将检查锁能否获得——这个锁可以是当前类对象的锁，也可以是一个临时锁( ad-hoc lock )，取决你如何使用，任务执行完成之后会释放锁。\n和ReentrantLock一样，synchronized关键字获取的锁是独占锁，并且也是“可重入”的，某个任务可以多次获得对象的锁，并由计数器维护获得锁的次数，当退出一个方法时，计数器-1，完全退出时，才释放锁，这和可重入锁的机制是一样的。\n类对象也持有一个锁，也就是说synchronized关键字可作用于静态方法。\n关于什么时候该使用同步， Brian Goetz 提出过同步规则：\n 若向一个变量写入值，它可能接下来被另一个线程读取，或者正在读取一个上一次由另一个线程写过的值，那么必须使用同步，并且读写线程都必须使用相同的监视器同步。\n 监视器是由 Per Brinch Hansen 和 Tony Hoare 提出的一种无锁机制，最初的监视器具有如下特性：\n 监视器是只包含私有域的类 每个监视器的类对象有一个相关的锁 使用该锁对所有相关的方法加锁 该锁可以有任意多个相关条件  Java不完全地采用了监视器的设计概念，这就是synchronized关键字。\n在使用synchronized关键字时，将共享域设为私有是非常重要的。由于域只能通过方法访问，而synchronized保证方法执行的有序性；若域不是私有的，其他任务可以直接操作域，这就可能产生冲突。\n3.1 同步方法 当synchronized关键字作用于方法时，表示这个方法是同步的，执行方法时，首先会尝试获取当前对象的锁——这个对象一般是类的实例对象（ this ），若是静态方法，便是类对象（ Class ）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public synchronized void transfer(int from, int to, double amount) throws InterruptedException { if (accounts[from] \u0026lt; amount) wait(); // can be interrupted  if (from == to) return; // transfer  accounts[from] -= amount; System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts[to] += amount; System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); notifyAll(); // wake up all threads waiting on this monitor }   考虑转账的任务，只需要将transfer()方法加上synchronized关键字即可保证安全，运行此方法时，线程会先去获取Bank实例的内部锁，并将其他线程阻塞，此线程完成之后会释放这个对象锁，其他线程方可继续运行。\n继续思考之前的问题，对于synchronized的transfer()方法，里面调用了totalBalance()方法，那totalBalance()方法是否需要同步呢？前面说过「是否加锁应该以**资源是否共享为参照**」，这其实和“同步法则“是的表述是一致的。如果只有多个线程访问transfer()方法，正好此方法是**串行访问**（有序访问）的，那么totalBalance()方法无需同步；若还有其他线程对访问totalBalance()方法的资源，那么必须使用同步。\n3.2 同步代码块 synchronized关键字也可以用于同步代码块（同步阻塞）。\n在用于同步方法时，相当于synchronized(this)，而同步代码块则多了一点灵活性。\n1 2 3  synchronized (obj){ // synchronized block  // critical section }   示例中的obj可以是 this ，也可以是其他对象。\n考虑最开始的EvenGenerator类，在next()方法中可以使用同步代码块加锁可保证安全性：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  static class EvenGenerator extends AbstractIntGenerator { private Integer even = 0; private Object lock = new Object(); @Override public int next() { // equals to using  // synchronized (this){  synchronized (lock) { ++even; Thread.yield(); ++even; // return语句必须包含在同步代码块里  return even; } } }   上例中，synchronized关键字使用了“其他对象”lock的锁，注意，synchronized代码块必须包括所有读写域的代码，包括return语句。\n 从字节码来看，return语句也不是原子性的——它要先加载并获取变量域even的值，然后再返回\nJava语言规范规定对变量的读写都是原子的（long和double）除外，因此return语句是原子的。但是单一语句的原子性并不能保证多线程的安全性，如果锁在return之前被释放，那么return可能获取到其他线程修改后的值。\n 可以看到，使用synchronized关键字比使用显示锁代码更加简洁。\n需要注意的是，尽管synchronized代码块中的锁可以是任意对象的，但是尽量不要把这种任意性视为绝对安全的。一般在同步代码块中使用this或某“不可变”域（上例中）的锁。\n考虑如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  static class Bank { private final Vector\u0026lt;Double\u0026gt; accounts; public Bank(int accountCount, double money) { // initialize bank account  accounts = new Vector\u0026lt;\u0026gt;(accountCount); List\u0026lt;Double\u0026gt; doubles = Collections.nCopies(accountCount, money); accounts.addAll(doubles); } public void transfer(int from, int to, double amount) { synchronized (accounts) { if (accounts.get(from) \u0026lt; amount) return; if (from == to) return; // transfer  accounts.set(from, accounts.get(from) - amount); System.out.println(Thread.currentThread() + \u0026#34; move away\u0026#34;); accounts.set(to, accounts.get(to) + amount); System.out.printf(\u0026#34;%s: %10.2f from %d to %d, Total Balance: %10.2f%n\u0026#34;, Thread.currentThread(), amount, from, to, totalBalance()); } } }   上例中使用Vector作为账户的容器，Vector()是同步的，是否可以不加锁呢？\n不是的，Vector()只能保证其实现方法是同步的，并不能保证transfer方法是同步的。换言之，accounts.set()方法是同步的，其完成之后该线程可能被剥夺运行权。\n作为改进，在transfer()方法中截获了accounts的锁，尝试使其同步，它是可行的。但是这是否意味着可以任意使用其他对象的锁呢？Java核心卷I给出一段晦涩的评论8：\n如果冒昧地使用某个其他域（客户端锁定）的锁，可能不能保证安全性\n This approach works, but it is entirely dependent on the fact that the Vector class uses the intrinsic lock for all of its mutator methods. However, is this really a fact? The documentation of the Vector class makes no such promise. You have to carefully study the source code and hope that future versions do not introduce unsynchronized mutators. As you can see, client-side locking is very fragile and not generally recommended.\n 其晦涩之处在于，synchronized使用accounts的内部锁保证同步，和Vector方法使用的锁是不是accounts的内部锁有什么联系？\n3.3 在哪使用同步 从之前的阐述我们知道，如果多个线程同时对共享资源进行访问，并且至少有一个线程对资源进行了写操作，那就需要同步。\n在编写同步代码的时候，我常常困惑，应该在哪里使用同步呢？究竟是在线程上同步还是应该在资源方法上同步，还是所有位置都需要同步？\n接下来我们从两个维度去剖析“在哪里同步”这个问题。\n3.1 在资源上同步 1 2 3 4 5 6 7 8 9 10 11 12 13 14  // 资源 synchronized void next(){ x++; } // 任务1 run(){ next(); } // 任务2 run(){ next(); }   这是常见的模式。当在资源上同步时，使用多线程执行任务1和任务2，都不会出现线程安全的问题。因为每一个对x进行操作的线程都会被同步阻塞。这就是资源的序列化访问。\n3.2 在任务上同步 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  final Lock lock ; // 资源 void next(){ x++; } // 任务1 run(){ synchronized(lock){ next(); } } // 任务2 run(){ next(); }   如上代码示例所示，我们在任务1的run()方法上使用同步，当多个线程实例执行任务1时，x是线程安全的。\n需要提出的是，run()方法中的synchronized使用的锁不能是this，如果是this，那么同步块将毫无作用。\n但是若此时有线程执行任务2，那么此代码的安全隐患就出现了：任务2的操作和任务1的操作就会互相干扰!\n若想保证线程安全，那么任务2的next方法也要和任务1一样使用同步，并且使用相同的对象锁。\n这样的条件下，同时运行任务1和任务2，那么线程会在lock对象上获取锁而进入同步阻塞，从而保证安全性，和在资源上同步的效果是等同的。\n3.3 建议 从代码的简洁性，可读性与可复用性上来讲，在资源上使用同步显得更加优雅，两种实现方式的代码可以进行比较直观的对比：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  // 在任务上同步 public TV call() { while (true) { synchronized (tick) { TV tv = tl.get(); tv.setT(Thread.currentThread()); if (tick.getTick()) { tv.setV((tv.getV() == null ? 0 : tv.getV()) + 1); tl.set(tv); try { // 给其他线程机会  tick.wait(10); } catch (InterruptedException e) { e.printStackTrace(); } } else { if (!tick.isTickSupply) break; } } } return tl.get(); } // 在资源上使用同步 public TV call() { while (true) { TV tv = tl.get(); tv.setT(Thread.currentThread()); // getTick()方法同步  if (tick.getTick()) { tv.setV((tv.getV() == null ? 0 : tv.getV()) + 1); tl.set(tv); TimeUnit.MILLISECONDS.sleep(1); } else { if (!tick.isTickSupply) break; } } return tl.get(); }   上述代码的作用是一样的，可以看到，在资源上使用同步比在任务上使用同步的代码更加易读，简洁。\n正如之前所说的，在资源上使用同步还可以避免新建任务时又重新设计同步逻辑。\n因此，在资源上使用同步是建议的方式。\n扩展阅读: https://docs.oracle.com/javase/tutorial/essential/concurrency/syncmeth.html\n4 原子性与原子类 原子性一般指原子操作，原子操作不能被线程调度机制中断，一旦操作开始，那么它一定可以在可能发生的上下文切换之前完成。Java语言规范规定了对基本对象(long和double除外)的读写操作是原子的2。\n不能将原子性和同步划等号！更不能使用原子性来代替同步，当你想使用原子性代替同步写出无锁代码时，思考 Brain Goetz 的建议：\n If you can write a high-performance JVM for a modern microprocessor, then you are qualified to think about whether you can avoid synchronizing.\n 考虑如下几个操作：\n1 2 3 4 5  int x = 1; // s1 boolean flag = flase; // s2 int y = x; // s3 x++; // s4 double d = 1.9d; // s5   只有前2个操作是原子操作，后面的操作都不是原子操作。\n对于s3来说，可以拆分为读取x的值和将y赋值两个操作，虽然这两个操作都是原子的，但是合起来就不是原子操作了；s4就更复杂了；对于double和long类型的变量，JMM（Java Memory Model）规定了对其的写操作分为2步，每步写入32位，因此也不是原子的。\n4.1 原子性的误用 查看一个误用原子性的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  public class AtomicTest implements Runnable { private int i = 0; public int getValue() { // atomic operation  return i; } private synchronized void increment() { i++; i++; // equals to  // i += 2;  } @Override public void run() { while (true) increment(); } public static void main(String[] args) throws InterruptedException { AtomicTest at = new AtomicTest(); // 线程1  new Thread(at).start(); TimeUnit.MILLISECONDS.sleep(1); while (true) { // the value can still be odd  int value = at.getValue(); if (value % 2 != 0) { System.out.println(value); System.exit(0); } } } } /* output: (sample) 145881 *///:~   上例过分高估了原子性的能力，当另一个线程（mian线程）调用getValue()去访问共享变量时，尽管getValue()方法只有一个return语句，是原子性的，但还是获得了一个不希望的结果——奇数，为什么？虽然increment()方法是同步的，但是getValue()方法不需要锁即可访问共享域，此时的i可能在一个不稳定的中间状态。\n Java内存模型有如下约定9\n  Java的域都储存在主存（即物理内存）中\n  Java的工作线程有独立的内存（CPU缓存）\n  同步保证可见性\n  原子操作不保证可见性\n  依据上面的论断，尝试分析这个不稳定状态：increment()方法使用了同步，即increment()每次自增后都将变量i的结果写入主存；由于getValue()是无锁访问i，它可能获取的可能是increment()方法第一次自增的结果。\n 那么解决办法有：\n 同步getValue()方法； 将2步自增换成一步操作(并不能保证每次getValue()获取的都是期望值，只是不再出现奇数罢了)； 使用原子类  Java SE 5 引入了java.util.concurrent.atomic包，里面提供了原子性变量类，这些类提供了一些原子性操作，实际应用的不多，但合理应用可以提升应用性能。\n 不要过分依赖原子类，就像不要过分依赖原子性一样。\n 4.2 谨慎使用原子类 可以使用AtomicInteger类对AtomicTest类进行优化，使其得到预期的结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class AtomicClassTest implements Runnable { private AtomicInteger i = new AtomicInteger(0); public int getValue() { // atomic operation  return i.get(); } /** * 无锁的原因不是因为原子性，而是因为有且只有一个原子操作 * 若此处使用 * \u0026lt;pre\u0026gt; * i.incrementAndGet(); * i.incrementAndGet(); * \u0026lt;/pre\u0026gt; * 那么依旧和{@link AtomicTest}一样失败 */ private void increment() { i.addAndGet(2); } @Override public void run() { while (true) increment(); } public static void main(String[] args) throws InterruptedException { AtomicClassTest act = new AtomicClassTest(); ExecutorService executor = Executors.newSingleThreadExecutor(); executor.execute(act); ScheduledExecutorService s = Executors.newSingleThreadScheduledExecutor(); s.schedule(() -\u0026gt; { // 此方法不会主动退出  System.out.println(\u0026#34;Aborting...\u0026#34;); executor.shutdown(); s.shutdown(); System.exit(0); }, 5, TimeUnit.SECONDS); while (true) { int value = act.getValue(); // the value can still be odd  if (value % 2 != 0) { System.out.println(value); System.exit(0); } } } }   上面的示例中，方法不用同步，获取到的i的值也不会是奇数。\n思考这个问题，main线程每次读取的都是最新修改的i么？\n不一定\n因为原子性并不能保证可见性，main线程也并不能保证每次获取的都是最新的i值。\n5 可见性（volatile） 在讨论原子性的时候，提到了原子操作并不能保证可见性。什么是可见性？可见性指的是一个变量被被线程修改后，另一个线程能够马上知道这一修改。\nJava SE 5 提供了volatile关键字保证可见性，对volatail域的修改会马上写入到主存中，其他线程会的本地缓存会失效而从主存中去读取。\n听起来不错，volatile似乎可以解决资源共享的问题，真的是这样么？\n遗憾的是，volatile并不能保证原子性：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public class VolatileIsNotAtomic { // 将变量设置为volatile并不能保证并发安全  private volatile int sum; void increase() { sum++; } void multiThread2() throws InterruptedException { for (int i = 0; i \u0026lt; 10; i++) { Thread thread = new Thread(() -\u0026gt; { for (int j = 0; j \u0026lt; 1000; j++) { increase(); } }); thread.start(); } Thread.sleep(3000); System.out.println(sum); } public static void main(String[] args) throws InterruptedException { VolatileIsNotAtomic va = new VolatileIsNotAtomic(); va.multiThread2(); } } /* output:(sample) 8806 *///:~   上例中将域设置为volatile并不能解决多线程环境下的资源共享问题，原因在于，volatile只保证了可见性，没有保证共享资源的有序访问。\nvolatile关键字的使用非常有限，当想使用volatile关键字的时候，需要仔细考量，因为其可能有潜在的多线程风险。\nvolatiile关键字最著名的应用是在双重检查( double-check-lock )单例中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class DoubleCheckSingleton { private static volatile DoubleCheckSingleton instance; private DoubleCheckSingleton() { } public static DoubleCheckSingleton getInstance() { if (instance == null) { synchronized (DoubleCheckSingleton.class) { // the double check lock  if (instance == null) { instance = new DoubleCheckSingleton(); } } } return instance; } }   更详细的关于volatile关键字的介绍：Java内存模型与volatile关键字\n6 临界区 使用synchronized关键字对整个方法加锁（防止其他线程访问整个方法）往往会带来更大的性能开销，如果你只想保护某些代码块，可以使用同步代码块，这一段被锁保护的代码块就称为临界区（ critical section ），前面的显式锁所保护的区域以及使用synchronized保护的代码块都是临界区。\n7 线程本地存储ThreadLocal 既然共享资源需要考虑同步问题，那么阻止资源共享就可避免线程冲突10。java.lang.ThreadLoacl类提供了一种机制，为使用相同变量的不同线程提供不同的存储，称为线程本地存储。\n考虑SimpleDateFormat类，它不是线程安全的，如果作为全局变量，在多线程情况下可能会出现问题。使用同步的开销太大，一般是直接使用局部变量来解决问题，不过这也很浪费资源。因为SimpleDateFormat不必是共享资源，这时候，可以使用线程本地存储：\n1 2 3 4  public static final ThreadLoacl\u0026lt;SimpleDateFormat\u0026gt; dateFormat = ThreadLoacal.withInitial(()-\u0026gt;{ new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;); })   这样每个线程都有一个dataFormat实例。\n下例中，每个线程都有一个线程本地存储，用于存储一个0-100的随机数，然后对其进行自增运算：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  public class ThreadLocalVariableHolder { // Java 8 提供的方法  /*static final ThreadLocal\u0026lt;Integer\u0026gt; value = ThreadLocal.withInitial(new Supplier\u0026lt;Integer\u0026gt;() { @Override public Integer get() { Random r = new Random(); return r.nextInt(10); } });*/ static class Task implements Runnable { static final ThreadLocal\u0026lt;Integer\u0026gt; value = new ThreadLocal\u0026lt;Integer\u0026gt;() { private Random r = new Random(); @Override protected synchronized Integer initialValue() { return r.nextInt(100); } }; static void increment() { value.set(value.get() + 1); } static Integer getValue() { return value.get(); } @Override public String toString() { return Thread.currentThread() + \u0026#34;: \u0026#34; + getValue(); } @Override public void run() { while (!Thread.currentThread().isInterrupted()) { increment(); System.out.println(this); } } } public static void main(String[] args) throws InterruptedException { for (int i = 0; i \u0026lt; 2; i++) { new Thread(new Task()).start(); } TimeUnit.MILLISECONDS.sleep(1); System.exit(0); } } /* output(sample): Thread[Thread-1,5,main]: 41 Thread[Thread-3,5,main]: 19 Thread[Thread-1,5,main]: 42 Thread[Thread-3,5,main]: 20 Thread[Thread-1,5,main]: 43 Thread[Thread-3,5,main]: 21 ... *///:~   可以看到，虽然没有同步，但是也无需担心资源冲突的问题，线程1和线程3的数据不会互相干扰。\nThreadLoacl通常作为静态域存储，虽然多个线程只有一个ThreadLocal实例，但是每个实例都有自己的存储，并不会有竞争条件。\n一个使用TheadLocal的例子\n深入理解ThreadLocal\n8 再论Object超类 之前的讨论中，我们说到了Object超类的hashCode和equals方法，这次在多线程环境下阐释Object超类的其他几个重要方法。\n多线程条件下，使用互斥（mutex）来解决资源共享问题时常用手段，接下来讨论的是如何让2个线程之间协同起来。\n其实在可重入锁的条件对象的使用中，就使用了对象之间的协作——当要转账时，发现余额不足则当前转账线程等待，而被其他线程唤醒以继续执行（虽然它可能又进入等待）。它工作的机制是线程A获得了锁，但是发现其必须在某个条件上等待（余额充足），于是其阻塞并释放锁（可被中断），线程B得以获得锁并执行，B执行完成之后唤醒线程A，其进入Runnable状态。\n线程在条件上等待的工作逻辑:   Object对象的wait()，notify()和notifyAll()方法提供了线程线程之间协作的能力。\nwait()方法使当前线程进入等待，其还可以接受一个超时参数。\nwait()方法必须配合synchronized关键字使用，原因是调用wait()方法时，该对象的监视器被释放了——前提是必须要先持有对象的监视器。\nnotify()用于唤醒一个在当前监视器（如果是临界区，则是指定对象锁；若是同步方法，则是实例锁）上等待的线程，notify方法有相当的局限性：\n 并不是唤醒所有的wait()线程，它没有这个能力，只能唤醒在相同锁（监视器）上等待的线程； 并不是唤醒指定当前监视器的线程，它只唤醒一个，至于是哪一个是不确定的；  notifyAll()用于唤醒在当前监视器上等待的所有线程。\nnotify()和notifyAll()方法也只能在获取锁之后执行，被唤醒的线程也只有等调用notify()和notifyAll()方法的锁被释放之后才可能继续执行。\n考虑下面的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  public class WaitOnCondition { private volatile boolean tracked = false; synchronized void playTrack() throws InterruptedException { if (!tracked) { // 在WaitOnCondition实例上等待  wait(); } System.out.println(\u0026#34;play \u0026#34;); tracked = false; } synchronized void recordTrack() { if (tracked) { return; } System.out.println(\u0026#34;record \u0026#34;); tracked = true; // 最好不要使用notify,除非你明确地知道期待的线程一定被唤醒  notifyAll(); } class Play implements Runnable { @SneakyThrows @Override public void run() { while (true) { playTrack(); TimeUnit.MILLISECONDS.sleep(1000); } } } class Record implements Runnable { @SneakyThrows @Override public void run() { while (true) { recordTrack(); TimeUnit.MILLISECONDS.sleep(1000); } } } public static void main(String[] args) throws InterruptedException { WaitOnCondition tp = new WaitOnCondition(); var pool = Executors.newCachedThreadPool(); pool.submit(tp.new Play()); pool.submit((tp.new Record())); TimeUnit.SECONDS.sleep(5); System.exit(0); } } /* output: record play record play record play record play *///:~   record和play任务本来是可以无序运行的，但是由于play任务在playTrack()方法上使用了wait()，条件是布尔值tracked，该值由record任务在recordTrack时修改，修改完成之后record任务负责唤醒等待的线程。这样就完成了线程的交互。\n将tracked设置为volatile变量是volatile关键字的典型应用场景。\n 在使用条件时，应当谨慎地避免死锁。\n  一般看来，任务越耗时，其被CPU调度剥夺运行权的几率越大 \u0026#x21a9;\u0026#xfe0e;\n https://docs.oracle.com/javase/specs/jls/se15/html/jls-17.html#jls-17.7 \u0026#x21a9;\u0026#xfe0e;\n java文件编译的字节码会对Java代码进行拆分 \u0026#x21a9;\u0026#xfe0e;\n 尚不清楚前面aload_0以及dup的意义 \u0026#x21a9;\u0026#xfe0e;\n 可重入锁是典型的独占锁 \u0026#x21a9;\u0026#xfe0e;\n 计数器最大231-1 \u0026#x21a9;\u0026#xfe0e;\n 实际上线程进入同步队列中排队，并自旋尝试获取锁，获取失败则线程的中断状态置位 \u0026#x21a9;\u0026#xfe0e;\n Java核心技术卷1 第14章并发第14.5.6节同步阻塞 \u0026#x21a9;\u0026#xfe0e;\n 不一定正确，还需要查阅资料进行确认 \u0026#x21a9;\u0026#xfe0e;\n 有时候资源共享是必须的，同步也是必须的 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文介绍了“共享资源”的概念，并发条件下的共享资源变得异常敏感，稍不注意就可能引发资源一致性等其他安全问题。Java引入了多种策略来应对这种情况，著名的就是同步关键字和锁，还有诸如volatile关键字，原子类以及线程本地存储等手段。","id":27,"section":"posts","tags":["锁","synchronized","volatile"],"title":"资源访问受限-并发之二","uri":"http://wangy325.top/zh/posts/java/concurrency/%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE%E5%8F%97%E9%99%90-%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E4%B9%8B%E4%BA%8C/"},{"content":"并发是生产过程不可能绕过去的坎，要编写高性能的程序，必须使用并发。\n并发的本质是多个线程同时处理任务1，不同于进程，线程之间的资源是共享的，当程序不够严谨时，使用多线程就可能带来问题，这是要反复讨论并发的原因之一。\n在Java中，必须明白一点：线程由Thread类启动，但Thread类并不执行任何操作，它只是驱动赋予它的任务。因此将线程与任务的概念区分开，有利于理解并发。\n1 任务 任务是由线程驱动的，因此声明任务然后将其交给线程即可。\n可以使用Runnable2来声明任务，Runnable是一个函数式接口，定义了一个run()方法，因此常见的创建线程的方式就是：\n1 2 3  new Thread(()-\u0026gt;{ //do some thing })   将其还原为普通类，那就是一个实现了Runnable接口的类可以作为任务分配给线程，重要的是你需要定义好“任务要做什么”——重写run()方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class LiftOff implements Runnable { private static int taskCount = 0; protected int countDown = 10; private final int id = taskCount++; public LiftOff() { } public LiftOff(int countDown) { this.countDown = countDown; } public String status() { return \u0026#34;#\u0026#34; + id + \u0026#34;(\u0026#34; + (countDown \u0026gt; 0 ? countDown : \u0026#34;LiftOff!\u0026#34;) + \u0026#34;), \u0026#34;; } @Override public void run() { while (countDown-- \u0026gt; 0) { System.out.print(status()); // 线程调度  Thread.yield(); } } }   上例中的LiftOff类实现了Runnable接口，但是你无法再将其转化为lambda，因为其是一个“更为丰富的类”：有区分实例的id，有构造器以及实例方法。\n通常，run()方法被设计为某种形式的循环甚至无限循环。\nThread.yield()是Java的线程调度机制之一，它声明“当前线程可以让出CPU时间，其他线程需要运行的就去运行吧”，遗憾的是它仅仅是一个建议，其他线程不一定真的会获取CPU时间并运行。\n new LiftOff().run()可以直接调用，但这并不会开启一个单独线程，而是在当前线程中顺序执行的。\n 因此，从Runnabl导出的类，除了必须声明run()方法之外，其不会产生任何的线程能力，要实现线程行为，必须显式地将其分配给线程。\n2 线程 Thread即线程。将Runnable转为 工作任务 的的传统方法就是将其提交给Thread构造器：\n1 2 3 4 5 6 7 8 9  private static void single() { Thread t = new Thread(new LiftOff()); t.start(); System.out.println(\u0026#34;waiting for liftoff\u0026#34;); } /* output: waiting for liftoff #0(9), #0(8), #0(7), #0(6), #0(5), #0(4), #0(3), #0(2), #0(1), #0(LiftOff!), *///:~   从输出可以看到，start()迅速地返回了，而由start()开启的新线程的工作任务还在执行，此例中，main线程（主线程）与LiftOff.run()线程”同时“执行。\n可以很容易地利用循环创建多个线程去驱动更多任务3：\n1 2 3 4 5 6 7 8 9 10  static void multi() { for (int i = 0; i \u0026lt; 5; i++) { new Thread(new LiftOff()).start(); } System.out.println(\u0026#34;waiting for liftoff\u0026#34;); } /* output:（sample） #1(9), #4(9), waiting for liftoff #3(9), #2(9), #0(9), #2(8), #0(8), #3(8), #4(8), #1(8), #4(7), #3(7), #4(6), #2(7), #0(7), #2(6), #4(5), #3(6), #1(7), #3(5), #4(4), #2(5), #0(6), #2(4), #4(3), #3(4), #1(6), #3(3), #4(2), #2(3), #0(5), #2(2), #4(1), #3(2), #1(5), #3(1), #4(LiftOff!), #2(1), #0(4), #2(LiftOff!), #3(LiftOff!), #1(4), #0(3), #0(2), #1(3), #0(1), #1(2), #0(LiftOff!), #1(1), #1(LiftOff!), *///:~   可以看到，不同任务的执行时混乱无序的，这是由线程调度自动控制的。\n3 线程生命周期 NEW\n​\t线程被创建。\nRUNNABLE\n​\t调用start()方法之后，这个线程可能在或不在运行，因为其要等等CPU时间。\nBLOCKED\n​\t当一个线程尝试获取对象的内部锁失败时，该线程进入阻塞状态。\nWAITING\n​\t当线程等待另一个线程通知调度器一个条件时，它自己进入等待状态。如调用Object.wait()和Thread.join()方法时，或等待Lock或Condition时。\nTIMED_WAITING\n​\t带有超时参数的方法调用时会让线程进入计时等待。\nTERMINATED\n​\t1）run()方法正常退出，2）没有捕获的异常终止了run()方法。\n4 线程的中断状态 当run()方法return或遇到异常时，线程终止运行，除此之外，无法强制终止线程4。\n但是，线程有一个中断状态（ interrupted state ），调用interrup()方法时，线程的中断状态将被设置（ interrupt status will be set ）。\n线程的中断状态和线程的阻塞是互斥的\n 笼统地描述为线程中断和阻塞互斥是不合适的\n   若线程被wait()、join()、sleep()及其重载方法阻塞5，调用interrupt()方法将抛出InterruptedException，并且线程不会设置中断状态。\n  若在线程的中断状态下调用wait()、join()、sleep()及其重载方法使线程阻塞，被调用的方法同样会抛出 InterruptedException ，线程的中断状态会被清除。\n  下例演示了中断和休眠的关系：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  public class InterruptAndSleep { public static void main(String[] args) { Thread apple = new Thread(new InnerThread(), \u0026#34;apple\u0026#34;); Thread google = new Thread(new InnerThread(), \u0026#34;google\u0026#34;); apple.start(); google.start(); apple.interrupt(); } static class InnerThread implements Runnable { private static int count = 0; private final int id = count++; private int countDown = 2; public InnerThread() { } public void info() { System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) \u0026#34;); } @Override public void run() { try { while (countDown-- \u0026gt; 0) { // Thread.sleep(100);  // Java SE5 or later style  TimeUnit.MILLISECONDS.sleep(100); info(); } } catch (InterruptedException e) { // e.printStackTrace();  System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) is\u0026#34; + \u0026#34; interrupted\u0026#34;); } } } } /* output: id(0 Thread[apple,5,main]) is interrupted id(1 Thread[google,5,main]) id(1 Thread[google,5,main]) *///:~   上例说明了线程被中断（调用interrupted()方法）之后，再调用sleep()方法会抛出 InterruptedException。\n但是线程被中断并不意味线程终止了，其还有再次运行的能力，将上例中run()方法的循环稍作修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // try this while (countDown-- \u0026gt; 0) { try { // Thread.sleep(100);  // Java SE5 or later style  TimeUnit.MILLISECONDS.sleep(100); info(); } catch (InterruptedException e) { // e.printStackTrace();  System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) is\u0026#34; + \u0026#34; interrupted\u0026#34;); } } /* output: id(0 Thread[apple,5,main]) is interrupted id(0 Thread[apple,5,main]) id(1 Thread[google,5,main]) id(1 Thread[google,5,main]) *///:~   这说明，尽管调用sleep()抛出中断异常，线程并没有终止，并且线程的中断状态还被清除了，再次循环时程序正常运行。\n同样地，当线程休眠(TIMED_WAITING)时尝试中断线程的表现和上面差不多：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  public class InterruptAndSleep { public static void main(String[] args) { Thread apple = new Thread(new InnerThread(), \u0026#34;apple\u0026#34;); apple.start(); try { Thread.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(apple.getState()); apple.interrupt(); } static class InnerThread implements Runnable { private static int count = 0; private final int id = count++; private int countDown = 3; public InnerThread() { } public void info() { System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) \u0026#34;); } @Override public void run() { while (countDown-- \u0026gt; 0) { try { // Thread.sleep(100);  // Java SE5 or later style  TimeUnit.MILLISECONDS.sleep(100); info(); } catch (InterruptedException e) { // e.printStackTrace();  System.out.println(\u0026#34;id(\u0026#34; + id + \u0026#34; \u0026#34; + Thread.currentThread() + \u0026#34;) is\u0026#34; + \u0026#34; interrupted\u0026#34;); } } } } } /* output: id(0 Thread[apple,5,main]) TIMED_WAITING id(0 Thread[apple,5,main]) is interrupted id(0 Thread[apple,5,main]) *///:~   可以看到，当线程休眠时，调用interrupted()方法也会抛出异常，并且清除中断状态。\n使用isInterrupted()和interrupted()方法都可以获取线程的中断状态，二者的区别在于isInterrupted()方法不会清除线程的中断状态（ interrupted status of the thread is unaffected ）；但interrupted()方法会清除线程的中断状态，且该方法是静态方法。\n5 线程优先级 线程的优先级将线程的重要性传递给调度器，尽管CPU处理线程的顺序是不确定的，但是调度器倾向于优先让优先级高的线程执行6。\nJava语言中，每个线程都有一个优先级，默认情况下，一个线程的优先级继承自其父线程。\n在绝大多数时间里，线程都应该以默认优先级在运行，试图利用优先级操纵线程是愚蠢的行为。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  public class SimplePrioroites implements Runnable { private int countDown = 2; private volatile double d; private int priority; public SimplePrioroites(int priority) { this.priority = priority; } @Override public String toString() { return Thread.currentThread() + \u0026#34;: \u0026#34; + countDown; } @Override public void run() { Thread.currentThread().setPriority(priority); while (true) { for (int i = 0; i \u0026lt; 100000; i++) { // 耗时操作  d += (Math.PI + Math.E) / (double) i; if (i % 1000 == 0) { Thread.yield(); } } System.out.println(this); if (--countDown == 0) { return; } } } public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; 5 ; i++) { executorService.execute(new SimplePrioroites(Thread.MIN_PRIORITY)); } executorService.execute(new SimplePrioroites(Thread.MAX_PRIORITY)); executorService.shutdown(); } } /* output: Thread[pool-1-thread-2,1,main]: 2 Thread[pool-1-thread-5,1,main]: 2 Thread[pool-1-thread-3,1,main]: 2 Thread[pool-1-thread-1,1,main]: 2 Thread[pool-1-thread-4,1,main]: 2 Thread[pool-1-thread-6,10,main]: 2 Thread[pool-1-thread-3,1,main]: 1 Thread[pool-1-thread-2,1,main]: 1 Thread[pool-1-thread-5,1,main]: 1 Thread[pool-1-thread-1,1,main]: 1 Thread[pool-1-thread-4,1,main]: 1 Thread[pool-1-thread-6,10,main]: 1 *///:~   事实上，尽管设置了线程优先级，并且使用了10w次浮点运算来尝试让线程调度优先选择优先级高的线程7，实际上却没有收到预期效果，说明线程优先级并不能准确地调度线程。\n6 线程让步（yield） Thread.yield()是一个静态方法，可以给线程调度器一个暗示：当前线程的run()方法已经完成的差不多了，可以让别的线程（相同优先级）使用CPU了。注意，没有任何机制保证这个暗示一定会采纳。\n不要误用此方法！\n7 守护线程 有些地方称之为后台（daemon）线程，一般在程序运行时在后台提供通用服务，守护线程在程序开发中并不是必不可少的。\n当所有的非后台线程终止时，程序也会终止，同时也会杀死所有的守护线程。\n不要误用守护线程，不应该使用守护线程去访问资源——一旦主程序结束，守护线程也会被杀死。\n在守护线程里创建的线程一定也是守护线程。\n可以使用setDaemon(true)在start()之前将线程设置为守护线程，同时可以使用isDaemon()查看线程是否为守护线程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  public class Daemons { public static void main(String[] args) { Thread t =new Thread(new Daemon()); t.setDaemon(true); t.start(); try { TimeUnit.MILLISECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } } static class Daemon implements Runnable { private List\u0026lt;Thread\u0026gt; threads = new ArrayList\u0026lt;\u0026gt;(); @Override public void run() { for (int i = 0; i \u0026lt; Integer.MAX_VALUE; i++) { threads.add(i, new Thread(new ThreadSpawn())); threads.get(i).start(); // System.out.println(\u0026#34;ThreadSpawn \u0026#34; + i + \u0026#34; started\u0026#34;);  System.out.println(\u0026#34;thread[\u0026#34;+i+\u0026#34;].isDaemon: \u0026#34; + threads.get(i).isDaemon()); } // while (true) Thread.yield();  } } static class ThreadSpawn implements Runnable { @Override public void run() { Thread.yield(); } } } /* output: (sample) thread[0].isDaemon: true thread[1].isDaemon: true thread[2].isDaemon: true thread[3].isDaemon: true thread[4].isDaemon: true *///:~   上例中，Daemon被设置为守护线程，其派生出的许多线程虽然没有被显示的声明为守护线程，其也确实是守护线程。注意到，Daemon线程的run()方法是一个“很大”的循环，但实际上只循环了几次，那是因为主线程终止了，守护线程于是也被杀死了。\n 守护线程不会执行finally子句，这是因为守护线程被设计为“强制关闭“的，一旦所有的非守护线程终止，守护线程就会”突然“关闭，不允许存在执行finally块这样”优雅“的行为。\n 8 线程休眠 通常调用sleep()可以使线程中止一段时间，此时线程让出CPU时间给其他线程使用。\nJava SE 5 之后，可以使用 TimeUnit来执行这个行为8。\n对sleep()的调用可能引发中断异常（ Interrupted Exception ）。\n 需要说明的是，不同于Object.wait()，在使用同步时，线程的休眠并不会释放锁。\n 9 加入一个线程（join） 可以在一个线程（ A ）中调用另一个线程（ B ）的join()方法，其效果是A线程会进入等待（挂起），等待B线程执行完毕后再继续执行，join()方法可以接受一个时间参数，表示最长等待时间，若超时仍未返回，A线程继续执行。\njoin()方法可以被中断，中断发生的情况和休眠一致。\n下面的代码演示了 interrupt，sleep和join方法所执行的操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  public class JoinAndSleep { public static void main(String[] args) { Slepper sa = new Slepper(\u0026#34;sa\u0026#34;,100); Slepper sb = new Slepper(\u0026#34;sb\u0026#34;,100); Joiner ja = new Joiner(\u0026#34;ja\u0026#34;,sa); Joiner jb = new Joiner(\u0026#34;jb\u0026#34;,sb); sa.interrupt(); } } // 继承Thread来创建线程 class Slepper extends Thread{ private int duration; public Slepper(String name, int duration) { super(name); this.duration = duration; start(); } @Override public void run() { try{ sleep(duration); }catch (InterruptedException e){ System.out.println(currentThread() + \u0026#34;is interrupted ? \u0026#34; + isInterrupted()); return; } System.out.println(currentThread() + \u0026#34; has awakened.\u0026#34;); } } class Joiner extends Thread{ private Slepper slepper; public Joiner(String name, Slepper slepper) { super(name); this.slepper = slepper; start(); } @Override public void run() { try { slepper.join(); } catch (InterruptedException e) { System.out.println(currentThread() + \u0026#34; interrupted()\u0026#34;); return; } System.out.println(currentThread() + \u0026#34;join completed.\u0026#34;); } } /* output: Thread[sa,5,main]is interrupted ? false Thread[ja,5,main]join completed. Thread[sb,5,main] has awakened. Thread[jb,5,main]join completed. *///:~   上例中，ja和jb总是会等待sa和sb完成，sa在main()中被设置中断状态，因此在sa的run()方法执行sleep()会抛出异常，同时清除中断状态，因此中断状态为false。\n 可以使不同的线程中断查看程序的状态\n若上例在main()方法中使ja中断，那么可能的输出结果是：\n 1 2 3 4 5 6  /* Thread[ja,5,main] interrupted() Thread[sa,5,main] has awakened. Thread[sb,5,main] has awakened. Thread[jb,5,main]join completed. */   此时的情况是ja的run()方法中执行join()抛出异常，此时ja直接结束而不等待sa运行结束。\n上例中，还有一个关注点：在构造器中直接调用了start()方法，这种方式称为自管理线程。\n9.1 利用join实现简单的无锁同步 不难理解，“加入一个线程”含有让线程有序执行的语义，利用这个性质，可以实现简单的无锁同步。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  public class SyncWithoutSynchronized { private int sum; void increase() { sum++; System.out.println(Thread.currentThread() + \u0026#34;: \u0026#34; + sum); } /** 单线程模式 */ void singleThread() throws InterruptedException { Thread task = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 100; i++) { increase(); } }); task.start(); // 等待task执行完成  task.join(); System.out.println(sum); } void multiThread() throws InterruptedException { for (int i = 0; i \u0026lt; 10; i++) { Thread thread = new Thread(() -\u0026gt; { for (int j = 0; j \u0026lt; 10; j++) { increase(); } }); thread.start(); // 使用join()保证有序性，此时可以不需要同步  // join() 保证了happens-before原则  thread.join(); } // 主线程等待所有的子线程结束  System.out.println(sum); } public static void main(String[] args) throws InterruptedException { SyncWithoutSynchronized va = new SyncWithoutSynchronized(); // va.singleThread();  va.multiThread(); } } /* output: Thread[Thread-0,5,main]: 1 Thread[Thread-1,5,main]: 2 Thread[Thread-2,5,main]: 3 Thread[Thread-3,5,main]: 4 Thread[Thread-4,5,main]: 5 Thread[Thread-5,5,main]: 6 Thread[Thread-6,5,main]: 7 Thread[Thread-7,5,main]: 8 Thread[Thread-8,5,main]: 9 Thread[Thread-9,5,main]: 10 10 *///:~   上例使用后台任务计算1+2+...+10的值，主线程总是等待后台任务执行完成之后再返回。在multiThread()方法中，额外开启了10个线程，每一个线程都在主线程上调用join()方法，从输出来看，线程0-9是顺序执行的，最终的结果不会出现讹误，这种情况下，实现了无锁同步，而共享变量sum不需要额外处理。\n10 自管理线程 除了实现Runnable接口之外，还可以通过继承Thread类来创建线程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  public class SelfManageThread { public static void main(String[] args) { for (int i = 0; i \u0026lt;5 ; i++) { new SelfManaged(); // new SlefRunnable();  } } static class SelfManaged extends Thread { private static int count = 0; private final int id = count; public SelfManaged() { super(String.valueOf(++count)); // 在构造器中调用start()  start(); } @Override public String toString() { return \u0026#34;#\u0026#34; + getName() + \u0026#34;(\u0026#34; + id + \u0026#34;), \u0026#34;; } @Override public void run() { System.out.print(this); Thread.yield(); } } } /* output: (sample) * #1(1), #4(4), #5(5), #3(3), #2(2), *///:~   上面的示例中，对象创建时顺便创建并启动线程。\n一般地，任务都实现自Runnable接口，同样可以利用Runnable实现自管理线程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  static class SlefRunnable implements Runnable{ private static int count = 0; private final int id = ++count; private Thread t = new Thread(this, String.valueOf(id)); public SlefRunnable() { t.start(); } @Override public String toString() { return \u0026#34;#\u0026#34; + t.getName() + \u0026#34;(\u0026#34; + id + \u0026#34;), \u0026#34;; } @Override public void run() { System.out.print(this); Thread.yield(); } }   实现Runnable的好处是其可以再继承自某个类（如果需要的话）。\n由于示例比较简单，因此在构造器中启动线程可能是安全的。但是，并不建议在构造器中启动线程，这样可能会存在风险：另一个任务可能在实例初始化完成之前开始执行，这意味着访问处于不稳定的状态。\n10.1 惯用法 有时候，把线程以内部类的形式实现可能会很有用，就像上面的示例那样，甚至可以使用匿名内部类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  // form1 比较常用 //... Thread thread = new Thread(new Runnable() { private int count = 5; @Override public String toString() { return \u0026#34;#\u0026#34; + Thread.currentThread().getName() + \u0026#34;(\u0026#34; + count + \u0026#34;), \u0026#34;; } @Override public void run() { while (--count \u0026gt; 0) { System.out.print(this); Thread.yield(); } } }); thread.start(); //...  // form2 public class SelfManageThread { Thread thread; public SelfManageThread() { thread= new Thread(new Runnable() { private int count = 5; @Override public String toString() { return \u0026#34;#\u0026#34; + Thread.currentThread().getName() + \u0026#34;(\u0026#34; + count + \u0026#34;), \u0026#34;; } @Override public void run() { while (--count \u0026gt; 0) { System.out.print(this); Thread.yield(); } } }); thread.start(); } }   需要说明的是，本节讨论的都是显式创建线程的方式，这种方式在有些规范里已经不再推荐了，尤其在很多线程协同的场景下，创建并维护线程的成本以及上下文切换的成本会非常高，此时，线程池将是更好的选择。\n11 捕获异常 从线程中逃逸的异常不能被捕获，一旦线程中的异常逃逸到run()方法外部，那么它将会传播到控制台，这种情况下，线程就终止了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class ExceptionThread { public static void main(String[] args) { Thread t = new Thread(new ExceptionT()); try { t.start(); } catch (Exception x) { x.printStackTrace(); } } static class ExceptionT implements Runnable { @Override public void run() { throw new RuntimeException(); } } } /* Exception in thread \u0026#34;Thread-0\u0026#34; java.lang.RuntimeException at com.access.concurrency.basic.ExceptionThread$ExceptionT.run(ExceptionThread.java:22) at java.lang.Thread.run(Thread.java:748) *///:~   可以看到，线程抛出的异常无法被捕获。\n在Java SE 5之后，为Thread类添加了一个接口Thread.UncaughtExceptionHandler，该接口允许在每个Thread对象上分配一个异常处理器，用来应对线程出现未捕获的异常而濒临死亡的情况。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  public class ExceptionThread2 { public static void main(String[] args) { // 为线程分配默认异常处理器  Thread.setDefaultUncaughtExceptionHandler(new MyUncaughtExceptionHandler(true)); Thread t = new Thread(new ExceptionT()); // 分配异常处理器  t.setUncaughtExceptionHandler(new MyUncaughtExceptionHandler()); t.start(); } static class ExceptionT implements Runnable { @Override public void run() { throw new RuntimeException(); } } // 自定义异常处理器  static class MyUncaughtExceptionHandler implements Thread.UncaughtExceptionHandler { private boolean isDeafult; public MyUncaughtExceptionHandler() { } public MyUncaughtExceptionHandler(boolean isDeafult) { this.isDeafult = isDeafult; } @Override public void uncaughtException(Thread t, Throwable e) { System.out.println(\u0026#34;default ?(\u0026#34; + isDeafult+ \u0026#34;) \u0026#34; + \u0026#34;caught \u0026#34; + e); } } } /* output: default ?(true) caught java.lang.RuntimeException *///:~   给线程分配异常处理器的的方法有2个：\n public static void setDefaultUncaughtExceptionHandler(UncaughtExceptionHandler eh){\u0026hellip;} public void setUncaughtExceptionHandler(UncaughtExceptionHandler eh) {\u0026hellip;}  其中给线程分配默认异常处理器是静态方法，调用之后，在此线程内创建的所有线程都使用此异常处理器。\n 多处理器下尤其如此，单处理器下Java的调度机制是“抢占式”的，谁获取CPU时间片谁运行。 \u0026#x21a9;\u0026#xfe0e;\n 这并不是唯一的方式。 \u0026#x21a9;\u0026#xfe0e;\n 此例中，只有一个主线程去创建LiftOff线程，如果有多个主线程去创建LiftOff线程，那么可能就会出现重复id的LiftOff实例。 \u0026#x21a9;\u0026#xfe0e;\n 早期版本中，可以使用stop()方法终止线程，这个方法已经过时了。 \u0026#x21a9;\u0026#xfe0e;\n 若以线程的活动来判断，这些方法会“阻塞”线程，从线程的生命周期来看，并不完全是这样。线程的I/O阻塞和中断的关系将在后文中讨论。 \u0026#x21a9;\u0026#xfe0e;\n 和yield()方法一样，倾向性并不是绝对的。 \u0026#x21a9;\u0026#xfe0e;\n 一般看来，任务越耗时，其被CPU调度剥夺运行权的几率越大。 \u0026#x21a9;\u0026#xfe0e;\n 上文已多处使用此方法。 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文介绍了Java并发的基础概念——线程，包括线程的创建，生命周期，以及Thread类的一些常用方法如让步(yield)，加入(join)，顺便介绍了如何使用UncaughtExceptionHandler处理线程中抛出的异常。","id":28,"section":"posts","tags":["线程"],"title":"线程与任务-并发之一","uri":"http://wangy325.top/zh/posts/java/concurrency/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E4%B9%8B%E4%B8%80/"},{"content":"集合框架中一个重要的类，其实是Collection接口的伴随类，其中定义了许多实用方法，用来获取集合视图，或提供一些方便的操作集合元素的算法。\n由于视图是直接封装的Collection接口，因此其方法有些局限，并且由于特殊的设计，部分操作是不允许的（会抛出 UnsupportedOperationExceptin ）。\n1 不可修改视图 顾名思义，一旦获取，其内容不再可以修改，Java集合框架中可以用于获取的不可修改视图有：\nCollections通过静态方法获取的8个不可修改视图\nJava中提供的获取不可修改视图的方法，只能用来遍历原集合中的信息，无法通过任何手段（集合，迭代器，entry等）修改集合，例如，当调用add方法时，Java的处理方式就是抛出 UnsupportedOperationException 异常：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82  public class UnmodifiableViewTest { static List\u0026lt;String\u0026gt; l = new ArrayList\u0026lt;String\u0026gt;() {{ add(\u0026#34;fan\u0026#34;); add(\u0026#34;bar\u0026#34;); add(\u0026#34;foo\u0026#34;); add(\u0026#34;anchor\u0026#34;); add(\u0026#34;ripe\u0026#34;); add(\u0026#34;rope\u0026#34;); add(\u0026#34;hope\u0026#34;); }}; static Set\u0026lt;String\u0026gt; s = new HashSet\u0026lt;\u0026gt;(l); static Map\u0026lt;String, String\u0026gt; m = new HashMap\u0026lt;String, String\u0026gt;() {{ put(\u0026#34;c\u0026#34;, \u0026#34;cable\u0026#34;); put(\u0026#34;b\u0026#34;, \u0026#34;bar\u0026#34;); put(\u0026#34;f\u0026#34;, \u0026#34;floyd\u0026#34;); put(\u0026#34;e\u0026#34;, \u0026#34;echo\u0026#34;); put(\u0026#34;a\u0026#34;, \u0026#34;anchor\u0026#34;); put(\u0026#34;d\u0026#34;, \u0026#34;dribble\u0026#34;); }}; public static void main(String[] args) { // unmodifiableList(); // unmodifiableSet();  unmodifiableMap(); } static void unmodifiableList() { List\u0026lt;String\u0026gt; ul = Collections.unmodifiableList(l); // 对视图集的元素增删会抛出UnsupportedOperationException  // strings.add(\u0026#34;add\u0026#34;);  // strings.remove(\u0026#34;bar\u0026#34;);  // strings.removeAll(l);  ul.forEach(System.out::print); //可以操作迭代器  ListIterator\u0026lt;String\u0026gt; iterator = ul.listIterator(); System.out.println(iterator.nextIndex()); // List\u0026lt;String\u0026gt; ul_sub = l.subList(1, 3);  List\u0026lt;String\u0026gt; ul_sub = ul.subList(1, 3); // 子集对元素的操作也是不支持的 // ul_sub.removeIf(s -\u0026gt; s.equals(\u0026#34;foo\u0026#34;));  ul_sub.forEach(System.out::println); } static void unmodifiableSet() { Set\u0026lt;String\u0026gt; set = Collections.unmodifiableSet(s); System.out.println(set.contains(\u0026#34;anchor\u0026#34;)); Iterator\u0026lt;String\u0026gt; i = set.iterator(); i.next(); // 迭代器无法移除元素是必然的  // i.remove();  // set.clear();  TreeSet\u0026lt;String\u0026gt; ts = new TreeSet\u0026lt;\u0026gt;(s); // 使用sorted set构建  NavigableSet\u0026lt;String\u0026gt; ns = Collections.unmodifiableNavigableSet(ts); // 无法从集中移除元素 UnsupportedOperationException // String s = ns.pollFirst();  System.out.println(ns.first()); NavigableSet\u0026lt;String\u0026gt; anchor = ns.headSet(\u0026#34;anchor\u0026#34;, true); // 子集也不能被修改 // anchor.remove(\u0026#34;anchor\u0026#34;);  anchor.forEach(System.out::println); } static void unmodifiableMap() { Map\u0026lt;String, String\u0026gt; map = Collections.unmodifiableMap(m); // 不支持的操作  // map.replace(\u0026#34;a\u0026#34;,\u0026#34;apple\u0026#34;);  Set\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; e = map.entrySet(); System.out.println(map.get(\u0026#34;f\u0026#34;)); TreeMap\u0026lt;String, String\u0026gt; tm = new TreeMap\u0026lt;\u0026gt;(m); // 使用sorted map  NavigableMap\u0026lt;String, String\u0026gt; nm = Collections.unmodifiableNavigableMap(tm); System.out.println(nm.ceilingEntry(\u0026#34;car\u0026#34;).getValue()); NavigableMap\u0026lt;String, String\u0026gt; sm = nm.subMap(\u0026#34;b\u0026#34;, true, \u0026#34;d\u0026#34;, true); // 不支持的操作  // sm.remove(\u0026#34;c\u0026#34;);  sm.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;, \u0026#34; + v)); NavigableMap\u0026lt;String, String\u0026gt; descendingMap = sm.descendingMap(); descendingMap.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;, \u0026#34; + v)); } }   稍微查看源码就知道，不可修改视图的工作方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  static class UnmodifiableList\u0026lt;E\u0026gt; extends UnmodifiableCollection\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt; { //...  public E get(int index) {return list.get(index);} public E set(int index, E element) { throw new UnsupportedOperationException(); } public void add(int index, E element) { throw new UnsupportedOperationException(); } public E remove(int index) { throw new UnsupportedOperationException(); } //...  }   不可修改视图的封装思路就是，当试图改变集合时，不予处理并抛出异常。\n2 同步视图 由于Java集合框架中的组成都不是同步的（Vector和Hashtable除外）， Java SE 8 API Specification 里面重复出现的一段话就是：\n Note that this implementation is not synchronized. If multiple threads access an ArrayList instance concurrently, and at least one of the threads modifies the list structurally, it must be synchronized externally. (A structural modification is any operation that adds or deletes one or more elements, or explicitly resizes the backing array; merely setting the value of an element is not a structural modification.) This is typically accomplished by synchronizing on some object that naturally encapsulates the list. If no such object exists, the list should be \u0026ldquo;wrapped\u0026rdquo; using the Collections.synchronizedListmethod. This is best done at creation time, to prevent accidental unsynchronized access to the list:\nList list = Collections.synchronizedList(new ArrayList(...));\n 因此同步视图就是用来处理并发访问的，除了同步视图之外，java.util.concurrent包里提供了线程安全的集合，用于并发环境。\nCollections通过静态方法获取的8个同步视图（不包含SynchronizedRandomAccessList）\n3 受查视图 受查视图用来对泛型类发生问题时提供调试支持。\nCollections通过静态方法获取的9个受查视图（不包含checkededRandomAccessList）\n4 实用方法 4.1 空集合 Collections提供了一些返回空集合、映射、迭代器的方法，实际上返回的是Collections所封装的对应的对象。\n向返回的空集合中插入元素会抛出 UnsupportedOperationException。\n1 2 3 4 5  static void emptyList(){ List\u0026lt;Object\u0026gt; emptyList = Collections.emptyList(); //emptyList.add(1); // USOE  System.out.println(emptyList.size()); // actual 0 }   4.2 单一元素集合 Collections还提供了返回指定1个元素的集合或映射：\n1 2 3 4 5 6  static void singletonList(){ Set\u0026lt;String\u0026gt; singlton = Collections.singleton(\u0026#34;singlton\u0026#34;); System.out.println(singlton.size()); // actual 1  // singlton.add(\u0026#34;sin\u0026#34;); // USOE  // singlton.clear(); // USOE }   同样地，单一元素集合也是不可修改的。\n4.3 其他有利算法 Collections类还包含了很多有利的算法，如：\n Collections.sort(List\u0026lt;T\u0026gt;)\n 根据对集合元素按照自然顺序升序排序，而\n Collections.binarySearch(List\u0026lt;? extends Comparable\u0026lt;? super T\u0026raquo; list, T key)\n 会二分查找集合中的元素，其前提是元素是自然升序排序的1\n除此之外，Collections还定义了一些实用方法，简单列出部分：\n public static void reverse(List\u0026lt;?\u0026gt; list)\npublic static void shuffle(List\u0026lt;?\u0026gt; list)\npublic static void shuffle(List\u0026lt;?\u0026gt; list, Random rnd)\npublic static \u0026lt;T extends Object \u0026amp; Comparable\u0026lt;? super T\u0026raquo; T min(Collection\u0026lt;? extends T\u0026gt; coll)\npublic static \u0026lt;T\u0026gt; T min(Collection\u0026lt;? extends T\u0026gt; coll, Comparator\u0026lt;? super T\u0026gt; comp)\npublic static \u0026lt;T extends Object \u0026amp; Comparable\u0026lt;? super T\u0026raquo; T max(Collection\u0026lt;? extends T\u0026gt; coll)\npublic static \u0026lt;T\u0026gt; T max(Collection\u0026lt;? extends T\u0026gt; coll, Comparator\u0026lt;? super T\u0026gt; comp)\n  排序和查找有重载方法，具体请查看API文档 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文介绍了java集合框架中的伴随类——Collections工具类中提供的有利方法。","id":29,"section":"posts","tags":["集合框架","Collections工具类"],"title":"Collections工具类","uri":"http://wangy325.top/zh/posts/java/collections/collections/"},{"content":"Map即映射，即键-值对，键不允许重复，并且一个键最多映射一个值。\n映射提供3种集合视图\n 键集 （Set实现） 值集 （Collection实现） Map.Entry集（Set实现）  由于Map的键是Set，因此使用可变对象作为Map的key时，需要覆盖 equals 和 hashCode 方法，Map不能使用自身作为key\nJava 8对Map接口进行了优化，新增了主要是针对函数式接口的 默认 方法（方法体被省略）：\n  default V merge(K key, V value,\nBiFunction\u0026lt;? super V, ? super V, ? extends V\u0026gt; remappingFunction) {\u0026hellip;} default V compute(K key,\nBiFunction\u0026lt;? super K, ? super V, ? extends V\u0026gt; remappingFunction) {\u0026hellip;} default V computeIfPresent(K key,\nBiFunction\u0026lt;? super K, ? super V, ? extends V\u0026gt; remappingFunction) {\u0026hellip;} default V computeIfAbsent(K key,\nFunction\u0026lt;? super K, ? extends V\u0026gt; mappingFunction) {\u0026hellip;} default V replace(K key, V value) {\u0026hellip;} default boolean replace(K key, V oldValue, V newValue) {\u0026hellip;} default boolean remove(Object key, Object value) {\u0026hellip;} default V putIfAbsent(K key, V value) {\u0026hellip;} default void replaceAll(BiFunction\u0026lt;? super K, ? super V, ? extends V\u0026gt; function) {\u0026hellip;} default V getOrDefault(Object key, V defaultValue) {\u0026hellip;}   上述方法使用的不多，主要用来对Map键值进行更新，按需查阅API文档\n1 HashMap HashMap是由散列表对键进行散列的，允许null键和null值。HashMap是无序的，这点和HashSet是一样的\n HashMap和Hashtable大致相同，区别在与Hashtable是同步的，且Hashtable不允许null\n HashMap的初始化和扩容机制叙述参见散列表，如果初始化时不指定容量（桶数？容量不是键值对数目），默认为16。容量总是2n，最大容量是230，每次扩容加倍，当桶数大于最大桶数后，不再rehash。容量总是为2的幂次的原理和ArrayDeque一致，通过5次位运算将低位全部转为1，然后执行+1操作进位，变成下一个2n。因此HashMap带参构造器指定的capacity最后会初始化为大于其的最近的2n。（1变2，3变4，5变8，9变16\u0026hellip;）\nHashMap使用table和entrySet分别表示桶数和当前映射中的键值对数：\n transient Node\u0026lt;K,V\u0026gt;[] table;\t桶数组，桶由链表构成\ntransient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026raquo; entrySet; 映射中的键值对数，size\nint threshold; 临界键值对数，等于 table.length * loadFactor，当size \u0026gt; threshold时，发生扩容\nfinal float loadFactor; 装载因子，默认0.75\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  static void bucketsTest() throws Exception { //load factor 0.75  HashMap\u0026lt;String, String\u0026gt; hm = new HashMap\u0026lt;\u0026gt;(7); hm.put(\u0026#34;1\u0026#34;, \u0026#34;ok\u0026#34;); hm.put(\u0026#34;2\u0026#34;, \u0026#34;fine\u0026#34;); hm.put(\u0026#34;3\u0026#34;, \u0026#34;nice\u0026#34;); hm.put(\u0026#34;4\u0026#34;, \u0026#34;no\u0026#34;); hm.put(\u0026#34;5\u0026#34;, \u0026#34;ops\u0026#34;); hm.put(\u0026#34;6\u0026#34;, \u0026#34;fuck\u0026#34;); Class\u0026lt;?\u0026gt; cls = HashMap.class; Field table = cls.getDeclaredField(\u0026#34;table\u0026#34;); Field threshold = cls.getDeclaredField(\u0026#34;threshold\u0026#34;); // can not access  // Class\u0026lt;?\u0026gt; node = Class.forName(\u0026#34;java.util.HashMap$Node\u0026#34;);  table.setAccessible(true); threshold.setAccessible(true); // Node\u0026lt;K,V\u0026gt;[]  Object[] o = (Object[]) table.get(hm); System.out.println(\u0026#34;initial buckets size: \u0026#34; + o.length); System.out.println(\u0026#34;initial threshold: \u0026#34; + threshold.get(hm)); Set\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entries = hm.entrySet(); System.out.println(\u0026#34;number of entries: \u0026#34; + entries.size()); // 遍历  /*entries.forEach((e) -\u0026gt; { System.out.println(e.getKey() + e.getValue()); });*/ hm.put(\u0026#34;apple\u0026#34;, \u0026#34;music\u0026#34;); // reshash needed  System.out.println((\u0026#34;buckets after rehash: \u0026#34; + ((Object[]) table.get(hm)).length)); } /* output: initial buckets size: 8 initial threshold: 6 number of entries: 6 buckets after rehash: 16 *///:~   上例解释了HashMap的扩容过程，当映射中的元素数大于桶数与装载因子之积时，便会扩容\nMap中提供3种集合视图，键的，值的和entry的，视图并不能对映射进行完全结构性控制，比如向Map中添加条目，则只能使用Map.put方法，使用视图时，除了删除这一改变Map结构的操作，其他操作会抛出UnsurportedOperationException\nHashMap的集合视图都支持迭代器，并可以通过任意视图的迭代器删除键值对，但是不支持新增和替换键值对\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  private static void viewTest() { Map\u0026lt;Integer, String\u0026gt; hm = new HashMap\u0026lt;\u0026gt;(8); hm.put(1,\u0026#34;难忘的一天\u0026#34;); Set\u0026lt;Integer\u0026gt; keySet = hm.keySet(); //keySet.add(2); // unsupported operation exception  Iterator\u0026lt;Integer\u0026gt; ikey = keySet.iterator(); ikey.next(); // can remove key-value pair by keySet  ikey.remove(); ikey.forEachRemaining(System.out::println); Collection\u0026lt;String\u0026gt; values = hm.values(); // already deleted  System.out.println(\u0026#34;values contains: \u0026#34; + values.contains(\u0026#34;难忘的一天\u0026#34;)); // values.add(\u0026#34;你瞒我瞒\u0026#34;); // unsupported either  hm.put(1,\u0026#34;你瞒我瞒\u0026#34;); hm.put(2,\u0026#34;樱花树下\u0026#34;); // ikey.next(); // fast-fail iterator, ikey is out of date  boolean remove = values.remove(\u0026#34;你瞒我瞒\u0026#34;); Iterator\u0026lt;String\u0026gt; ivalue = values.iterator(); ivalue.next(); ivalue.remove(); hm.put(1,\u0026#34;红豆\u0026#34;); hm.put(2,\u0026#34;风衣\u0026#34;); Set\u0026lt;Map.Entry\u0026lt;Integer, String\u0026gt;\u0026gt; entries = hm.entrySet(); // entries.add() // unsupported either  System.out.println(\u0026#34;entry size: \u0026#34; + entries.size()); // remove entry with particular key-value  entries.remove(new Map.Entry\u0026lt;Integer, String\u0026gt;() { @Override public Integer getKey() { return 1; } @Override public String getValue() { return \u0026#34;红豆\u0026#34;; } @Override public String setValue(String value) { return null; } }); hm.forEach((k,v) -\u0026gt; System.out.println(\u0026#34;key:\u0026#34; + k + \u0026#34;, value:\u0026#34; + v)); Iterator\u0026lt;Map.Entry\u0026lt;Integer, String\u0026gt;\u0026gt; ientry = entries.iterator(); ientry.next(); ientry.remove(); ientry.forEachRemaining(System.out::println); } /* output values contains: false entry size: 2 key: 2, value:风衣 *///:~   值得一提的事，和SortedSet的子集视图一样，对原集合和视图的修改是相互的，不会引发 ConcurrentModificationException ，但是其对映射的操作是有限的，比如keySet.add(2)就抛出 UnsupportedOperationException ，迭代器不支持操作。查看源码即可知：\nHashMap内部视图和迭代器方法表\n可以看到，视图实现的方法有限，并没有实现集合的所有方法。因此当使用视图调用add方法时，直接在AbstractCollection里抛出异常：\n1 2 3  public boolean add(E e) { throw new UnsupportedOperationException(); }   2 LinkedHashMap LinkedHashMap(链表散列映射)是HashMap的导出类，像LinkedHashSet与HashSet的关系一样\n其与HashMap的差别在于其使用LinkedList来维护键值对插入的顺序，其插入机制和HashMap是一致的\nLinkedHashMap和HashMap的性能相差不大与HashSet和LinkedHashSet一致：\n         HashMap HashMap基于散列表，插入和查询键值对的开销是固定的   LinkedHashMap 和HashMap类似，不过其使用LinkedList维护内部次序，因此其迭代顺序是插入顺序或者LRU（最近最少使用）次序，性能稍差于HashMap    一般地，LinkedHashMap使用插入顺序（ insertion order ）。但有特殊情况，LinkedHashMap提供构造参数accessOrder，来根据访问顺序（ access order ）对映射条目进行迭代\n主要构造器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  /** * Constructs an empty LinkedHashMap instance with the * specified initial capacity, load factor and ordering mode. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @param accessOrder the ordering mode - true for * access-order, false for insertion-order * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor); this.accessOrder = accessOrder; }   当使用访问顺序时，映射条目的会按照最少访问——最多访问的顺序迭代，也就是说每次有效访问，受到影响的条目都会“移动”到链表的尾部，这个性质非常适合 “最近最少使用”（LRU）高速缓存\n那么哪些方法是有效访问呢？\n put get putIfAbsent getOrdefault compute computeIfAbsent computeIfPresent merge replace  其中，replace方法只有成功替换值之后才是有效访问\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  static { map.put(\u0026#34;hebe\u0026#34;, \u0026#34;不醉不会\u0026#34;); map.put(\u0026#34;andy\u0026#34;, \u0026#34;谢谢你的爱\u0026#34;); map.put(\u0026#34;lala\u0026#34;, \u0026#34;寻人启事\u0026#34;); map.put(\u0026#34;yoga\u0026#34;, \u0026#34;成全\u0026#34;); } static void accessOrderTest() { Map\u0026lt;String, String\u0026gt; lhm = new LinkedHashMap\u0026lt;\u0026gt;(8, 0.75f, true); lhm.putAll(map); System.out.println(\u0026#34;entry in access order:\u0026#34;); // 有效访问会将entry移动至队尾  lhm.replace(\u0026#34;yoga\u0026#34;, \u0026#34;说谎\u0026#34;); // Java 8新增方法  lhm.computeIfPresent(\u0026#34;hebe\u0026#34;, (k, v) -\u0026gt; \u0026#34;魔鬼中的天使\u0026#34;); lhm.put(\u0026#34;chua\u0026#34;, \u0026#34;坠落\u0026#34;); lhm.get(\u0026#34;lala\u0026#34;); lhm.forEach((k, v) -\u0026gt; System.out.println(\u0026#34;\\t\u0026#34; + k + \u0026#34;: \u0026#34; + v)); } /* output: entry in access order: andy: 谢谢你的爱 yoga: 说谎 hebe: 魔鬼中的天使 chua: 坠落 lala: 寻人启事 *///:~   映射视图的操作不影响迭代顺序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  static void viewTest() { Map\u0026lt;String, String\u0026gt; lhm = new LinkedHashMap\u0026lt;\u0026gt;(8, 0.75f, true); lhm.putAll(map); lhm.forEach((k, v) -\u0026gt; System.out.println(\u0026#34;\\t\u0026#34; + k + \u0026#34;: \u0026#34; + v)); Set\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entries = lhm.entrySet(); // 视图操作不会影响映射的排序  Iterator\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; i = entries.iterator(); for (Map.Entry\u0026lt;String, String\u0026gt; entry : entries) { entry.setValue(\u0026#34;魔鬼中的天使\u0026#34;); break; } System.out.println(\u0026#34;------\u0026#34;); lhm.forEach((k, v) -\u0026gt; System.out.println(\u0026#34;\\t\u0026#34; + k + \u0026#34;: \u0026#34; + v)); i.next(); } /* output: hebe: 不醉不会 lala: 寻人启事 yoga: 成全 andy: 谢谢你的爱 ------ hebe: 魔鬼中的天使 lala: 寻人启事 yoga: 成全 andy: 谢谢你的爱 *///：～   关于LinkedHashMap的一个重要的用途，还涉及到一个方法，利用好此方法可以将LinkedHashMap作为缓存使用\n1 2 3  protected boolean removeEldestEntry(Map.Entry\u0026lt;K,V\u0026gt; eldest) { return false; }   这个方法在put或者putAll方法插入新条目到映射之后调用，也就是说，使用put更新已有key的value不会触发此操作1\n如果方法返回false，不执行操作；返回true，则移除参数eldest条目\n参数 eldest是映射的“最旧的”元素——当前最先插入/最少访问的元素，即队头元素：\n1 2 3 4 5 6 7 8  void afterNodeInsertion(boolean evict) { // possibly remove eldest  LinkedHashMap.Entry\u0026lt;K,V\u0026gt; first; // if true，移除队头元素  if (evict \u0026amp;\u0026amp; (first = head) != null \u0026amp;\u0026amp; removeEldestEntry(first)) { K key = first.key; removeNode(hash(key), key, null, false, true); } }   这个方法始终返回false——也就是说永远不会作任何操作，可以继承此方法（从访问权限修饰符也知道），用于改变行为\n此法可以用来在put和putAll之后操作映射，如此做之后，此法一定要返回false，不再允许映射有后续的操作，原因很简单——若在操作时就remove了eldest，返回true之后该如何？\nremoveEldestEntry可以作用于插入顺序和访问顺序的LinkedeHashSet中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  private static void eldestRemoveTest() { class Access\u0026lt;K, V\u0026gt; extends LinkedHashMap\u0026lt;K, V\u0026gt; { @Override protected boolean removeEldestEntry(Map.Entry\u0026lt;K, V\u0026gt; eldest) { return size() \u0026gt; 1; } } Access\u0026lt;Integer, String\u0026gt; access = new Access\u0026lt;\u0026gt;(); access.put(1, \u0026#34;apple\u0026#34;); // Access中始终只有最后插入的一个条目  access.put(2, \u0026#34;google\u0026#34;); access.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;: \u0026#34; + v)); } /* output 2: google *///:~   上例中，每次put后调用removeEldestEntry方法，最终映射中只有最后插入的条目\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72  static void lruCacheTest() { class Cache\u0026lt;K, V\u0026gt; extends LinkedHashMap\u0026lt;K, V\u0026gt; { private final int count = 50; private Cache(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor, accessOrder); } /** * 此方法总是返回false * * @param eldest * @return false */ @Override protected boolean removeEldestEntry(Map.Entry\u0026lt;K, V\u0026gt; eldest) { Set\u0026lt;Map.Entry\u0026lt;K, V\u0026gt;\u0026gt; entries = entrySet(); // lambda表达式中使用外部变量需要保证线程安全  AtomicInteger vs = new AtomicInteger(); entries.removeIf(next -\u0026gt; { V value = next.getValue(); if (value instanceof Integer) { if ((Integer) value \u0026gt; 0) { vs.addAndGet((Integer) value); return (Integer) value \u0026lt; 10; } } return false; }); // 打印次数反映此法的调用次数  System.out.println(vs.intValue() == count); //若在此方法中对集合进行修改，那么必须返回false  return false; } } Cache\u0026lt;Integer, Integer\u0026gt; cache = new Cache\u0026lt;\u0026gt;(8, 0.75f, true); // 初始化映射集， afterNodeInsertion  cache.put(1, 0); cache.put(2, 0); cache.put(3, 0); cache.put(4, 0); cache.put(5, 0); for (int i = 0; i \u0026lt; cache.count; i++) { int key = new Random().nextInt(50) % 5 + 1; int value = cache.get(key); if (i == cache.count - 1) { //保证最后一次访问removeEldestEntry方法  cache.remove(key); } // 将值增1，实现计数器效果  // 此处不能使用compute方法，因此法会调用afterNodeInsertion  // 设计的目的在最后一次put之后调用afterNodeInsertion方法，而使用compute会调用2次 // cache.put(key, cache.compute(key, (k, v) -\u0026gt; Integer.sum(value, 1)));  cache.put(key, ++value); } System.out.println(\u0026#34;-------\u0026#34;); cache.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;: \u0026#34; + v)); } /* output: false false false false false true ------- 1: 11 2: 12 4: 14 *///:~   上例对一个容量为5的LinkedList进行50次随机访问，每次访问后记录访问次数（用value自增），最后删除访问次数不到10次的条目。可以看到，removeEldestEntry方法调用了6次，最后映射集中只有访问次数大于10次的键值对了\n2.1 LinkedHashMap如何链接节点 我们知道，LinkedHashMap在HashMap的基础上使用linkedList（并不是集合框架中的LinkedList）将键值对链接起来，因此键值对才能够被有序迭代，那么这一动作是在什么时候发生的呢？\n这一过程涉及到2个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // 覆盖了HashMap的newNode方法 Node\u0026lt;K,V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = new LinkedHashMap.Entry\u0026lt;K,V\u0026gt;(hash, key, value, e); // 链接节点  linkNodeLast(p); return p; } // link at the end of list private void linkNodeLast(LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last = tail; tail = p; if (last == null) head = p; else { p.before = last; last.after = p; } }   上面的两个方法可以看到，每次插入键值对到映射中时，总会和前一个节点建立连接\n2.2 LinkedHashMap的回调方法 LinkedHashMap中有3个重要的回调方法，是LinkedHashMap维护链表以及实现顺序迭代的重要依赖\nafterNodeRemoval 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  // 删除键值对之后调用 void afterNodeRemoval(Node\u0026lt;K,V\u0026gt; e) { // unlink  LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null){ // e = head  head = a; }else{ // 将b.after指向a  b.after = a; } if (a == null){ // e = tail  tail = b; }else{ // 将a.before指向b  a.before = b; } // 连接完成 }   afterNodeInsertion 1 2 3 4 5 6 7 8 9 10 11 12 13  // 插入新节点之后调用 void afterNodeInsertion(boolean evict) { // possibly remove eldest  LinkedHashMap.Entry\u0026lt;K,V\u0026gt; first; // 注意判断条件，需要removeEldestEntry方法返回true  // removeEldestEntry方法默认返回false  //因此默认行为是不删除节点  if (evict \u0026amp;\u0026amp; (first = head) != null \u0026amp;\u0026amp; removeEldestEntry(first)) { K key = first.key; // 移除队头节点  removeNode(hash(key), key, null, false, true); //will call afterNodeRemoval  } }   afterNodeAccess 如果构造LinkedHashMap时指定构造参数accessOrder=true，那么此法将访问的节点移动至队尾\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  void afterNodeAccess(Node\u0026lt;K,V\u0026gt; e) { // move node to last  LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last; // 访问顺序，且访问节点不为tail  if (accessOrder \u0026amp;\u0026amp; (last = tail) != e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; // 置空p.after，因要将p放到队尾  p.after = null; if (b == null){ // b == null说明e==head  head = a; }else{ // 将e的前一节点与e的后一节点连接  b.after = a; } if (a != null){ // 将e的后一节点与e的前一节点连接  a.before = b; }else{ // 这个条件会被满足吗？  last = b; } if (last == null){ // 这个条件会被满足吗  head = p; }else { // 将p作为最后节点  p.before = last; last.after = p; } tail = p; ++modCount; } }   上述方法的流程图为：\n![afterNodeAccess](/img/afterNodeAccess_flow.svg) 3 TreeMap TreeSet是TreeMap的KeySet的封装，TreeMap是使用红—黑树对键进行排序的有序映射\nTreeMap的继承结构和TreeSet极为相似，对应地，TreeMap是SortedMap和NavigableMap的实现，SortedMap/NavigableMap的接口声明和SortedSet/NavgableSet相似，所声明的方法名都是自解释型的，具体可查看JDK文档\n要将条目插入TreeMap中，key必须是可排序的，排序方式可以是自然排序或者定义比较器，和TreeSet一样，比较器规则必须和equals方法的结果保持一致，以避免映射中出现重复key-value\nTreeMap的集合视图和对应的迭代器表现和HashMap一致\n 视图和映射的作用是相互的，即修改映射，视图随之修改，反之亦然，但是视图支持的操作是有限的，注意 UnsupportedOperationException 迭代器是 fail-fast 的， 只支持remove一个改变映射结构的方法  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  static { map.put(\u0026#34;hebe\u0026#34;, \u0026#34;不醉不会\u0026#34;); map.put(\u0026#34;AMIT\u0026#34;,\u0026#34;母系社会\u0026#34;); map.put(\u0026#34;Lin\u0026#34;,\u0026#34;可惜没如果\u0026#34;); map.put(\u0026#34;andy\u0026#34;, \u0026#34;一起走过的日子\u0026#34;); map.put(\u0026#34;lala\u0026#34;, \u0026#34;寻人启事\u0026#34;); map.put(\u0026#34;yoga\u0026#34;, \u0026#34;说谎\u0026#34;); } static void treeMapTest() { Map\u0026lt;String, String\u0026gt; tm = new TreeMap\u0026lt;\u0026gt;(map); Set\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; entries = tm.entrySet(); tm.put(\u0026#34;andy\u0026#34;, \u0026#34;来生缘\u0026#34;); // 映射和entrySet是互相作用的  for (Map.Entry\u0026lt;String, String\u0026gt; entry : entries) { entry.setValue(\u0026#34;难搞\u0026#34;); break; } tm.computeIfPresent(\u0026#34;lala\u0026#34;, (k, v) -\u0026gt; \u0026#34;失落沙洲\u0026#34;); // Unsupported Operation Exception  // entries.add(new Map.Entry\u0026lt;String, String\u0026gt;() {...});  tm.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;: \u0026#34; + v)); // test iterator  Iterator\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; ie = entries.iterator(); ie.next(); ie.remove(); // tm.putAll(map); //ConcurrentModificationException  ie.next(); ie.forEachRemaining(x -\u0026gt; System.out.print(x + \u0026#34;\\t\u0026#34;)); // 指定比较器  Map\u0026lt;String, String\u0026gt; tm2 = new TreeMap\u0026lt;\u0026gt;(String::compareToIgnoreCase); tm2.putAll(map); System.out.println(); tm2.forEach((k,v)-\u0026gt; System.out.println(k +\u0026#34;: \u0026#34; + v)); } /* output: AMIT: 难搞 Lin: 可惜没如果 andy: 来生缘 hebe: 不醉不会 lala: 失落沙洲 yoga: 说谎 andy=来生缘\thebe=不醉不会\tlala=失落沙洲\tyoga=说谎 AMIT: 母系社会 andy: 一起走过的日子 hebe: 不醉不会 lala: 寻人启事 Lin: 可惜没如果 yoga: 说谎 *///:~   上例中分别对HashMap使用自然排序和指定比较器的方法，可以看到映射中key的排序差异\n当指定TreeMap实现类的名字SortedMap或NavigableMap的实现时，方可使用SortedMap和NavigableMap的实用方法，由于方法名都是解释型的，此处不多作表述：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  static void navigableTest() { TreeMap\u0026lt;String, String\u0026gt; tm = new TreeMap\u0026lt;\u0026gt;(map); System.out.println(tm.firstEntry().getKey()); // 使用一个比key \u0026#39;andy\u0026#39;大的值，即可包含这个key，\u0026#34;+ 0\u0026#34;是一个实用手段  SortedMap\u0026lt;String, String\u0026gt; subMap = tm.subMap(\u0026#34;AMIT\u0026#34;, \u0026#34;andy\u0026#34; + \u0026#34;0\u0026#34;); subMap.compute(\u0026#34;AMIT\u0026#34;, (k, v) -\u0026gt; \u0026#34;彩虹\u0026#34;); subMap.forEach((k, v) -\u0026gt; System.out.println(k + \u0026#34;, \u0026#34; + v)); //NavigableMap接口方法，返回大于或等于给定key的一个entry  System.out.println(tm.ceilingEntry(\u0026#34;AMIT\u0026#34;).getValue()); } /* output: AMIT AMIT, 彩虹 Lin, 可惜没如果 andy, 一起走过的日子 彩虹 *///:~    由于subMap方法是“包前不包尾”的（其他获取子映射视图的方法也一样），为了包尾，可以使用上例的方法\n NavigableMap对获取子映射视图的方法进行了扩展，不作过多表述\n 实际上使用put更新已有key的value时，触发的是另一个方法：afterNodeAccess，此方法将条目移动至队尾（如果使用访问顺序） \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文介绍了Java集合框架中的映射（Map），主要以HashMap和LinkedHashMap和TreeMap为主。","id":30,"section":"posts","tags":["集合框架","Map"],"title":"Map","uri":"http://wangy325.top/zh/posts/java/collections/map/"},{"content":"Set是不含重复元素的集，严格来讲，Set不允许当e1.equals(e2)为真时， e1 和 e2 同时出现在集合中。Set最多允许一个null元素。\n将可变对象置入Set时需要特别小心，当对象的改动影响到了元素之间的equals()比较的结果，那么Set的行为就变得不确定了。因此，不能将Set本身作为Set的元素。\n1 散列集 关于散列的桶与桶中的元素，还有部分描述可能存在问题  数组和链表能够记录元素的插入顺序，这对于通过索引快速对元素执行操作很有利，但是如果忘记了索引，那么需要从头遍历，这在数据量很大的情况下效率低下。在不考虑元素的顺序情况下，能提供快速查询所需要的数据，这就是散列表(hash table)\n散列表为每个对象计算一个整数，称为散列码( hash code )，这意味着如果将自定义对象作为Set的对象，那么必须要负责实现这个类的 hashCode 方法，还有一点要注意的是，hashCode和equals方法之间存在约束关系，因此最好也重写equals方法以保证一致性\nJava中的散列表是用链表数组实现的，每个链表称为桶\n散列表(hash table)  form Core Java\n设有散列表桶数为 x ，有对象 y ，那么散列表如何存入对象呢？\n$$\nz = hash(y) % x\n$$\n那么对象 y 应该放在 z 号桶中\n若桶被占满1了，就会发生散列冲突(hash collection)，散列表会尽量避免散列冲突\n 在Java 8 中，桶满时链表会转换成为平衡二叉树\n 保证散列中桶数富余能够有效提升散列表的性能，反之若要插入的元素过多，散列表的性能就会降低\n散列表一般可初始化桶数，通常将桶数设置为容量的75%～150%。若不知道元素的个数，散列表太满就会导致再散列（ rehashed ），在散列就是创建一个桶数更多的表（加倍），将所有的元素copy到新表，丢弃原来的表。在散列由桶数和装填因子（ load factor ）两方面决定，如果不加指定，装填因子默认为0.75，若\n$$\n散列元素数 \u0026gt; 桶数 * 装填因子\n$$\n就会发生再散列\nJava标准类库中，散列表的桶数总是2n，默认值是16\n1.1 HashSet HashSet是由HashMap实现的基于散列表的集合，允许至多一个null元素\n不论桶数，当元素被合理地分配在散列表的桶中时，HashSet的基本操作（add，remove，contains和size）的效率是一致的；但是迭代HashSet所需要的时间则与元素数量以及组成集的HashMap桶数正相关。因此合理的设置桶数非常有必要\n与List不同的是，HashSet的迭代器不能保证元素的迭代顺序，并且迭代器也是 fail-fast 的，在使用迭代器时同样需要留意 ConcurrentModificationException\nHashSet主要字段：\n1 2 3 4  private transient HashMap\u0026lt;E,Object\u0026gt; map; // Dummy value to associate with an Object in the backing Map  private static final Object PRESENT = new Object();   HashSet构造器：\n1 2 3 4  public HashSet() {map = new HashMap\u0026lt;\u0026gt;();} public HashSet(Collection\u0026lt;? extends E\u0026gt; c) {...} public HashSet(int initialCapacity, float loadFactor) {...} public HashSet(int initialCapacity) {...}   所以HashSet就是一个所有值为PRESENT常量的 HashMap的KeySet，参考如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  static void initializationTest() throws Exception { Set\u0026lt;Integer\u0026gt; hs = new HashSet\u0026lt;\u0026gt;(); hs.add(1); hs.add(2); Class\u0026lt;?\u0026gt; cls = HashSet.class; Field fm = cls.getDeclaredField(\u0026#34;map\u0026#34;); fm.setAccessible(true); System.out.println(fm.get(hs).getClass()); @SuppressWarnings(\u0026#34;unchecked\u0026#34;) HashMap\u0026lt;Integer, Object\u0026gt; o = (HashMap\u0026lt;Integer, Object\u0026gt;) fm.get(hs); for (Map.Entry\u0026lt;Integer, Object\u0026gt; entry : o.entrySet()) { System.out.println(entry.getKey() + \u0026#34;:\u0026#34; + entry.getValue()); } } /* output class java.util.HashMap 1:java.lang.Object@1540e19d 2:java.lang.Object@1540e19d *///:~   如果将自定义对象存入HashSet，必须覆盖 equals 和 hashCode 方法\n1.2 LinkedHashSet HashSet的子类，与HashSet的 区别在于LinkedHashSet使用双端链表维护集中的元素，因此元素能够被有序迭代（迭代顺序是元素的插入顺序），当元素添加到集中时，便会并入LinkedList中\n链表散列表  from Core Java\nHashSet中有一个包访问权限的构造器，专门用来构造LinkedHashSet：\n1 2 3  HashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); }   可以看到，LinkedHashSet实质上是LinkedHashMap的是个KeySet\n和HashSet的区别（性能上）:\n 性能稍微比HashSet低一点 由于加入了链表，迭代LinkedHashSet时只与集合的容量(size)有关，而与桶数无关；而HashSet的迭代效率与二者都有关 LinkedHashSet设置过大的桶数所带来的性能（负）影响小于HashSet  2 TreeSet 树集是由红—黑树实现的有序集合(sorted collection)。在Java集合框架中，TreeSet由TreeMap实现，和HashSet一样，TreeSet是TreeMap的所有值为new Object()的keySet\nTreeSet是NavigableSet和SortedSet的实现，其中NavigableSet接口继承了SortedSet接口\nSortedSet接口定义了如下方法：\n   Comparator\u0026lt;? super E\u0026gt; comparator();\n获取用于排序的比较器，若使用comparable则返回null\n  SortedSet\u0026lt;E\u0026gt; subSet(E fromElement, E toElement);\n返回一个子集，元素范围从 fromElement （含）到 toElement （不含），当 fromElement 和 toElement 相等时，返回空集，返回的集合是一个视图，对此视图的修改会作用到原集合上，反之亦然\n  SortedSet\u0026lt;E\u0026gt; headSet(E toElement);\n  SortedSet\u0026lt;E\u0026gt; tailSet(E fromElement);\n返回一个子集，元素小于/大于 toElement/fromElement ，返回的集合是一个视图，对此视图的修改会作用到原集合上，反之亦然\n  E first();\n  E last();\n获取集合中最小/最大的元素\n   NavigableSet继承了SortedSet，并新增了方法：\n   E lower(E e);\n  E higher(E e);\n返回小于 e 的最大/大于 e 的 最小元素，若不存在则返回null\n  E floor(E e);\n  E ceiling(E e);\n返回小于等于 e 的最大/大于等于 e 的 最小元素，若不存在则返回null\n  E pollFirst();\n  E pollLast();\n获取并删除集合中的最小/最大元素，若集合为空则返回null\n  Iterator descendingIterator();\n获取倒序迭代器\n   TreeSet中的元素总是有序的，排序规则可以是默认的自然排序（ comparable ）或在构造器中指定比较器（ comparator ），和PriorityQueue一样，若向TreeSet插入未排序的元素，会抛出 ClassCastException\n需要注意的是，在使用自定义比较规则时，置入TreeSet中的元素需要考虑到comparable/comparator 方法和 equals 方法的一致性\n参考如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  //... 省略头部 static void consistenceTest() { class Item implements Serializable { private int code; private String name; public Item(int code, String name) { this.code = code; this.name = name; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Item item = (Item) o; if (code != item.code) return false; return Objects.equals(name, item.name); } @Override public int hashCode() { int result = code; result = 31 * result + (name != null ? name.hashCode() : 0); return result; } } // 故意修改比较器的相等逻辑  SortedSet\u0026lt;Item\u0026gt; ss = new TreeSet\u0026lt;\u0026gt;((o1, o2) -\u0026gt; o1.code - o2.code + 1); Item item = new Item(1, \u0026#34;apple\u0026#34;); ss.add(item); ss.add(item); // Set中出现重复元素  ss.forEach(System.out::println); } /* output: TreeSetTest$1Item@58b8379 TreeSetTest$1Item@58b8379 *///:~   上例中，对于Item对象 a 和 b ，以及Item的比较器 c ，有\n$$\na.equals(b) \u0026amp;\u0026amp; c.compare(a,b)!=0\n$$\n成立，那么第二次add()就会返回true，此时TreeSet中出现了重复的元素！这与Set.add方法的约束相悖，为什么？原因在于尽管Set是以equals来判断元素相等的，但是TreeSet使用的是比较器规定的方法，上例在TreeSet的角度看， a 和 b 并不等，这样会使集合出现难以理解的行为\n因此，保持比较器和equals方法的一致性是很重要的\n值得一提的是，NavigableSet的获取子集的方法，可以用来对原集合进行修改；同样地，若原集合发生改变，子集也会随之改变\n 这与ArrayList的SubList不同，SubList获取子集后对原集合的修改会引发ConcurrentModificationException\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  //...省略头部 static void eleTest() { TreeSet\u0026lt;String\u0026gt; ss = new TreeSet\u0026lt;String\u0026gt;() {{ add(\u0026#34;nokia\u0026#34;); add(\u0026#34;motorola\u0026#34;); add(\u0026#34;apple\u0026#34;); add(\u0026#34;samsung\u0026#34;); add(\u0026#34;mi\u0026#34;); add(\u0026#34;oppo\u0026#34;); add(\u0026#34;vivo\u0026#34;); add(\u0026#34;sony\u0026#34;); add(\u0026#34;google\u0026#34;); }}; SortedSet\u0026lt;String\u0026gt; headSet = ss.headSet(\u0026#34;oppo\u0026#34;, false); // equals  // SortedSet\u0026lt;String\u0026gt; headSet = ss.headSet(\u0026#34;oppo\u0026#34;);  ss.add(\u0026#34;huawei\u0026#34;); // 之前的子集中也会添加  Iterator\u0026lt;String\u0026gt; i = headSet.iterator(); int j = 0; while (i.hasNext()) { j++; i.next(); if (j % 2 == 0) { i.remove(); } } headSet.forEach(System.out::println); System.out.println(\u0026#34;contains google? \u0026#34; + ss.contains(\u0026#34;google\u0026#34;)); // 获取当前集合的逆序迭代器  Iterator\u0026lt;String\u0026gt; i2 = ss.descendingIterator(); System.out.println(\u0026#34;vivo\u0026#34;.equals(i2.next())); } /* output: apple huawei motorola contains google? false true *///:~   上例中，获取headSet之后对原集合添加元素，且添加的元素正好在子集的范围中 ，那么子集中也会添加这个元素；\n 每个桶里都有元素么？每个桶至多有多少元素？ \u0026#x21a9;\u0026#xfe0e;\n  ","description":"“本文介绍Java集合框架中的集合（Set），以HashSet和TreeSet为例。”","id":31,"section":"posts","tags":["集合框架","Set"],"title":"Set","uri":"http://wangy325.top/zh/posts/java/collections/set/"},{"content":"Queue（队列），实际开发过程中，在单线程环境下使用的情况下不多，Queue作为集合框架中重要组成似乎习惯性被忽略，队列总是先持有元素，再处理元素1。\nQueue继承关系简图\n除了Collection定义的操作之外，Queue定义了额外的插入/删除/检查元素的操作，这些操作有2种形式：\n    Throws Exception Returns special value     Insert add(e) offer(e)   Remove remove() poll()   Examine element() peek()    如表所示，add/remove/element方法失败后抛出异常。offer/poll/peek方法失败后返回一个特殊值（null或false，视具体操作不同），需要说明的是，offer()方法主要是为有容量限制的队列设计的 对于有限队列而言，offer()方法比add()方法更可取。\n典型的队列遵从FIFO( first-in-first-out )原则，FIFO队列的新元素总是插入到队尾。\n当然有例外，PriorityQueue 就是之一，它根据给定（或默认）的比较器决定元素顺序；此外还有LIFO( last-in-first-out )队列（如栈）。\n不管是何种队列，都可以使用remove()或poll()移除并返回 队列头元素，至于头元素是“谁”就由队列的排序规则决定。此二者的区别体现在当队列为空时，remove()抛出异常，而poll()返回null。\nelement()和peek()获取但不移除 队列头元素，区别在于当队列为空时，element()抛出异常，而peek()返回null。\noffer()方法尝试向队列中插入一个元素，否则返回false，而Collection.add方法失败之后会抛出（运行时）异常。因此offer()方法适用于定容或有界队列中插入元素。\n队列中不允许插入null，或者说不应将null插入队列中（LinkedList允许空值），因为null会作为队列方法的特殊返回值（空队列指示器）出现，若将null插入队列，会引发歧义。\nQueue有两个子接口：\n  BlockingQueue\nQueue中并没有定义 阻塞队列 的相关方法，阻塞队列通常在 并发编程 中使用。阻塞队列的方法会等待元素出现或（有限）集合空间可用这2个条件之一满足才执行。\n  Deque\n双端队列 是支持从 队首和队尾添加/删除元素 的线性集合，一般来说，Deque 没有容量限制，但是其也支持有限长度的实现。\n从Deque的定义可知，其比Queue的定义多了队头的入队、队尾的出队以及相应的查看操作：\n  First Element (Head) Last Element (Tail)    Throws exception Special value Throws exception Special value   Insert addFirst(e) offerFirst(e) addLast(e) offerLast(e)   Remove removeFirst() pollFirst() removeLast() pollLast()   Examine getFirst() peekFirst() getLast() peekLast()   与Queue不同的是，获取而不删除的方法由element()变成了getXXX()，这些方法用来在队列头/尾中插入/删除/检查元素，当操作失败时有不同的处理：一组直接抛出异常，一组返回一个特殊值（null或false）。，同样地，返回特殊值的方法适用于有限容量的队列。\n由于Deque继承自Queue，当其作为Queue使用时，是一个FIFO队列，新元素会添加至队尾，删除操作删除队首元素，因此下表的方法在Deque作为Queue使用时是等价的：\n     Queue Methods Equivalent Deque Methods     add(e) addLast(e)   offer(e) offerLast(e)   remove() removeFirst()   poll() pollFirst()   element() getFirst()   peek() peekFirst()    此外，Deque还可以作为LIFO队列（栈）使用，当作为栈使用时，新元素会从队首添加或删除，这种情况下，java.util.Stack的方法和Deque的方法是等价的：\n   Stack Methods Equivalent Deque Methods     push(e) addFirst(e)   pop() removeFirst()   peek() peekFirst()     ArrayDeque 就是一个LIFO队列实现\n Deque不提供使用索引操作集合的方法。\n和Queue一样，虽然没有严格约束不能插入null到队列中，也强烈不推荐将null值插入。\n除此之外，Deque还提供2个删除元素的方法：\n boolean removeFirstOccurrence(Object o);\nboolean removeLastOccurrence(Object o);\n 1 优先级队列(NON-FIFO)实现——PriorityQueue 优先级队列不允许null值。\n优先级队列是一个有序队列，其底层是由堆( heap )实现的，堆是一个可以自我调整的二叉树。优先级队列的排序依据可以来自元素的自然排序（实现Comparable接口）或自定义比较器，当使用自然排序规则时，优先级队列不允许插入non-comparable对象。\n优先级队列的第一个元素(head)总是按照排序规则计算出最小元素，如果有几个相等的最小元素，那么head为其中任意一个，当使用poll()或remove()后，其他最小元素自动移动至head。\n 从输出来看，优先级队列并没有对所有元素进行完全排序，而是队列发生结构性变化时，保证队头元素一定是满足排序规则的最小元素。\n 优先级队列是自动扩容的，其扩容机制为：\n 当队列较小时（\u0026lt;64），容量翻倍； 当队列长度\u0026gt;64时，容量增加一半（和ArrayList 一样）  优先级队列也有迭代器，此迭代器不能按照指定排序规则顺序迭代元素——优先级队列并没有对所有元素进行排序，若想获得所有元素的排序，可以使用Arrays.sort(pq.toArray())。\n参考下例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  static void unsorted(){ Queue\u0026lt;Integer\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;(); pq.add(7); pq.add(1); pq.add(12); pq.add(6); pq.add(9); pq.add(1); System.out.println(\u0026#34;pq: \u0026#34; + Arrays.toString(pq.toArray())); Object[] array = pq.toArray(); Arrays.sort(array); System.out.println(\u0026#34;sorted array:\u0026#34; + Arrays.toString(array)); // the least element always in the head of queue  pq.poll(); pq.forEach((e) -\u0026gt;{ System.out.print(e + \u0026#34;\\t\u0026#34;); }); } /* output: pq: [1, 6, 1, 7, 9, 12] sorted array:[1, 1, 6, 7, 9, 12] 1\t6\t12\t7\t9 *///:~   和上面的叙述一样，PriorityQueue并没有对所有元素进行排序，不过其保证了最小元素始终在队首，并且队列发生结构性变化时，队列中的元素“位置”也会发生变化。\n下例展示了如何在PriorityQueue中使用自定义比较器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  static void userComparator() { class PC { private String model; private Double price; private PC(String model, Double price) { this.model = model; this.price = price; } } // compare by price descend  Queue\u0026lt;PC\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;((o1, o2) -\u0026gt; (int) (o2.price - o1.price)); pq.add(new PC(\u0026#34;dell\u0026#34;, 15499d)); pq.add(new PC(\u0026#34;apple\u0026#34;, 18899d)); pq.add(new PC(\u0026#34;samsung\u0026#34;, 8999d)); pq.add(new PC(\u0026#34;asus\u0026#34;, 12999d)); pq.add(new PC(\u0026#34;hp\u0026#34;, 6399d)); pq.add(new PC(\u0026#34;lenovo\u0026#34;, 16999d)); pq.forEach(e -\u0026gt; System.out.print(e.price + \u0026#34;\\t\u0026#34;)); System.out.println(); pq.remove(); pq.forEach(e -\u0026gt; System.out.print(e.price + \u0026#34;\\t\u0026#34;)); System.out.println(); pq.remove(); pq.forEach(e -\u0026gt; System.out.print(e.price + \u0026#34;\\t\u0026#34;)); System.out.println(); // compare by model ascend  Queue\u0026lt;PC\u0026gt; pq1 = new PriorityQueue\u0026lt;\u0026gt;((o1,o2) -\u0026gt; (o1.model.compareTo(o2.model))); pq1.add(new PC(\u0026#34;samsung\u0026#34;, 8999d)); pq1.add(new PC(\u0026#34;apple\u0026#34;, 18899d)); pq1.add(new PC(\u0026#34;lenovo\u0026#34;, 16999d)); pq1.add(new PC(\u0026#34;asus\u0026#34;, 12999d)); pq1.add(new PC(\u0026#34;dell\u0026#34;, 15499d)); pq1.add(new PC(\u0026#34;hp\u0026#34;, 6399d)); pq1.forEach(e -\u0026gt; System.out.print(e.model + \u0026#34;\\t\u0026#34;)); System.out.println(); pq1.remove(); pq1.forEach(e -\u0026gt; System.out.print(e.model + \u0026#34;\\t\u0026#34;)); System.out.println(); pq1.remove(); pq1.forEach(e -\u0026gt; System.out.print(e.model + \u0026#34;\\t\u0026#34;)); } /* output: 18899.0\t15499.0\t16999.0\t12999.0\t6399.0\t8999.0 16999.0\t15499.0\t8999.0\t12999.0\t6399.0 15499.0\t12999.0\t8999.0\t6399.0 apple\tasus\thp\tsamsung\tdell\tlenovo asus\tdell\thp\tsamsung\tlenovo dell\tlenovo\thp\tsamsung *///:~   从结果来看，元素在PriorityQueue里并不是全排序的，不过其会自动将“最小”的元素移动至队首。\n此例中，如果不在构造器中指定比较器，PriorityQueue会在运行时抛出 ClassCastException——试图将PC向上转型为Comparable时异常。\n2 双端队列的双向链表实现——LinkedList LinkedList是Deque的实现，可以作为双端队列使用，其实现了Deque声明的所有方法。\n想将LinkedList作为Deque使用，须将其声明为 Deque：\n1  Deque\u0026lt;String\u0026gt; deque = new LinkedList\u0026lt;\u0026gt;();   LinkedList得益于双向链表节点的灵活性，很容易就能够实现在首尾两端对元素进行操作。\n3 双端队列的循环数组实现——ArrayDeque ArrayDeque是由循环数组实现的双端队列，没有容量限制，并且能够自动扩容，不允许 插入null值。\n ArrayDeque作为栈（ LIFO 队列）使用时，效率比java.util.Stack高。\nArrayDeque作为Queue使用时，效率比LinkedList高。\n ArrayDeque的迭代器也是 fail-fast 的，意味着和ArrayList一样，在获取迭代器之后使用集合方法对队列进行结构性修改会引发 ConcurrentModificationException。\nArrayDeque主要的字段域有：\n1 2 3 4  transient Object[] elements; transient int head; transient int tail; private static final int MIN_INITIAL_CAPACITY = 8;   elements用于存储数据，head和tail分别用来标记队列的头尾。 MIN_INITIAL_CAPACITY 是创列的最小容量（23）。当构造器没有指定容量时，初始化容量为16；只有当指定容量且数值小于8时才会使用8作为初始容量。\n参考如下源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // ArrayDeque初始化时容量的计算 private static int calculateSize(int numElements) { int initialCapacity = MIN_INITIAL_CAPACITY; // Find the best power of two to hold elements.  // Tests \u0026#34;\u0026lt;=\u0026#34; because arrays aren\u0026#39;t kept full.  if (numElements \u0026gt;= initialCapacity) { initialCapacity = numElements; initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 1); initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 2); initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 4); initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 8); initialCapacity |= (initialCapacity \u0026gt;\u0026gt;\u0026gt; 16); initialCapacity++; if (initialCapacity \u0026lt; 0) // Too many elements, must back off  initialCapacity \u0026gt;\u0026gt;\u0026gt;= 1;// Good luck allocating 2 ^ 30 elements  } return initialCapacity; }   若指定容量\u0026gt;8时，那么需要对其进行 5次右移及位或运算保证最终的容量大小是2n，比如传进来的参数是13，那么最后得到的容量就是24。\nArrayDeque中，当head==tail2时触发扩容，容量增加一倍。\n TODO\n 参考如下源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  public void addFirst(E e) { //...  if (head = (head - 1) \u0026amp; (elements.length - 1) == tail) doubleCapacity(); //... } public void addLast(E e) { //...  if (tail = (tail + 1) \u0026amp; (elements.length - 1) == head) doubleCapacity(); //... } public E pollFirst() { //...  if (head = (h + 1) \u0026amp; (elements.length - 1) == tail) doubleCapacity(); //... } public E pollLast() { //...  if (tail = (tail - 1) \u0026amp; (elements.length - 1) == head) doubleCapacity(); //... } // 扩容 private void doubleCapacity() { assert head == tail; int p = head; int n = elements.length; int r = n - p; // number of elements to the right of p  int newCapacity = n \u0026lt;\u0026lt; 1; if (newCapacity \u0026lt; 0) throw new IllegalStateException(\u0026#34;Sorry, deque too big\u0026#34;); Object[] a = new Object[newCapacity]; System.arraycopy(elements, p, a, 0, r); System.arraycopy(elements, 0, a, r, p); elements = a; head = 0; tail = n; }   一般地，循环队列都是使用模运算实现的，而ArrayDeque通过位运算来实现循环队列，Java集合框架中很多地方都使用了位运算（如HashMap的扩容），位运算和模运算有如下关系：\n x % 2n = x \u0026amp; (2n - 1)\n 并且位运算的效率远远高出模运算，这就是Java设计的高明之处。\n当触发扩容时，将容量增加一倍，同时使用两次System.arraycopy将原数组拷贝到新数组中，现引用ArrayDeque扩容将其机制作简要阐述：\n 假如默认容量16，此时数组情况如图\n当再次调用addFirst(\u0026quot;G\u0026quot;)时，\n此时head==tail，触发扩容，将会创建一个大小为 16*2 的新数组，然后通过两次拷贝将原数组的数据复制到新数组\n 第一次将G-H拷贝到新数组 第二次将A-F拷贝到新数组  ArrayDeque扩容图解 来源见水印\n 参考如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  void initializationTest() throws Exception { Deque\u0026lt;Integer\u0026gt; aq = new ArrayDeque\u0026lt;\u0026gt;(5); // actual circle array size: 8  System.out.println(\u0026#34;array size : \u0026#34; + getElements(aq).length); // double capacity while i = 7  for (int i = 0; i \u0026lt; 8; i++) { aq.offerLast(i); } Object[] elements = getElements(aq); System.out.println(Arrays.toString(elements)); aq.addLast(19); aq.forEach(e-\u0026gt; System.out.print(e + \u0026#34;\\t\u0026#34;)); } private \u0026lt;T\u0026gt; T[] getElements(Deque\u0026lt;?\u0026gt; aq) throws Exception { Class\u0026lt;?\u0026gt; cls = ArrayDeque.class; Field ef = cls.getDeclaredField(\u0026#34;elements\u0026#34;); ef.setAccessible(true); return (T[]) ef.get(aq); } /* output: array size : 8 [0, 1, 2, 3, 4, 5, 6, 7, null, null, null, null, null, null, null, null] 0\t1\t2\t3\t4\t5\t6\t7\t19 *///~   ArrayDeque的具体方法就不再赘述了，其囊括了作为Queue以及Stack的的实现。\n A collection designed for holding elements prior to processing \u0026#x21a9;\u0026#xfe0e;\n head和tail在循环数组中的行为是如何？ \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文介绍了Java集合框架中的队列，以PriorityQueue，LinkedList，ArrayDeque为例。","id":32,"section":"posts","tags":["集合框架","Queue"],"title":"Queue","uri":"http://wangy325.top/zh/posts/java/collections/queue/"},{"content":"Java集合框架简图\n1. 未列出枚举集（EnumSet/EnumMap）  2. 未列出IdentityHashMap  3. 未列出java.util.concurrent包下的实现 -- 上图列出了集合框架的常见实现，Java集合框架系列文章介绍了图中列出的大部分内容\nList List是有序集合，或称之为序列。List的实现可以准确地控制插入元素的位置，也可以通过元素的索引(index)访问之，还可以在集合中搜索元素\n和Set不同，List允许元素重复出现，甚至允许多个null元素出现\nList定义了4个由索引执行的操作\n E get(int index);\nE set(int index, E element);\nvoid add(int index, E element);\nE remove(int index);\n ArrayList由于实现了RandomAccess接口，其在使用索引随机访问时性能不会受影响，但是LinkedList执行索引操作的耗时是与集合大小正相关的。因此，在不清楚List的实现类型的时候1，通过迭代器遍历集合中的元素进行操作比直接使用索引更可取\nList提供了一个独有的迭代器ListIterator，其提供了插入/替换元素的操作，并且支持双向迭代\n1 ArrayList ArrayList是Java集合框架中使用最为频繁的实现，其本质是一个有序的可自由扩容的对象数组。它实现了RandomAccess这个标记接口，意味着其在随机访问性能上有一定优势\n下图显示了ArrayList的继承关系\nArrayList继承关系\n1.1 初始化及扩容机制 ArrayList初始化为一个空的对象数组，如果不在构造对象时指定初始容量大小，那么ArrayList的默认初始化一个容量为10的对象数组，其扩容规则是每当新增加对象超出对象数组的容量时，将对象数组的容量增加当前容量的1/2\n参考如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  static void initializeTest() throws NoSuchFieldException, IllegalAccessException { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // initial size = 10  for (int i = 0; i \u0026lt;16; i++){ list.add(new Random().nextInt(100)); // 本体是elementData  Field field = list.getClass().getDeclaredField(\u0026#34;elementData\u0026#34;); field.setAccessible(true); // 获取list的“elementData”  Object[] o = (Object[]) field.get(list); // size是ArrayList的长度，length是elementData的长度  System.out.println(\u0026#34;size = \u0026#34; + (i+1) + \u0026#34;, length = \u0026#34; + o.length + \u0026#34; , element = \u0026#34; + Arrays.toString(o)); } } /* output: size = 1, length = 10 ,element = [15, null, null, null, null, null, null, null, null, null] size = 2, length = 10 ,element = [15, 15, null, null, null, null, null, null, null, null] size = 3, length = 10 ,element = [15, 15, 31, null, null, null, null, null, null, null] size = 4, length = 10 ,element = [15, 15, 31, 40, null, null, null, null, null, null] size = 5, length = 10 ,element = [15, 15, 31, 40, 47, null, null, null, null, null] size = 6, length = 10 ,element = [15, 15, 31, 40, 47, 26, null, null, null, null] size = 7, length = 10 ,element = [15, 15, 31, 40, 47, 26, 47, null, null, null] size = 8, length = 10 ,element = [15, 15, 31, 40, 47, 26, 47, 41, null, null] size = 9, length = 10 ,element = [15, 15, 31, 40, 47, 26, 47, 41, 91, null] size = 10, length = 10 ,element = [15, 15, 31, 40, 47, 26, 47, 41, 91, 69] size = 11, length = 15 ,element = [15, 15, 31, 40, 47, 26, 47, 41, 91, 69, 32, null, null, null, null] size = 12, length = 15 ,element = [15, 15, 31, 40, 47, 26, 47, 41, 91, 69, 32, 94, null, null, null] size = 13, length = 15 ,element = [15, 15, 31, 40, 47, 26, 47, 41, 91, 69, 32, 94, 25, null, null] size = 14, length = 15 ,element = [15, 15, 31, 40, 47, 26, 47, 41, 91, 69, 32, 94, 25, 11, null] size = 15, length = 15 ,element = [15, 15, 31, 40, 47, 26, 47, 41, 91, 69, 32, 94, 25, 11, 80] size = 16, length = 22 ,element = [15, 15, 31, 40, 47, 26, 47, 41, 91, 69, 32, 94, 25, 11, 80, 86, null, null, null, null, null, null] *///:~   ArrayList的内容存储在elementData对象数组中，通过在运行时获取对象信息，能够窥视ArrayList的初始化过程：\n  elementData初始化为容量默认为10，内容为空的对象数组new Object[10] = {}\n  添加第10个元素时，此时elementData的容量也是10，无法容纳更多元素，需扩容，源码所见：\n1 2 3 4 5 6 7 8 9 10 11  if (minCapacity - elementData.length \u0026gt; 0){ int oldCapacity = elementData.length; // 扩容 扩容方式为将容量增加一半  int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); if (newCapacity - minCapacity \u0026lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win:  elementData = Arrays.copyOf(elementData, newCapacity); }     使用Arrays.copyOf()方法将elementData重新引用至新的拷贝数组——这一过程去尾\n  1.2 迭代器 集合框架的继承关系图显示，Collection接口继承了 Iterable 接口，这意味着所有的集合实现都可以使用迭代器操作集合\n作为使用最广的集合实现，ArrayList可以获取 Iterator 和 ListIterator 的实现，后者继承了前者，在前者的基础上新增了一些用于可逆迭代（ cursor在集合中来回穿梭 ）的特性，如previous()，previousIndex()等方法\n迭代器方法表\n下面代码简单展示了迭代器的使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  static void iteratorTest() { List\u0026lt;String\u0026gt; a = new ArrayList\u0026lt;String\u0026gt;() {{ add(\u0026#34;apple\u0026#34;); add(\u0026#34;google\u0026#34;); add(\u0026#34;amazon\u0026#34;); add(\u0026#34;cisco\u0026#34;); add(\u0026#34;facebook\u0026#34;); add(\u0026#34;twitter\u0026#34;); }}; Iterator\u0026lt;String\u0026gt; iterator = a.iterator(); a.remove(2); // throw ConcurrentModificationException  // System.out.println(iterator.next());  // 重新获取迭代器，避免上述异常  Iterator\u0026lt;String\u0026gt; newIterator = a.iterator(); newIterator.next(); // Java 8新增方法，迭代剩余元素  newIterator.forEachRemaining(s -\u0026gt; { s= s.replaceFirst(\u0026#34;g\u0026#34;,\u0026#34;G\u0026#34;); System.out.println(s); }); } /* output: Google cisco facebook twitter *///:~   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  static void listIteratorTest() { ListIterator\u0026lt;String\u0026gt; listIterator = a.listIterator(); listIterator.next(); // do not change cursor  listIterator.set(\u0026#34;Apple\u0026#34;); listIterator.previous(); while (listIterator.hasNext()) { System.out.println(listIterator.next()); } System.out.println(\u0026#34;-------\u0026#34;); // cursor changed  listIterator.remove(); listIterator.add(\u0026#34;TWITTER\u0026#34;); // cursor in the end  // reverse output  while (listIterator.hasPrevious()) { System.out.println(listIterator.previous()); } } /* output: Apple google twitter ------- TWITTER google Apple *///:~   关于集合的迭代器2，作如下说明：\n1 当集合和迭代器持有的“计数器”不一致时，迭代器的 ConcurrentModificationException 出现：\n计数器：记录发生集合结构性变化的次数，一般指集合元素增删，更新集合元素值一般不会被视作结构性\t变化3；迭代器也维护一个计数器，此数字初始化为原集合计数器的值\n需要记住的是，迭代器的计数器只能通过迭代器维护（ 调用迭代器的add()，remove()等方法会更新计数器 ），而集合的计数器却可以通过迭代器和集合维护，亦即通过迭代器更新的计数器会同步更新集合的计数器（ 因为迭代器方法也是通过集合方法实现的 ）；反之不亦然，记住，在获取迭代器之后，在使用集合而非迭代器的方法修改集合结构，那么迭代器会发生异常（ 2个计数器值不一致 ）\n参考ArrayList.Itr.remove()4源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public void remove() { if (lastRet \u0026lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; // 更新计数器  expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } final void checkForComodification() { // 一致性检查  if (modCount != expectedModCount) throw new ConcurrentModificationException(); }   2 不论是 Iterator 或 ListIterator 接口在Java集合框架中都没有独立的实现类，都是作为集合具体实现的内部类存在的，这种机制使得不同的集合类型，拥有“定制”的迭代器类型，这意味着方法表并不是一成不变的，如ArrayList.ListIterator就缺失hasNext()方法\nLinkedList(左)和ArrayList(右)内部ListIterator的实现差异\n这种只定义接口而使用内部类实现的现象在Java集合框架中非常常见，理解这一点有利于理解集合视图( Collection view )，接下来这个概念将多次出现\n按照理论，ListItr实现了ListIterator接口应该覆盖所有方法，Intellij IDEA编译器对于ArrayList的内部类ListItr给出了 method should be defined since the class is not abstract的批注，这或许是Java源码的豁免权\n实际上，ArrayList.ListItr继承了ArrayList.Itr，因此，ListItr缺失的方法由Itr实现了\n3 Java 8的改进\nJava 8 新增的函数式接口，在集合框架中得到广泛使用，关于Java 8对集合框架的优化，后文将单独说明\n在迭代器 Iterator 接口中，新增了一个方法\n1 2 3 4 5  default void forEachRemaining(Consumer\u0026lt;? super E\u0026gt; action) { Objects.requireNonNull(action); while (hasNext()) action.accept(next()); }   这是一默认方法，其接受一个 Consumer 参数，用来对元素执行操作，需要注意的是此迭代器的指针( cursor )并不是0，而是当前实际的指针，亦即此法用于迭代还未被此迭代器迭代的元素\n1.3 SubList SubList是ArrayList的内部类，是方法subList(int fromIndex, int toIndex)的返回对象，也就是说，ArrayList.subList()的返回不是一个ArrayList实例，而是一个视图\n所谓集合视图，可以通俗的理解为集合的内部类5，如此Sublist，其一个主要的特点是可以更改原集合（作用可以理解为原集合的一个代理）\n1 2 3  private class SubList extends AbstractList\u0026lt;E\u0026gt; implements RandomAccess { //... }   SubList可以看作一个\u0026quot;类ArrayList\u0026quot;，方法也有很多共性，而往往只需要注意差异即可\n参考下例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  static void subListTest(){ List\u0026lt;String\u0026gt; a = new ArrayList\u0026lt;String\u0026gt;() {{ add(\u0026#34;apple\u0026#34;); add(\u0026#34;google\u0026#34;); add(\u0026#34;amazon\u0026#34;); add(\u0026#34;cisco\u0026#34;); }}; List\u0026lt;String\u0026gt; strings = a.subList(1, 2); // [google]  System.out.println(\u0026#34;Is subList instance of ArrayList? \u0026#34; + (strings instanceof ArrayList) + \u0026#34;\\n-------\u0026#34;); // a.add(\u0026#34;Java\u0026#34;) // ERROR! cause ConcurrentModificationException for subList  ListIterator\u0026lt;String\u0026gt; subIterator = strings.listIterator(); while (subIterator.hasNext()){ subIterator.set(subIterator.next().toUpperCase() + \u0026#34; revised by subList\u0026#34;); } // 增加元素  subIterator.add(\u0026#34;foobar added by subList\u0026#34;); a.forEach(System.out::println); // 删除子集，父集也删除元素  strings.clear(); System.out.println(\u0026#34;-------\u0026#34;); a.forEach(System.out::println); } /* output: Is subList instance of ArrayList? false ------- apple GOOGLE revised by subList foobar added by subList amazon cisco ------- apple amazon cisco *///:~   之所以将其称为视图，一个很重要的原因就是，这个类所有有利数据全部来自外围类(ArrayList)，其能够修改外围类的能力来自于直接对外围类方法的调用6：\n1 2 3 4 5 6 7 8  public void add(int index, E e) { rangeCheckForAdd(index); checkForComodification(); // 实际上调用的就是外围类的方法  parent.add(parentOffset + index, e); this.modCount = parent.modCount; this.size++; }   实际上，可以将SubList理解为ArrayList实用工具的巧妙封装\n 和迭代器一样，获取SubList之后，对原集合进行结构性改变，也会引起ConcurrentModificationException\n 1.4 插入与删除 前文提到，尽管ArrayList因实现了Random接口而具有很好的随机读取性，ArrayList也有一些缺点，比如差强人意的插入和删除\nArrayList方法：\n1 2 3 4  public void add(int index, E e) {...} public E remove(int index) {...} public boolean remove(Object o) {...} ...   实现了从插入集合到指定索引为止或从集合中删除（指定索引）元素，但这些操作并不是ArrayList的强项，拿add(int index, E e)为例：\n1 2 3 4 5 6 7 8 9 10  public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!!  // 拷贝数组--实际上是将数组index位置以后的所有元素”后移一位“  System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; }   同理，从ArrayList的删除相关方法中也可以看到类似的操作，这意味着在操作大量数据的时候，ArrayList可能会遇到性能问题。在对象数组长度很小时，这种影响一般可以忽略\n2 LinkedList LinkedList是基于双向链表实现的有序集合，其不能像ArrayList一样通过索引(index)访问元素，同时LinkedList还实现了Deque接口，意味着LinkedList可以实现双端队列的操作\nLinkedList继承关系图\n链表将每个对象存放在独立的节点(Node)中，节点中还保存对序列中前、后节点的引用。理论上，LinkedList没有容量限制\nLinkedList的基本数据结构 from Core Java\n2.1 Node Node（节点）是LinkedList的存储载体，每向LinkedList中增加/删除一个元素，就会增加/减少一个Node，Node定义了3个字段，其含义分别是：\n E item：存入LinkedList的内容\nNode\u0026lt;E\u0026gt; prev：前一个节点的引用\nNode\u0026lt;E\u0026gt; next：后一个节点的引用\n 结合LinkedList的字段来看，LinkedList定义了两个个Node相关的引用：\n transient Node\u0026lt;E\u0026gt; first：总是指向LinkedList的第一个节点\ntransient Node\u0026lt;E\u0026gt; last：总是指向LinkedList的最后一个节点\n LinkedList有如下规律：\n first.prev总是为null last.next总是为null 当LinkedList只有一个元素时，first == last  下面的代码验证了上述推论：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  static void initializeTest() throws Exception { List\u0026lt;String\u0026gt; a = new LinkedList\u0026lt;\u0026gt;(); a.add(\u0026#34;google\u0026#34;); // a.add(\u0026#34;chrome\u0026#34;);  // a.add(\u0026#34;photos\u0026#34;);  Class\u0026lt;?\u0026gt; cls = LinkedList.class; // LinkedList field  Field ff = cls.getDeclaredField(\u0026#34;first\u0026#34;); Field lf = cls.getDeclaredField(\u0026#34;last\u0026#34;); ff.setAccessible(true); lf.setAccessible(true); Object first = ff.get(a); Object last = lf.get(a); Class\u0026lt;?\u0026gt; node = Class.forName(\u0026#34;java.util.LinkedList$Node\u0026#34;); // LinkedList$Node field  Field item = node.getDeclaredField(\u0026#34;item\u0026#34;); Field next = node.getDeclaredField(\u0026#34;next\u0026#34;); Field prev = node.getDeclaredField(\u0026#34;prev\u0026#34;); item.setAccessible(true); next.setAccessible(true); prev.setAccessible(true); // first  System.out.println(\u0026#34;first: \u0026#34; + first); Object firstItem = item.get(first); Object firstPrev = prev.get(first); // Node  Object firstNext = next.get(first); // Node  System.out.println(\u0026#34;\\t\u0026#34; + \u0026#34;item: \u0026#34; + firstItem +\u0026#34;\\n\\t\u0026#34; + \u0026#34;prev: \u0026#34; + firstPrev + \u0026#34;\\n\\t\u0026#34; + \u0026#34;next: \u0026#34; + firstNext + \u0026#34;\\n\u0026#34;); // last  System.out.println(\u0026#34;last: \u0026#34; + last); Object lastItem = item.get(last); Object lastPrev = prev.get(last); Object lastNext = next.get(last); System.out.println(\u0026#34;\\t\u0026#34; + \u0026#34;item: \u0026#34; + lastItem +\u0026#34;\\n\\t\u0026#34; + \u0026#34;prev: \u0026#34; + lastPrev + \u0026#34;\\n\\t\u0026#34; + \u0026#34;next: \u0026#34; + lastNext); } /* output: first: java.util.LinkedList$Node@512ddf17 item: google prev: null next: null last: java.util.LinkedList$Node@512ddf17 item: google prev: null next: null // 当有3个元素时，first的next == last的prev first: java.util.LinkedList$Node@512ddf17 item: google prev: null next: java.util.LinkedList$Node@2c13da15 last: java.util.LinkedList$Node@77556fd item: photos prev: java.util.LinkedList$Node@2c13da15 next: null *///:~   利用Node，对链表中的元素的删除和插入操作将变得便利，只需要同时修改自身及前后节点的引用即可将元素置入链中\n参考如下源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * Inserts element e before non-null Node succ. */ void linkBefore(E e, Node\u0026lt;E\u0026gt; succ) { // assert succ != null;  final Node\u0026lt;E\u0026gt; pred = succ.prev; final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; }   上述源码解释了如何将一个新的元素插入到链表中\n2.2 迭代器 LinkedList没有 Iterator 的实现，只有 ListIterator 的实现，里面定义了相当充分的操作元素的方法，由于LinkedList也是List的实现类，故也可调用接口定义的iterator()方法7，不过其实际上返回的是 LinkedList.ListIterator 实例\nLinkedList调用iterator()的时序图\n尽管如此，由于使用LinkedList.iterator()方法返回的是Iterator，其对集合的操作性降低到只有4个方法。由于我们知道其实际返回的是Listiterator，我们可以将该返回值向下转型：\n1 2 3 4 5  ListIterator\u0026lt;String\u0026gt; i = (ListIterator\u0026lt;String\u0026gt;) list.iterator(); // 等价于 ListIterator\u0026lt;String\u0026gt; listIterator = list.listIterator(); // 等价于 ListIterator\u0026lt;String\u0026gt; listIterator1 = list.listIterator(0);   参考如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  static void iteratorTest(){ List\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;String\u0026gt;(){{ add(\u0026#34;Java\u0026#34;); add(\u0026#34;Python\u0026#34;); add(\u0026#34;JavaScript\u0026#34;); add(\u0026#34;C\u0026#34;); }}; ListIterator\u0026lt;String\u0026gt; i = (ListIterator\u0026lt;String\u0026gt;) list.iterator(); while (i.hasNext()){ if (i.next().equals(\u0026#34;JavaScript\u0026#34;)){ i.set(\u0026#34;JS\u0026#34;); } } i.remove(); i.add(\u0026#34;C++\u0026#34;); // 反向迭代  while (i.hasPrevious()){ System.out.println(i.previous()); } System.out.println(\u0026#34;-------\u0026#34;); ListIterator\u0026lt;String\u0026gt; iterator = list.listIterator(2); iterator.forEachRemaining(System.out::println); } /* output: C++ JS Python Java ------- JS C++ *///:~    ListIterator\u0026lt;E\u0026gt; listIterator(int index);\n此方法用于获取 index （含）之后的元素的迭代器\n 2.3 对比ArrayList ArrayList的优势在于可以利用 index 快速访问集合中的元素，劣势在于对于容量大的集合，插入和删除的效率稍低\nLinkedList基于链表，插入和删除操作效率高并不总这样；但由于没有元素索引( index )，使用get(int index)和set(int index , E e)的效率稍低8\n在LinkedList中，和索引相关的操作有：\n public E get(int index)\npublic E set(int index, E element)\npublic void add(int index, E element)\npublic E remove(int index)\npublic int indexOf(Object o) 获取对象首次出现的位置\npublic int lastIndexOf(Object o)\t获取对象最后出现的位置\n 除了indexOf和lastIndexOf方法之外，其他的四个方法的实现都和这个方法有关：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  public void add(int index, E element) { checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index)); } /** * Returns the (non-null) Node at the specified element index. */ Node\u0026lt;E\u0026gt; node(int index) { // assert isElementIndex(index);  if (index \u0026lt; (size \u0026gt;\u0026gt; 1)) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) x = x.next; return x; } else { Node\u0026lt;E\u0026gt; x = last; for (int i = size - 1; i \u0026gt; index; i--) x = x.prev; return x; } }   可以看到，node(int index)总是从头/尾开始逐一遍历，当集合较大时，这种操作的效率是很低的\n既然如此，LinkedList插入和删除的效率如何高呢？答案就是使用迭代器，由于迭代器持有指针(cursor)，免去了遍历集合获取节点的时间消耗，因而插入和删除只需要修改前后节点的引用即可：\n从LinkedList删除一个元素 from Core Java\n 所以，不要在LinkedList中使用带有索引(index)参数的操作，这会大大降低程序的运行效率，若要使用索引，请使用ArrayList\n 2.4 作为双端队列 LinkedList除了实现了List接口之外，还实现了Deque接口，也就是说，LinkedList还是一个双端队列，具体请参照Queue—Java集合框架系列之二\n 这种情况在获取集合视图(Collection view)时经常出现 \u0026#x21a9;\u0026#xfe0e;\n 集合框架所有迭代器都是如此 \u0026#x21a9;\u0026#xfe0e;\n 这一论点的普适性有待验证 \u0026#x21a9;\u0026#xfe0e;\n 这只是一种表述形式，实际上ArrayList的迭代器是私有内部类，无法使用该语法访问，下同 \u0026#x21a9;\u0026#xfe0e;\n 是否一直如此？集合框架中的视图（子集、键集、条目映射、Collections视图等等）都是基于基本接口的内部类实现 \u0026#x21a9;\u0026#xfe0e;\n SubList并没有集合视图的共性，其操作集合的方法是独特的；它被称为集合视图的原因是其不是标准的Java集合框架成员 \u0026#x21a9;\u0026#xfe0e;\n 这和ArrayList的ListIterator没有实现hasNext()一样，实际上也是可以使用的(接口动态绑定超类方法)，这种情况在集合框架中很常见 \u0026#x21a9;\u0026#xfe0e;\n LinkedList使用和索引相关的操作get()/set()/add()/remove()的效率是一致的 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"“本文介绍了Java集合框架中的两个重要List实现，ArrayList和LinkedList。”","id":33,"section":"posts","tags":["集合框架","List"],"title":"List","uri":"http://wangy325.top/zh/posts/java/collections/list/"},{"content":"将一个类定义在另一个类的内部，这就是内部类。\n 定义言简意赅 ，内涵丰富多彩。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  public class Flight2 { // inner class  class Comp{ private String name; public String getName(){ return name; } public void setName(String name) { this.name = name; } } class Dest{ private String to; public Dest(String to) { this.to = to; } public String showDest(){ return to; } } // use method to get inner class instance  public Comp comp(){ return new Comp(); } // use method to get inner class instance  public Dest dest(String to){ return new Dest(to); } public void ship(){ Comp c = comp(); c.setName(\u0026#34;South Air\u0026#34;) Dest d = dest(\u0026#34;HK\u0026#34;); System.out.println(\u0026#34;the flight is \u0026#34; + c.getName() + \u0026#34; to \u0026#34; + d.showDest()); } public static void main(String[] args) { Flight2 f2 = new Flight2(); f2.ship(); // OuterClassName.InnerClassName to refer inner class  Flight2 f2s = new Flight2(); Flight2.Comp comp = f2s.comp(); Flight2.Dest d2 = f2s.dest(\u0026#34;New York\u0026#34;); } }   通过new关键字实例化内部类和使用普通类并没有什么区别。\n需要说明的是：当创建一个内部类的引用时，需要使用OuterClassName.InnerClassName这样的格式指明内部类的类型。\n10.1 访问外部类  当生成一个内部类对象时，此对象与制造它的外围对象（ enclosing object ）就形成了某种联系，内部类能够访问外围对象的所有成员，而不需要任何特殊条件。\n 考虑如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  // 内部类实现的接口 interface Selector{ boolean end(); Object current(); void next(); } public class Sequence { private Object[] items; private int next = 0; public Sequence(int size) { items = new Object[size]; } public void add(Object o){ if (next \u0026lt; items.length){ items[next++] = o; } } // 内部类实现自接口  // 这是一个private修饰的内部类  private class SequenceSelector implements Selector{ private int i = 0; // 内部类直接访问了外围类的私有域  @Override public boolean end() { return i == items.length; } @Override public Object current() { return items[i]; } @Override public void next() { if (i \u0026lt; items.length) i++; } } // 获取内部类实例  public Selector selector(){ return new SequenceSelector(); } public static void main(String[] args) { Sequence s = new Sequence(10); for (int i = 0; i \u0026lt;10 ; i++) { s.add(Integer.toString(i)); } Selector selector = s.selector(); // equals to  // Sequence.SequenceSelector selector = s.selector();  while (!selector.end()){ System.out.println(selector.current()); selector.next(); } } }   这是一个简单的“迭代器”的例子，这个说明的是，在内部类里，无需任何说明，即可访问外围类的私有域。这是由于内部类在实例化时，必定捕获一个创建此内部类的外围类对象的引用（静态内部类除外），当在内部类访问外围类成员时，就使用那个引用访问。\n当使用private来修饰内部类时，情况有一些特殊。结论是当使用private修饰内部类时，内部类仅在外围类作用域中可用，在其他作用域内不可用，我们将上面的例子试图作如下修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  interface Selector{ boolean end(); Object current(); void next(); } class Sequence1 { private Object[] items; private int next = 0; public Sequence1(int size) { items = new Object[size]; } public void add(Object o){ if (next \u0026lt; items.length){ items[next++] = o; } } private class SequenceSelector implements Selector{ private int i = 0; @Override public boolean end() { return i == items.length; } @Override public Object current() { return items[i]; } @Override public void next() { if (i \u0026lt; items.length) i++; } } // 此处返回内部类或其基类类型都可以  public SequenceSelector selector(){ return new SequenceSelector(); } } public class Sequence{ public static void main(String[] args) { Sequence1 s = new Sequence1(10); for (int i = 0; i \u0026lt;10 ; i++) { s.add(Integer.toString(i)); } // 此处的返回只能向上转型为基类  Selector selector = s.selector(); // illegal！can not access. private class  // Sequence.SequenceSelector selector = s.selector();  while (!selector.end()){ System.out.println(selector.current()); selector.next(); } } }   可以看到，当试图在另一个类中访问内部类时，编译器会给出错误信息——不能访问私有内部类，它被隐藏了。\n这是一种保护机制，除了内部类的外部类之外，任何人无法访问内部类，这样可以将内部类的实现（甚至其他不属于接口的实现）隐藏起来，这给Java编译器提供了生成高效代码的机会。\n10.2 .this和.new  在拥有外部类的引用之前，是不能创建内部类对象的，因为内部类总是和外部类建立着联系\n当然，这个规则不适用于静态内部类（嵌套类）\n 如果需要在内部类中生成对外部类对象的引用，就需要用到.this。\n如果创建一个内部类对象，可以使用.new。\n正如前面提到的，此例中的内部类不能使用private修饰。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public class ThisNew { public static void main(String[] args) { DotThis d = new DotThis(); // OuterClassName.InnerClassName语法  DotThis.Inner ti = d.inner(); ti.outer().f(); DotNew n = new DotNew(); // 使用 .new 获取内部类引用  DotNew.Inner ni = n.new Inner(); ni.f(); } } class DotThis{ void f(){System.out.println(\u0026#34;DotThis.f()\u0026#34;);} class Inner{ // 在内部类中生成外部类对象引用  public DotThis outer(){return DotThis.this;} } Inner inner(){ return new Inner(); } } class DotNew{ class Inner{ void f(){ System.out.println(\u0026#34;DotNew.Inner.f()\u0026#34;); } } }   10.3 局部内部类 之前提到的示例中，内部类都是一个“单独的作用域”，那些内部类看起来都很容易理解，直观上都是把一个普通的Java类“放置”在另一个Java类内部\n然而 ，内部类可以定义在一个方法里甚至任意的作用域内。\n10.3.1 方法中的内部类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  interface Dest{ String showDest(); } public class Flight3 { public Dest dest(String to){ // 内部类在方法的作用域中  class PDest implements Dest{ private String to; // 私有构造器  private PDest(String dest) { this.to = dest; } @Override public String showDest() { return to; } } // 构造内部类实例，向上转型  return new PDest(to); } public static void main(String[] args) { Flight3 f = new Flight3(); Dest d = f.dest(\u0026#34;Macao\u0026#34;); System.out.println(d.showDest()); } } /* Macao *///:~   内部类PDest在dest()方法体内，只能在dest()中能够访问，其他地方无法访问，引出几个内涵：\n PDest类使用权限修饰符没有意义，编译器也警告你不能使用任何修饰符 PDest类的构造器是私有的，实际上由于作用域的限制，其访问权限无论是私有还是公有意义不大  10.3.2 任意域中的内部类 参考如下例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class Flight4 { private void flight(boolean fly){ if (fly) { // inner class scope  class InternalFlight { private String to; InternalFlight(String to) { this.to = to; } String showDest(){return to;} } // instance can only initialized here(in scope)  InternalFlight f = new InternalFlight(\u0026#34;TaiPei\u0026#34;); System.out.println(f.showDest()); } // illegal access! out of scope  // InternalFlight f = new InternalFlight(\u0026#34;TaiPei\u0026#34;);  } public static void main(String[] args) { Flight4 f = new Flight4(); f.flight(true); } } /* TaiPei *///:~   内部类InternalFlight定义在if语句的作用域内，无法在if语句的作用域之外创建对内部类的引用。\n同样地，定义在语句作用域的内部类也可以继承自接口，参考下例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  class FlightShip { Dest flight(boolean fly){ if (fly) { // inner implements interface  class InternalFlight implements Dest { private String to; InternalFlight(String to) { this.to = to; } @Override public String showDest(){return to;} } InternalFlight f = new InternalFlight(\u0026#34;TaiPei\u0026#34;); System.out.println(f); System.out.println(f.showDest()); // upcast to interface  return f; } return null; // illegal access!  // InternalFlight f = new InternalFlight(\u0026#34;TaiPei\u0026#34;);  } } public class Flight4{ public static void main(String[] args) { FlightShip f = new FlightShip(); Dest dest = f.flight(true); System.out.println(dest.showDest()); } } /* innerclass.FlightShip$1InternalFlight@74a14482 TaiPei TaiPei *///:~   上例中，定义在if语句块的内部类继承了Dest接口，并且包含内部类的方法返回了一个Dest引用（实际上是内部类对象引用的向上转型）。\n 它像不像一个工厂方法？\n 10.4 匿名内部类 不负责任地说，匿名内部类应该是实际应用中使用最多的内部类了。\n10.4.1 实现接口 当你需要“创建一个接口的匿名类的对象”时，通过new表达式返回的引用被自动向上转型为接口的引用。\n参考下例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class Flight5 { public static void main(String[] args) { AnonFlight af = new AnonFlight(); Dest hk = af.flight(\u0026#34;HK\u0026#34;); System.out.println(hk.showDest()); } } class AnonFlight { Dest flight(String dest) { // 实现了Dest接口的匿名内部类  return new Dest() { // 匿名内部类中还可以进行字段初始化  private String to = dest; @Override public String showDest() { return to；} }; } } /* HK *///:~   匿名内部类常见的语法格式为：\n* new SuperType(construction parameters){ inner class method and data } *\n上例中，我们传递“构造器参数”，实际上它不是构造器参数，只是用于内部类的字段初始化。\n10.4.2 继承超类 匿名内部类还可以继承自某个普通类，此种情况下，内部类还可能有一些特殊的行为——调用构造器实现实例初始化。\n 实际上匿名内部类没有名字，也不可能有构造器。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  public class Flight6 { public static void main(String[] args) { Pistol p = new Pistol(); Wrap wrap = p.wrap(3); System.out.println(wrap.value()); } } class Pistol { Wrap wrap(int x) { // 继承类的匿名内部类  return new Wrap(x) { int v; // 使用{}实现类似构造器的行为（初始化字段）  { System.out.println(\u0026#34;extended initialized\u0026#34;); // 字段初始化  v = super.value() *3; } @Override int value() { return v ; } }; } } // 基础类 class Wrap { private int i; public Wrap(int i) { this.i = i; System.out.println(\u0026#34;base constructor\u0026#34;); } int value() { return i; } } /* base constructor extended initialized 9 *///:~   上例中，匿名内部类new Wrap(x)中由wrap(int x)传递来的参数x作为了基类的构造器参数，在构造内部类的时候首先调用了基类的构造器，这是可以预想的结果。同时，在匿名内部类中使用了{}语句来模拟匿名内部类的构造器行为——初始化字段信息， super.value()的返回值也说明了基类已经在构造内部类之前就已经实例化成功了。\n 双花括号语法：{{\u0026hellip;}}\n其实上例给了一个启示：在内部类中使用{}进行了字段初始化，那么{{}}是否可以用来实例初字段始化呢？答案是肯定的，比如在初始化一个数组列表时\nList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(){{add(\u0026quot;ali\u0026quot;); add(\u0026quot;google\u0026quot;); add(\u0026quot;amazon\u0026quot;);}};\n这样有一个便利，当一个对象只需要使用一次的时候，可以使用匿名数组列表\n 10.4.3 再论工厂方法 在讨论接口的过程中，讨论了利用接口使代码与实现分离的工厂模式，下例中使用匿名内部类优化代码时，会发现代码变得更加优雅。\n下例展示了如何使用静态工厂方法获取实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  public class SimpleFactory2 { public void serviceConsumer(ServiceFactory sf){ Service s = sf.getService(); s.service_a(); s.service_b(); } public static void main(String[] args) { SimpleFactory2 sf = new SimpleFactory2(); sf.serviceConsumer(NameService.factory); sf.serviceConsumer(AgeService.factory); } } interface Service { void service_a(); void service_b(); } interface ServiceFactory { Service getService(); } class NameService implements Service { private NameService() {} @Override public void service_a() {System.out.println(\u0026#34;NameService.service_a()\u0026#34;);} @Override public void service_b() {System.out.println(\u0026#34;NameService.service_b()\u0026#34;);} // 使用匿名内部类获取工厂类  // 使用static避免服务的初始化，因为工厂是来获取实例的，已经初始化了就没意义了  public static ServiceFactory factory = new ServiceFactory() { @Override public Service getService() { return new NameService(); } }; // same as lambda expression below  // public static ServiceFactory factory = () -\u0026gt; new NameService(); } class AgeService implements Service { private AgeService() { } @Override public void service_a() {System.out.println(\u0026#34;AgeService.service_a()\u0026#34;);} @Override public void service_b() {System.out.println(\u0026#34;AgeService.service_b()\u0026#34;);} public static ServiceFactory factory = new ServiceFactory() { @Override public Service getService() { return new AgeService(); } }; // same as lambda expression below  // public static ServiceFactory factory = () -\u0026gt; new AgeService(); }    服务类的构造器私有，使得无法从外部实例化构造器 静态字段获取工厂，实际上也只能使用静态字段 匿名内部类可以等价转换为lambda表达式  10.4.4 与lambda表达式 Java SE 8引入lambda表达式之后，匿名内部类与lambda表达式的关系变得亲密起来，匿名内部类可以等价转换为lambda表达式，但这不是绝对的。\nlambda表达式的本质是一个函数，在一般来讲，lambda表达式“实例化接口”时，该接口一般为函数式接口，只需覆盖一个抽象方法，这是lambda能做的全部。\n而匿名内部类则要复杂的多，它是一个完整的类，除了没有构造器之外，其可以有字段利用参数进行初始化，其可以有{}statement实现类实例化操作等等，这种形式的匿名内部类，是无法等价为lambda表达式的。\n考虑lambda表达式体中自由变量的几个约束，除了变量命名规则之外 ，其他规则同样在匿名内部类中适用，一些较老的资料（Java SE 7或之前）甚至常有这样的描述：\n Java编译器要求传入内部类（包括lambda表达式）的的参数必须显示使用final修饰\n 就像这样：\n1 2 3 4 5 6 7 8 9 10 11  class AnonFlight { Dest flight(final int dest) { return new Dest() { private int to = dest; @Override public String showDest() { // dest--； // not allowed!  return to；} }; } }   事实上，之前的示例中我们从来没有将内部类的参数引用声明为final，不过，尽管可以不用声明为final，约束依旧是存在的，你不能在内部类中修改参数（的引用）。\n编译器给出的信息像这样：\n Variable \u0026lsquo;variable\u0026rsquo; is accessed from within inner class, needs to be final or effectively final\n 值得一提的是，上述约束对于局部内部类的参数引用同样适用\n参考如下局部内部类的示例：\n1 2 3 4 5 6 7 8 9 10 11 12  public Dest dest(String t) { class PDest implements Dest { private String to; private PDest(String dest) {this.to = dest;} @Override public String showDest() { // t = t.concat(\u0026#34;xxx\u0026#34;); // not allowed!  return to; } } return new PDest(t); }   10.5 静态内部类 非静态内部类编译的时候，会提供一个对外部类的引用，这是在内部类中使用.this的前提。\n如果不需要这种内部类和外部类的联系，可以将内部类声明为static，这通常称为静态内部类或嵌套类。\n如果使用静态内部类，那么意味着：\n  不需要外围类即可创建静态内部类对象\n  静态内部类无法访问外围类的非静态对象\n  静态内部类可以有static字段和数据\n 普通内部类也能有静态字段，但是必须配合final声明为静态常量。原因很简单，Java希望静态字段只有一个实例，但是对每个外围类对象，会分别有一个内部类实例，如果这个字段不是final，那它可能不是唯一的\n普通内部类不能有static方法\n   静态内部类可以嵌套静态内部类内部类\n 普通内部类也可以嵌套，这种嵌套关系变得愈发复杂\n   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  public class Flight7 { public static void main(String[] args) { // ERROR! out of scope!  // StaticFlight.InnerComp comp = StaticFlight.comp();  // private inner class must upcast  Comp comp = StaticFlight.comp(); StaticFlight.InnerDest dest = StaticFlight.dest(\u0026#34;GZ\u0026#34;); // ERROR! cannot access!  // StaticFlight.InnerComp.g();  // 访问内部类静态域  System.out.println(\u0026#34;StaticFlight.InnerDest.x = \u0026#34; + StaticFlight.InnerDest.x); System.out.println(comp.showComp()); System.out.println(dest.showDest()); // 访问内部类嵌套类静态方法  StaticFlight.InnerDest.AnotherLevel.f(); // 获取内部类嵌套类实例并调用方法  StaticFlight.InnerDest.AnotherLevel l = dest.anotherLevel(); System.out.println(\u0026#34;StaticFlight.InnerDest.AnotherLevel.p(): \u0026#34;+ l.p()); } } interface Dest { String showDest(); } interface Comp{ String showComp(); } class StaticFlight{ private int constant = 10; private static int constant_b = 10; // 私有静态内部类  private static class InnerComp implements Comp { private String comp = \u0026#34;AIR CHINA\u0026#34;; // ERROR! cannot access non-static filed of outer class  // private int a = constant;  @Override public String showComp() { return comp; } // 有限作用域  static void g(){ System.out.println(\u0026#34;g()\u0026#34;); } } // 静态内部类  static class InnerDest implements Dest{ private String to; private InnerDest(String to) { this.to = to; } @Override public String showDest() { return to; } // 静态域，能够访问外围类静态域  static int x = constant_b; // 嵌套静态内部类  static class AnotherLevel{ // 静态方法  static void f(){ System.out.println(\u0026#34;StaticFlight.InnerDest.AnotherLevel.x = \u0026#34; + y); } int p(){ return ++x; } static int y = constant_b; // same as  // static int y = x  } AnotherLevel anotherLevel(){ return new AnotherLevel(); } } static InnerComp comp(){ return new InnerComp(); } static InnerDest dest(String s){ return new InnerDest(s); } } /* StaticFlight.InnerDest.x = 10 AIR CHINA GZ StaticFlight.InnerDest.AnotherLevel.x = 10 StaticFlight.InnerDest.AnotherLevel.p(): 11 *///:~   上面的实例展示了上述静态内部类的性质。\n外围类的comp()和dest()方法被声明为静态的（非必须），说明不需要外围类实例即可创建内部类实例，在main方法里也是这么做的，而这是普通内部类无法完成的，如果试图这样做，会得到错误消息。\n ​\t\u0026lsquo;xx.xx.x.outerClass.this\u0026rsquo; cannot be referenced from a static context\n 外围类定义了非静态字段constant和静态字段constan_b，在静态内部类中无法访问constant，却可以访问constant_b。\n静态内部类可以嵌套，嵌套的内部类可以访问嵌入其的所有外围类的。\n静态内部类除了static数据和域存在特殊性之外，其他的使用和普通内部类无异。\n10.6 接口中的内部类 接口中的任何类都是public和static的，因此将静态内部类置于接口中并不违反接口的规则。\n甚至可以使接口中的内部类实现自其外围接口，参考下例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public interface InnerclassInterface { void m(); class Test implements InnerclassInterface{ @Override public void m() {System.out.println(\u0026#34;man!\u0026#34;);} } // static method in interface  static Test test(){return new Test();} class Main{ public static void main(String[] args) { Test test = test(); test.m(); } } } /* man! *///:~   ","description":"在一个类的内部再定义一个类，那么被定义的类就是内部类。","id":34,"section":"posts","tags":["内部类","工厂方法","lambda"],"title":"内部类","uri":"http://wangy325.top/zh/posts/java/basic/%E5%86%85%E9%83%A8%E7%B1%BB/"},{"content":"1 lambda表达式 lambda表达式是一个可传递的代码块，可以在以后执行一次或多次。\n从一个比较器说起：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class Intro { public static void main(String[] args) { String[] s = new String[]{\u0026#34;baidu\u0026#34;,\u0026#34;alibaba\u0026#34;,\u0026#34;tencent\u0026#34;,\u0026#34;baida\u0026#34;,\u0026#34;kingdee\u0026#34;}; // String类实现了Comparable接口，可以直接使用sort方法实现字典序排序  // 为什么是字典序？因为String类的实现逻辑是字典序  Arrays.sort(s); System.out.println(Arrays.toString(s)); Arrays.sort(s, new StringLengthComparator()); //等效使用lambda表达式实现  //Arrays.sort(s, (o1, o2) -\u0026gt; o1.length() - o2.length());  System.out.println(Arrays.toString(s)); } } // 比较器实现——先按字符串长度排序 class StringLengthComparator implements Comparator\u0026lt;String\u0026gt;{ @Override public int compare(String o1, String o2) { return o1.length() - o2.length(); } } /* output [alibaba, baida, baidu, kingdee, tencent] [baida, baidu, alibaba, kingdee, tencent] *///:~   上例中，compare方法不是立即调用，在数组完成排序之前，sort方法会一直调用compare方法，只要元素的排列顺序不正确就会重新排列元素。\n1  API:\tpublic static \u0026lt;T\u0026gt; void sort(T[] a, Comparator\u0026lt;? super T\u0026gt; c)   sort方法需要一个比较器作为参数，接口Comparator只有一个抽象方法compare，要实现排序，实现compare方法即可，这正是StringLengthComparator类所做的事情。\n由于StringLengthComparator类只有一个方法，这相当于将一段代码块（函数）传递给sort。实际上这就是Java处理函数式编程的方式：Java是面向对象语言，因此必须构造一个对象，这个对象有一个方法包含所需的逻辑代码。\n此例中，如果使用lambda表达式Arrays.sort(s, (o1, o2) -\u0026gt; o1.length() - o2.length());，那么Arrays.sort会接收实现了Comparator\u0026lt;String\u0026gt;的某个类的对象，并在这个对象上调用compare方法去执行lambda表达式的“体”，这些对象和类的管理完全取决于具体实现，与传统的内联类相比，更加高效。\nlambda表达式可以将代码块传递给某个对象。形如：\n1  (String o1, String o2) -\u0026gt; o1.length() - o2.length()   就是一个lambda表达式，由参数、箭头（-\u0026gt;）以及表达式3部分组成。为什么和代码示例中有细微差别？这里声明了String参数类型。\n如果可以推导出lambda表达式的参数类型（多数情况如此），那么可以省略类型声明：\n1  (o1, o2) -\u0026gt; o1.length() - o2.length()   即便lambda表达式没有参数，也必须保留参数括号，以下lambda展示了表达式有多句的情况——使用{}，看起来就像一个Java方法：\n1  () -\u0026gt; {for (int i = 0, i\u0026lt;10, i++) System.out.println(i);}   如果lambda表达式只有一个参数，并且这个参数类型可以推导得出，甚至连()都可以省略：\n1  new ArrayList().removeIf(e -\u0026gt; e == null)   无需指定lambda表达式的返回类型。lambda表达式的返回类型总是可以根据上下文推导得出。\n2 函数式接口  对于只有一个抽象方法的接口，需要这种接口的对象时，就可以提供一个lambda表达式，这种接口叫函数式接口\n java.util.Comparator接口就是一个函数式接口，它只有一个抽象方法：\n1  int compare(T o1, T o2);   其他方法均被声明为默认方法。\njava.util.function包中定义了很多通用的函数式接口，上文中的Predicate便是。ArrayList中的forEach方法参数就是此包中的另一个函数式接口Consumer:\n1  public void forEach(Consumer\u0026lt;? super E\u0026gt; action)   可以用此接口快速遍历集合元素\n list.forEach(e -\u0026gt; System.out.println(e))\nlist.forEach(System.out::println)方法引用\n Java API使用@FunctionalInterface注解来标注函数式接口。\n类似地，org.springframework.jdbc.core.RowMapper也被声明为一个函数式接口，它只有一个方法mapRow，用来处理SQL语句的回调：\n1  T mapRow(ResultSet rs,int rowNum) throws SQLException   3 方法引用 如果有现成的方法完成想要传递到其他代码的操作，例如你只想通过forEach打印集合中的元素，可以使用\n1  list.forEach(e -\u0026gt; System.out.println(e))   就像之前提到的那样，但是，也可以直接把println方法传递给forEach，就像这样：\n1  list.forEach(System.out::println)   这就是方法引用，它和上面的lambda表达式是等价的。\n如果lambda表达式的“体”直接调用了某个方法，而没有其他多余代码，那么这个lambda表达式可以等价转换为方法引用。\n还是参考比较器的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Intro { public static void main(String[] args) { String[] s = new String[]{\u0026#34;baidu\u0026#34;, \u0026#34;alibaba\u0026#34;, \u0026#34;tencent\u0026#34;, \u0026#34;baida\u0026#34;, \u0026#34;kingdee\u0026#34;}; // lmabda statement original \t/*Arrays.sort(s, (o1,o2) -\u0026gt; { if (o1.length() != o2.length()) return o1.length() - o2.length(); return o1.compareTo(o2); })*/ // lambda expression with method reference  Arrays.sort(s, (o1,o2) -\u0026gt; localCompare(o1, o2) ); // method reference  Arrays.sort(s, Intro::localCompare) System.out.println(Arrays.toString(s)); private static int localCompare(String o1, String o2) { if (o1.length() != o2.length()) return o1.length() - o2.length(); return o1.compareTo(o2); } }   原始的lambda表达式有2行代码（2个逻辑），可以将其重构为一个方法，并在lambda表达式中引用该方法，这样做之后，原lambda表达式的“体”就变成了一个简单的方法调用，那么它便可以等价为方法引用：\n1  Arrays.sort(s, Intro::localCompare)   方法引用根据调用者和方法类型区分，有3种形式\n  object.instanceMethod：对象调用实例方法\n  Class.staticMethod：类调用静态方法\n  Class.instanceMethod：类调用实例方法\n  前2者较容易理解，第3种情况需要特殊说明，参考如下示例：\n1 2 3 4 5 6 7 8 9 10  //... Arrays.sort(s, new Comparator\u0026lt;String\u0026gt;() { @Override public int compare(String s3, String str) { return s3.compareToIgnoreCase(str); } }); Arrays.sort(s, (s3, str) -\u0026gt; s3.compareToIgnoreCase(str)); Arrays.sort(s, String::compareToIgnoreCase); //...   当使用类调用实例方法时，第一个参数会成为方法的目标，第二个参数作为方法的参数需求证。\n方法引用种可以使用this和super关键字，分别表示调用当前类和超类的方法。\n3 变量作用域 在使用Spring JDBC操作数据库时，需要用到RowMapper的回调来处理返回数据，前文已提及，RowMapper是一个函数式接口，可以等价为lambda表达式：\n1 2 3 4 5  public List\u0026lt;Spitter\u0026gt; findAll() { return jdbcOperations.query(SPITTER_SELECT, (rs, rowNum) -\u0026gt; this.mapResult(rs, rowNum)); } // skip mapResult...   可以看到，lambda表达式中使用了this关键字，指定的是创建这个lambda表达式的方法的this，通俗地讲，就是调用传入lambda参数方法的实例，此处的this可以省略。\n之前的所述的lambda表达式都没有涉及一个概念：自由变量，这是除了表达式和参数之外，lambda的另一个组成部分，指的是不是参数且不在表达式中定义的变量。\n1 2 3 4 5 6 7  static void repeatMessage(String msg, int delay) { ActionListener listener = e -\u0026gt; { System.out.println(msg); Toolkit.getDefaultToolkit().beep(); }; new Timer(delay, listener).start(); }   当调用repeatMessage(\u0026quot;Hello World\u0026quot;, 1000);时，控制台每隔1s输出Hello World\n上例的lambda中，msg就是一个自由变量，它来自于repeatMessage方法的参数变量。在运行过程中，lambda表达式可能会延迟执行或者执行很多次，这时候主线程可能已经结束，repeatMessage方法的参数变量也可能已经销毁了，这个变量是如何保存的呢？\n实际上，lambda表达式在运行时“捕获”了自由变量的值，可以把lambda表达式理解为一个含有方法的实例对象，自由变量的的值便复制到了这个实例对象中\n当在lambda表达式中使用自由变量时，有几个约束：\n1） 不能在lambda表达式中改变自由变量的值\n1 2 3 4 5 6 7  static void countDown(int start, int delay){ ActionListener listener = evevt -\u0026gt; { // start--; // ERROR! can\u0026#39;t mutate captured variable  System.out.println(start); }; new Timer(delay, listener).start(); }   这是出于线程安全的考虑。\n2） 不能引用在外部改变了值的自由变量\n1 2 3 4 5 6 7 8  static void repeat(String text, int count){ for (int i = 1, i\u0026lt;= count, i++){ ActionListener listener = evevt -\u0026gt; { // System.out.println(i + \u0026#34;text\u0026#34;); // ERROR! can\u0026#39;t refer to changing i  }; new Timer(1000, listener).start(); } }   3） 注意变量的命名\n1 2 3  int first = 1; Compartor\u0026lt;String\u0026gt; comp = (first, second) -\u0026gt; first.length() - senond.length(); // ERROR variable first already exists   lambda表达式的“体”和“嵌套块”具有相同的作用域。\n","description":"本文介绍了Java8的新特性，lambda表达式，函数式接口，以及方法引用。并讨论了使用lambda表达式时，变量作用域的问题。","id":35,"section":"posts","tags":["lambda"],"title":"lambda表达式","uri":"http://wangy325.top/zh/posts/java/basic/lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"content":"抽象类是由abstract关键字修饰的类。将一个普通类用abstract修饰，它就是抽象类。\n若使用abstract修饰方法，那么称该方法为抽象方法，抽象方法没有方法体。\n8.1 抽象类 但是抽象类有一些特征：\n 抽象类不能被实例化（虽然抽象类可以声明域和构造器） 抽象方法必须置于抽象类中  如果你继承某抽象类，但是却不想实现某个抽象方法，可以继续让方法保持抽象，如此做导出类也要被声明为抽象类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  public class AbsTest { public static void main(String[] args) { S s = new S(); s.f(); s.g(); } } abstract class F{ public F() { System.out.println(\u0026#34;F constructor\u0026#34;); } abstract void f(); void g(){ System.out.println(\u0026#34;F.g()\u0026#34;); } } class S extends F{ public S() { super(); System.out.println(\u0026#34;S constructor\u0026#34;); } @Override void f() { System.out.println(\u0026#34;S.f()\u0026#34;); } } /* output F constructor S constructor S.f() F.g() *///:~   8.2 接口 接口的存在，解决了抽象类只能单继承的不足——同一个类可以实现多个接口。\n接口有如下特点：\n  接口不是类，不能使用new实例化一个接口，但是可以声明一个接口变量：\n List x = new ArrayList();\n如上，变量必须引用实现了接口的类对象\n   可以使用instanceof操作符判断一个类是否是接口的实现类：\n If (ObjectA instanceof List) {\u0026hellip;}\n   接口的方法都是public的，无论是否使用public修饰；\n  接口可以有常量，即public static final CONSTANT = 1，如你所见，接口的常量自动设为静态常量。\n  8.2.1 静态方法 Java SE 8允许在接口中增加静态方法。\n在Java SE 8之前，通常的做法是将静态方法放在伴随类中，如Java标准库中成对出现的接口和工具类如Collection/Collections或Path/Paths。\n实际上在Java SE 8，我们可以将 Paths的静态方法置于Path接口中：\n1 2 3 4 5 6 7  public interface Path{ //...  // 通过Path.get(a, b)直接调用  public static Path get(String first, String... more){ return FileSystems.getDefault().getPath(first, more); } }   实现类不可覆盖接口的静态方法。\n8.2.2 默认方法 使用default关键字为接口方法提供一个默认实现\n1 2 3 4 5 6 7  /** @since 1.8 */ public interface java.util.Collection{ //...  default Stream\u0026lt;E\u0026gt; parallelStream() { return StreamSupport.stream(spliterator(), true); } }   接口默认方法能够有效地解决“接口演化”问题——不会影响实现类原有逻辑。\n当实现类没有覆盖默认方法时，会调用接口的默认方法。\n参考如下实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  public class InterfaceTest { public static void main(String[] args) { System.out.println(I.get()); I i = new L(); i.j(); i.k(); } } interface I { int CONSTANT = 1; // static method in a interface  static int get() { return CONSTANT; } // abstract method  void j(); // default method  default void k() { System.out.println(\u0026#34;I.k()\u0026#34;); } } class L implements I { @Override public void j() { System.out.println(\u0026#34;L.j()\u0026#34;); } } /* output 1 L.j() I.k() *///:~   8.2.3 默认方法的冲突 考虑如下情况：\n 若2个接口提供了同样的默认方法 若超类定义了和接口中默认方法同名同参数的具体方法  情况1中，实现类必须手动覆盖默认方法（一般无需覆盖）来告诉编译器调用哪个方法——实际上是调用类自己的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class InterfaceTest { public static void main(String[] args) { C c = new C(); c.di(); } } interface I1 { default void di() { System.out.println(\u0026#34;I1.di()\u0026#34;); } } interface I2 { default void di() { System.out.println(\u0026#34;I2.di()\u0026#34;); } } class C implements I1, I2 { // 必须覆盖方法以消除歧义性  @Override public void di() { System.out.println(\u0026#34;calling C.di()\u0026#34;); // 这里使用了I1的实现，注意这里的写法 Interface.super.default_method  I1.super.di(); } } /* output calling C.di() I1.di() *///:~   若上例中I2.di()是抽象方法，是不是就不存在歧义了呢？并不是，编译器还是会提醒覆盖di()方法。\n情况2中，Java使用“类优先”原则，即编译器只会考虑超类的方法而忽略接口的默认方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class InterfaceTest2 { public static void main(String[] args) { W w = new W(); w.pType(); } } interface Vita{ default void pType(){ System.out.println(\u0026#34;Vita 柠檬茶\u0026#34;); } } abstract class Drink{ public void pType(){ System.out.println(\u0026#34;Vita 奶\u0026#34;); } } class W extends Drink implements Vita{ // empty body } /* Vita 奶 *///:~   当然，也可以通过手动覆盖来指定实现，就像情况1中的那样：\n1 2 3 4 5  @Override public void pType() { super.pType(); // Vita.super.pType();  }   8.2.4 接口与工厂 工厂方法用来生成实现了某个接口的对象，这一过程并不直接调用构造器，而是调用工厂类的创建方法。\n考虑如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  public class SimpleFactory { public void serviceConsumer(ServiceFactory sf) { Service s = sf.getService(); s.service_a(); s.service_b(); } public static void main(String[] args) { SimpleFactory sf = new SimpleFactory(); sf.serviceConsumer(new NameServiceFactory()); sf.serviceConsumer(new AgeServiceFactory()); } } interface Service { void service_a(); void service_b(); } interface ServiceFactory { Service getService(); } // 服务1 class NameService implements Service { NameService() {} @Override public void service_a() {System.out.println(\u0026#34;NameService.service_a()\u0026#34;);} @Override public void service_b() {System.out.println(\u0026#34;NameService.service_b()\u0026#34;);} } // 服务1的工厂 class NameServiceFactory implements ServiceFactory { @Override public Service getService() {return new NameService();} } // 服务2 class AgeService implements Service { AgeService() {} @Override public void service_a() {System.out.println(\u0026#34;AgeService.service_a()\u0026#34;);} @Override public void service_b() {System.out.println(\u0026#34;AgeService.service_b()\u0026#34;);} } // 服务2的工厂 class AgeServiceFactory implements ServiceFactory { @Override public Service getService() {return new AgeService();} } /* NameService.service_a() NameService.service_b() AgeService.service_a() AgeService.service_b() *///:~   上例中，服务类没有提供公有构造器，而其实例化由工厂了完成。这样做的好处在于，在使用服务方法时，无需知道确切服务的类型而去调用构造器，代码完全与接口的实现（本例中为NameService和AgeService）分离，具体应用过程中可以轻易的将A实现替换为B实现。\n","description":"本文介绍了Java中的抽象类和接口，简单介绍了工厂方法。","id":36,"section":"posts","tags":["工厂方法"],"title":"抽象类与接口","uri":"http://wangy325.top/zh/posts/java/basic/%E6%8A%BD%E8%B1%A1%E7%B1%BB%E4%B8%8E%E6%8E%A5%E5%8F%A3/"},{"content":"在Java中，如果一个类没有明确地指出超类，那么Object就是这个类的超类。实际上，Object类是所有类超类，这个类定义了一些重要的方法。\n1 equals equals方法用来比较两个对象是否相等。不过，在Object类中，这是判断两个对象是否具有相同的引用。\n当对象引用a和b指向同一个对象即认为a等于b，看起来，这似乎合乎情理，但是在很多情况下，需要比较对象的状态的相等性，所以，Object类的equals方法往往是没有什么用处的。\nJava语言规范要求equals方法具有以下特性：\n 自反性：对于任何非空引用x，x.equals(x)为true； 对称性：对于任何引用x、y，当且仅当y.equals(x)为true时，x.equals(y)才为true； 传递性：对于任何引用x、y、z，若x.equals(y)为true，y.equals(z)为true，那么x.equals(z)也应该为true； 一致性：对于任何引用x、y，若对象引用和equals方法未发生变化，那么多次调用应返回一致的结果； 对于任何非空引用x，x.equals(null)为false。  参考之前Employee2类的equals方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Employee2 { // skip...  @Override public boolean equals(Object o) { if (this == o) return true; if (o == null) return false; if (o.getClass() != getClass()) return false; Employee2 employee2 = (Employee2) o; /*if (salary != employee2.salary) return false; return name != null ? name.equals(employee2.name) : employee2.name == null;*/ // or using Objects.equals(Object a, Object b) to compare  return Objects.equals(name,employee2.name) \u0026amp;\u0026amp; salary == employee2.salary; }   这是一个典型的覆盖equals方法的策略：\n 检测o和this是否同一引用，若是，则返回true 检测o是否为空，若为空，则返回false 检测o和this是否是同一类型，若否，则返回false 将o转换为this类 比较o和this域的相等性   在导出类中调用equals方法时，要先调用基类的equals方法，基类的方法通过之后，再比较导出类的相关域的相等性。\n 参考如下例子：\n1 2 3 4 5 6 7 8 9 10 11  class Manager extends Employee2{ // skip...  @Override public boolean equals(Object o) { if(!super.equals(o)) return false; // super.equals checked that o and this belong to same class  Manager m = (Manager)o; return bonus == m.bonus; } }   以上的2个equals方法说明的是若导出类拥有自己的相等概念，那么在第3步类型判断中必须使用getClass，这样，基类和导出类（或者不同导出类）之前必然是不等的。\n考虑一种情况：若想在基类和导出类之间（或不同导出类之间）进行相等比较，那么只需要比较基类共有的域即可，即是否相等由基类判断，该如何处理呢？\n参考如下例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  class Stu{ // skip...  @Override public final boolean equals(Object o) { if (this == o) return true; if (o == null) return false; if (!(o instanceof Stu)) return false; Stu stu = (Stu) o; return stu.age == age \u0026amp;\u0026amp; Objects.equals(stu.name, name) \u0026amp;\u0026amp; Objects.equals(stu.code, code); } }   这个equals方法有几处变化：\n 这个方法是final的 判断类型使用的是instanceof而非getClass  将方法声明为final即保证了基类对相等概念的控制权（导出类无法覆盖equals方法），这还不够，使用instanceof保证了基类和导出类（或不同导出类）之间域的相等性比较的可能\n 应该谨慎使用instanceof判断操作符号。\n 2 hashCode hash code （散列码）是由对象导出的一个整型值\nJava语言对hashCode方法有如下规范：\n 在同一次Java程序运行过程中，无论调用多少次对象的hashCode方法，返回的应该是同一个整型值；而在不同程序运行过程中则无此要求； 对于任何对象a、b，若a.equals(b)为true，那么a和b的hashCode返回值应该相等； 对于任何对象a、b，若a.equals(b)为false，a和b的hashCode返回值没有必要一定不等；需要指出的是，给不同对象分配不同的hashcode值有利于提升哈希表的性能；  基于第2点规范，若重新定义了equals方法，那么必须重新定义hashCode方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class HashT { public static void main(String[] args) { String s = \u0026#34;s\u0026#34;; String t = new String(\u0026#34;s\u0026#34;); StringBuilder sb = new StringBuilder(s); StringBuilder tb = new StringBuilder(t); System.out.println(s.hashCode() + \u0026#34; : \u0026#34; +sb.hashCode()); System.out.println(t.hashCode() + \u0026#34; : \u0026#34; +tb.hashCode()); } } /* output 115 : 1956725890 115 : 356573597 *///:~   注意，s和t哈希值相同时因为String类覆盖了hashCode方法，其值是由字符串字面量值计算来的，而StringBuilder没有覆盖hashCode方法，其值是Object默认的hashCode方法导出的对象存储地址。\n","description":"本文简单阐述了Object超类中的equals和hashCode方法，说明了重写这两个方法的规范。","id":37,"section":"posts","tags":["Object"],"title":"Object超类（一）","uri":"http://wangy325.top/zh/posts/java/basic/object%E8%B6%85%E7%B1%BB/"},{"content":"这是Java方法调用的2个术语，用来描述Java虚拟机方法调用的2种机制。\n6.1 动态绑定 方法的名字和参数列表构成了方法的签名。\n 返回类型并不是方法签名的一部分，因此在覆盖方法时，允许将导出类的方法返回类型定义为基类返回类型的子类型\n 方法调用时，虚拟机为每个类创建一个方法表，列出所有的方法签名和实际调用的方法，调用方法时按表查找即可，例如方法表可能是这样的：\nFinalMethod: f() -\u0026gt; FinalMethod.f(); g() -\u0026gt; FinalMethod.g(); p() -\u0026gt; FinalMethod.p(); // skip Object method... FinalMethodExt f() -\u0026gt; FinalMethodExt.f(); p() -\u0026gt; FinalMethodExt.p(); // skip Object method... 当对象引用o调用方法时，其过程可归纳为：\n 虚拟机提取o的实际类型的方法表 在方法表中搜索调用的方法，若有满足，则直接调用 若无满足，则在o实际类型的父类中搜索调用的方法 调用方法或抛出异常  从上面的描述可以看出，继承体系中的方法调用可能出现不同的结果（导出类覆盖和未覆盖基类方法时的差异现象）。\n6.2 静态绑定 当方法被private，static，final修饰或调用构造器（构造器可看作是static方法）的时候，编译器即可准确的知道该调用哪个类的哪个方法，这一过程就是静态绑定。\n","description":"","id":38,"section":"posts","tags":[""],"title":"动态绑定与静态绑定","uri":"http://wangy325.top/zh/posts/java/basic/%E5%8A%A8%E6%80%81%E7%BB%91%E5%AE%9A%E4%B8%8E%E9%9D%99%E6%80%81%E7%BB%91%E5%AE%9A/"},{"content":"不同的使用环境下，final关键字的含义有细微差别，但通常它指“这是无法改变的”。\n5.1 final数据 final关键字通常用来表示一块数据是恒定不变的：\n5.1.1 常量   比如一个永不改变的编译时常量 \u0026mdash;\u0026gt; 对应前文所谓静态常量\npublic final double PI = 3.14\n如果使用static final来修饰变量，那么它就是一个标准的编译时常量（静态常量）\npublic static final double PI = 3.14\n在Java中，编译时常量必须是基本数据类型或字符串，声明时必须赋值\n  一个在运行时被初始化的值，你不希望它被改变\npublic final int RANDOM = new Random().nextInt(47)\n  一个既是final也是static的域只占用一段不能改变的存储空间\n当对非基本数据类型使用final时，其含义稍微有点变化，其使引用恒定不变，这就是说被final修饰的对象引用无法使其指向另一个对象，但是对象内容却是可以被修改的。\nJava允许声明一个空白final域，但是这个final域在使用前必须使用构造器（常见）或表达式初始化。\n5.1.2 参数 此外，Java允许参数列表中将参数指明为final，这意味着你无法在方法中更改参数引用所指向的对象，但是对象状态也是可变的。\n 注意此处的表述。作为对比，Java引用对象作为参数时，参数引用指向的对象是可以改变的（尽管这个改变不能应用到对象引用上\u0026mdash;对象引用不可变）\n 参考如下代码Employee2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  // 继续使用上例中的Employee2 public class FinalParam { static void with(final Employee2 e){ raiseSalary(e); // object it\u0026#39;s self can be modified  System.out.println(\u0026#34;salary of e = \u0026#34; + e.getSalary()); } static void raiseSalary(final Employee2 e){ e.raiseSalary(3); } static void swap(final Employee2 j, final Employee2 k){ Employee temp = j; // object reference can not be modified  // k = temp; // not allowed  // j = k; // not allowed  } static void g(final int i){ // i++; // not allowed  } public static void main(String[] args) { Employee x = new Employee(\u0026#34;ali\u0026#34;, 1000); with(x); System.out.println(\u0026#34;salary of x = \u0026#34; + x.getSalary()); } } /* output: salary of e = 3000 salary of x = 3000 *///:~   final参数一般用来向匿名内部类中传递数据。\n实际上，Java并没有提供任何对象恒定不变的途径，虽然可以通过编程取得对象恒定不变的效果单例。\n5.2 final方法\u0026ndash;阻止继承 当将一个方法声明为final时，其主要作用就是锁定方法，阻止继承，这往往是出于设计的考虑。\n需要特殊说明的是：如果一个方法是private的，那么它就被隐式地声明为final了，因为由于无法取用private方法，也就无法覆盖之。\n参考如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  public class FinalMethodT{ public static void main(String[] args) { FinalMethodExt x = new FinalMethodExt(); x.f(); x.g(); x.p(); System.out.println(\u0026#34;----\u0026#34;); // upcast  FinalMethod y = x; y.f(); y.g(); // y.p() // can\u0026#39;t access  System.out.println(\u0026#34;----\u0026#34;); FinalMethod z = new FinalMethod(); z.f(); z.g(); // z.p(); // can\u0026#39;t access  } } class FinalMethod { void f(){ System.out.println(\u0026#34;f()\u0026#34;); } final void g(){ System.out.println(\u0026#34;g()\u0026#34;); } // final is redundant actually  private final void p(){ System.out.println(\u0026#34;p()\u0026#34;); } } class FinalMethodExt extends FinalMethod{ void f() { System.out.println(\u0026#34;ext f()\u0026#34;); } // cannot override  // final void g(){ System.out.println(\u0026#34;ext g()\u0026#34;); }  final void p(){ System.out.println(\u0026#34;ext p()\u0026#34;); } } /* output: ext f() g() ext p() ---- ext f() g() ---- f() g() *///:~   基类和导出类的p方法，看上去像是导出类覆盖了基类的方法，实际上这是一种“字面”的覆盖，因为private方法并不是基类接口的一部分，它和导出类的p方法只是具有相同名称而已。\n还需要注意的是，即使使用了向上转型试图调用基类的方法，实际上却失败了，因为子类覆盖了这个方法。这种行为在Java中被称为动态绑定，即编译器知道实际引用的对象类型，从而去调用对应的方法。\n5.3 final类\u0026ndash;阻止继承 如果将一个类声明为final的（通常使用final class ...），意味着这个类不能被继承。\n也就是说，该类的所有方法都含有一个隐式的final修饰符。\nfinal类的域可以是或不是final，规则同final数据一致。\n","description":"","id":39,"section":"posts","tags":["final"],"title":"final关键字","uri":"http://wangy325.top/zh/posts/java/basic/final%E5%85%B3%E9%94%AE%E5%AD%97/"},{"content":"Java语言设计总是按值调用\n 按值调用：方法接收的是调用者提供的值\n按引用调用：方法接收的是调用者提供的变量地址\n 一个方法可以修改传递引用所对应的变量值，但是不能修改传递值所对应的变量值。\n3.1 基本数据类型参数  一个方法不能修改一个基本数据类型的参数（数值类型或布尔值）。\n 参考如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // doesn\u0026#39;t work class ByValue { static void tripleValue(int x) { x = 3 * x; System.out.println(\u0026#34;x = \u0026#34; + x); } public static void main(String[] args) { int y = 10; tripleValue(y); System.out.println(\u0026#34;y = \u0026#34; + y); } } /* output: x = 30 y = 10 *///:~   方法执行时，x被初始化为y值的一个拷贝，方法执行后 ，x值变为30，y仍为10，之后x不再使用。\n3.2 对象引用 3.2.1 (引用的)对象可变  一个方法可以改变一个对象参数的状态\n 参考如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  public class ByRef { static void raiseSalary(Employee2 o) { o.raiseSalary(3); System.out.println(\u0026#34;after salary of o = \u0026#34; + o.getSalary()); } public static void main(String[] args) { Employee2 a = new Employee2(\u0026#34;ali\u0026#34;, 1200); System.out.println(\u0026#34;before salary = \u0026#34; + a.getSalary()); raiseSalary(a); System.out.println(\u0026#34;after salary of a = \u0026#34; + a.getSalary()); } } class Employee2 { private String name; private int salary; public Employee2(String name, int salary) { this.name = name; this.salary = salary; } public String getName() { return name; } public int getSalary() { return salary; } void raiseSalary(int multiple) { this.salary = salary * multiple; } } /* output: before salary = 1200 after salary of o = 3600 after salary of a = 3600 *///:~   方法执行时，o被初始化为a值的拷贝，其中a的值为对象的引用；raiseSalary方法作用与o和a同时引用的那个对象；方法结束后，o对象不再使用，结果是a对象的薪水涨至原来3倍。\n既然如此，那是否可以将基本类型参数转化为其包装类型呢，这样就可以实现小节1中的期望了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // doesn\u0026#39;t work class ByValue { static void tripleValue(Integer x) { x = 3 * x; System.out.println(\u0026#34;x = \u0026#34; + x); } public static void main(String[] args) { Integer y = 10; tripleValue(y); System.out.println(\u0026#34;y = \u0026#34; + y); } } /* output: x = 30 y = 10 *///:~   非常遗憾，也失败了。这是因为**包装器类型是final**的，其value域(包装类型的值)也是final的。\n上例中的的测试是存在问题的，当使用Integer y = 10;初始化y时，Java会将y自动拆箱为int；\n 同样地，x = 3 * x;对Integer类型作操作符运算也会拆箱。  3.2.2 引用不可变  一个方法不能让对象参数引用一个新的对象\n 当试图去交换两个对象引用的值时，参考如下代码Employee2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  // 继续使用上例中的Employee2 public class ByRef { // doesn\u0026#39;t work  static void swap(Employee2 j, Employee2 k){ System.out.println(\u0026#34;before swap j.name = \u0026#34; + j.getName()); System.out.println(\u0026#34;before swap k.name = \u0026#34; + k.getName()); Employee2 temp = j; j = k; k = temp; System.out.println(\u0026#34;after swap j.name = \u0026#34; + j.getName()); System.out.println(\u0026#34;after swap k.name = \u0026#34; + k.getName()); } public static void main(String[] args) { Employee2 a = new Employee2(\u0026#34;ali\u0026#34;, 1200); Employee2 b = new Employee2(\u0026#34;bad\u0026#34;, 1300); swap(a,b); System.out.println(\u0026#34;after swap a.name = \u0026#34; + a.getName()); System.out.println(\u0026#34;after swap b.name = \u0026#34; + b.getName()); } } /* output: before swap j.name = ali before swap k.name = bad after swap j.name = bad after swap k.name = ali after swap a.name = ali after swap b.name = bad *///:~   方法执行时，j和k分别是a和b值的拷贝，也就是说j和k分别是a和b的对象引用，swap方法交换了这两个拷贝，但是方法结束后，j和k不再使用，而a和b还是指向方法调用前所指向的对象。\n也就是说，对于对象参数，对象参数的引用也是按值传递的。\n 如何理解这句话？\n  引用数据类型的参数传递实际上是对象的一个引用（按引用传递）\n  被传递的这个引用本身是值传递性质（引用无法被方法更改）\n  ","description":"Java语言的参数传递总是按值调用的。","id":40,"section":"posts","tags":[""],"title":"传值还是传引用","uri":"http://wangy325.top/zh/posts/java/basic/%E4%BC%A0%E5%80%BC%E8%BF%98%E6%98%AF%E4%BC%A0%E5%BC%95%E7%94%A8/"},{"content":"static关键字意为“静态的”，其语义可以理解为“类的对象”(不要理解为Class对象)，即不需要对象实例，可以直接通过类名.字段名的形式直接访问。\n2.1 静态域 如果将一个域定义为static，那么每个类中都只有一个这样的域。参考如下例子：\n1 2 3 4 5  class Employee{ private static int nextId = 1; private int id; ... }   每一个Employee都有自己的一个id域，但是这个类的所有实例都共享一个nextId域。记住，即使没有Employee实例，静态域nextId也存在，它属于类而不属于任何对象。static域只在类加载的时候初始化一次，并且是先于非static域初始化的。\n以下是一个简单的static关键字使用示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  class Employee { static int nextId = 0; private int id; private String name; private int salary; public Employee(String name, int salary) { this.name = name; this.salary = salary; } public void setId() { this.id = nextId; nextId++; } public static int getNextId() { return nextId; } // ...get() } public class TestStatic { public static void main(String[] args) { Employee[] x = new Employee[3]; x[0] = new Employee(\u0026#34;alex\u0026#34;, 5000); x[1] = new Employee(\u0026#34;bob\u0026#34;, 6000); x[2] = new Employee(\u0026#34;cup\u0026#34;, 7000); for (Employee e : x) { e.setId(); System.out.println(\u0026#34;id = \u0026#34; + e.getId() + \u0026#34; name = \u0026#34; + e.getName() + \u0026#34; salary = \u0026#34; + e.getSalary()); } System.out.println(\u0026#34;the nextId is: \u0026#34; + Employee.getNextId()); } } /* output: id = 0 name = alex salary = 5000 id = 1 name = bob salary = 6000 id = 2 name = cup salary = 7000 the nextId is: 3 *///:~   2.2 静态常量 使用static final修饰的域可以作为静态常量，静态常量一般被声明为public,通常作为工具包的常量被其他类使用，如Math.PI。\n2.3 静态方法 使用static修饰的方法被称为静态方法，和静态常量一样，通常被声明为public，供其他类通过类名直接调用，如Math.pow(x,a)用于计算xa。静态方法不能访问对象域，因为其不能操作对象，但是其可以访问类的静态域。\n尽管可以通过对象实例来调用类的静态方法，但是不推荐如此做，编译器也会提示应该使用类调用静态方法，因为对象尽管可以调用静态方法，但是往往静态方法的返回与对象无关（静态方法只能操作静态域，而不能操作对象属性），反而会造成混淆。\nJava对于static的语义可以理解为：\n 属于类但是不属于对象的字段和方法\n 2.4 工厂方法 也是一种静态方法，不过其用来构造对象，因此被称为静态工厂方法，例如NumberFormat.getCurrencyInstance()就是一个利用工厂方法获取对象的例子。\n","description":"本文介绍java的static关键字。","id":41,"section":"posts","tags":["static"],"title":"static关键字","uri":"http://wangy325.top/zh/posts/java/basic/static%E5%85%B3%E9%94%AE%E5%AD%97/"},{"content":" 本系列内容主要来自TIJ，Java核心技术卷以及Java SE 8 API\n 1.1 包访问权限  当前包中的所有其他类对该包内的某个类的成员具有访问权限，但这并不意味着能够访问到。是否访问到还要取决于类的成员的修饰符。若类的成员也是包访问权限或者public，那才能够访问到； 当前包中的所有类对这个包之外的所有非public权限的类没有访问权限； 类控制着哪些代码能够访问自己的成员，具体能否访问还需要看成员的权限。  1.2 接口访问权限 \u0026ndash;public  使用public，意味着public之后声明的成员对每个人都是可用的。  1.3 你无法访问 \u0026ndash;private  使用private，意味着除了包含该成员的类之外，其他任何类都无法访问这个成员； 私有构造器可以阻止继承。  1.4 继承访问 \u0026ndash;protected   protected也提供包访问权限，也就是说同一包内的其他类可以访问protected修饰的元素；\n  protected实际上处理的是继承的概念，试看如下例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  // base class Cookie in package access.dessert package access.dessert; public class Cookie{ public Cookie(){ System.out.print(\u0026#34;Cookie constructor\u0026#34;); } void bite(){System.out.print(\u0026#34;bite\u0026#34;)}; } // sub-class ChocolateChip in package access package access; import access.dessert.*; public class ChocolateChip extends Cookie{ public ChocolateChip(){ System.out.print(\u0026#34;ChocolateChip constructor\u0026#34;); } public void chomp(){ // bite(); // can\u0026#39;t access  } public void static void main(String[] args){ ChocolateChip x = new ChocolateChip(); x.chomp; } } /* output: Cookie constructor ChocolateChip constructor *///:~   继承了Cookie的ChocolateChip不和父类在同一个包下，尽管bite()具有包访问权限，ChocolateChip也无法访问bite()方法，一个可能的办法是将bite()修改为public，但是这样并不是很合适，所以我们可以使用propected来修饰bite()方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  // base class Cookie in package access.dessert package access.dessert; public class Cookie{ public Cookie(){ System.out.print(\u0026#34;Cookie constructor\u0026#34;); } protected void bite(){System.out.print(\u0026#34;bite\u0026#34;)}; } // sub-class ChocolateChip in package access package access; import access.dessert.*; public class ChocolateChip2 extends Cookie2{ public ChocolateChip2(){ System.out.print(\u0026#34;ChocolateChip2 constructor\u0026#34;); } public void chomp(){ bite(); } public void static void main(String[] args){ ChocolateChip2 x = new ChocolateChip2(); x.chomp; } } /* output: Cookie constructor ChocolateChip2 constructor bite *///:~   protected 保护了继承的访问权限。\n ","description":"最易忽视的Java基础。","id":42,"section":"posts","tags":null,"title":"访问权限修饰符","uri":"http://wangy325.top/zh/posts/java/basic/%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%E4%BF%AE%E9%A5%B0%E7%AC%A6/"},{"content":"有一个cd接口，其实体类用于播放歌曲，同时我们想在播放歌曲的时候记录每个曲目的播放次数。看起来，记录次数这个事和播放曲目是不相干的事情，当然，我们可以在每首歌曲播放完成之后记录，但是更好的办法是使用一个切面，切入到播放方法中，来完成这件事，这样可以减少无关逻辑对代码的侵入。\n此程序分别使用了基于@Aspect注解和基于XML配置文件2种方式进行了切面注入，2种方式效果是等同的。\n此程序使用的是Spring AOP，并没有使用功能更加丰富的AspectJ，Spring AOP很大部分借鉴了AspectJ，如果只是简单的方法层面的织入，那么Spring AOP就能够满足需求。如果需要构造器或者属性拦截，或者需要为spring bean引入新方法，那么就需要使用AspectJ了。\n1 开始 从start.spring.io下载空项目，引入Spring AOP依赖：\n1 2 3 4  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;   2 配置 2.1 基于JavaBean+注解的配置 2.1.1 注入Bean 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  @Configuration @Profile(\u0026#34;jc\u0026#34;) public class DiskConfig { @Bean(\u0026#34;jcd\u0026#34;) public CompactDisk saveRock() { BlankDisk cd = new BlankDisk(); cd.setArtist(\u0026#34;Fall Out Boy\u0026#34;); cd.setTitle(\u0026#34;Save Rock And Roll\u0026#34;); List\u0026lt;String\u0026gt; tracks = new ArrayList\u0026lt;\u0026gt;(); tracks.add(\u0026#34;The Phoenix\u0026#34;); tracks.add(\u0026#34;My Songs Know What You Did In the Dark (Light Em Up)\u0026#34;); tracks.add(\u0026#34;Alone Together\u0026#34;); tracks.add(\u0026#34;Where Did the Party Go\u0026#34;); tracks.add(\u0026#34;Just One Yesterday (feat. Foxes)\u0026#34;); tracks.add(\u0026#34;The Mighty Fall (feat. Big Sean)\u0026#34;); tracks.add(\u0026#34;Missing You\u0026#34;); tracks.add(\u0026#34;Death Valley\u0026#34;); cd.setTracks(tracks); return cd; } @Bean(\u0026#34;jtc\u0026#34;) public TrackCounter trackCounter() { return new TrackCounter(); } }   2.1.2 创建切面 使用注解@Aspect可以将一个Bean声明为切面：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  @Aspect @Slf4j public class TrackCounter { private Map\u0026lt;Integer, Integer\u0026gt; trackCounts = new HashMap\u0026lt;\u0026gt;(); public int getPlayCount(int trackNumber) { return trackCounts.getOrDefault(trackNumber, 0); } @Pointcut(\u0026#34;execution( * com.wangy.aop.disk.BlankDisk.playTrack(..)) \u0026amp;\u0026amp; args(trackNumber)\u0026#34;) public void pc1(int trackNumber){ } @Pointcut(\u0026#34;execution(* com.wangy.aop.disk.BlankDisk.playTrack(int))\u0026#34;) public void pc2(){} @Before(value = \u0026#34;pc2()\u0026#34;) public void init(){ // do something  log.info(\u0026#34;start playing\u0026#34;); } @AfterReturning(value = \u0026#34;pc1(trackNumber)\u0026#34;) public void countTrack(int trackNumber) { log.info(\u0026#34;Track {} played\u0026#34;, trackNumber); trackCounts.put(trackNumber, getPlayCount(trackNumber) + 1); } @AfterThrowing(value = \u0026#34;pc1(trackNumber)\u0026#34;) public void skipTrack(int trackNumber) { log.info(\u0026#34;track {} skipped\u0026#34;, trackNumber); } @After(value = \u0026#34;pc2()\u0026#34;) public void after(){ // do something  } @Around(value = \u0026#34;pc1(trackNumber)\u0026#34;) public void aroundTest(ProceedingJoinPoint jp, int trackNumber) throws Throwable { int pl = 2; // do some judgement  if (getPlayCount(trackNumber) \u0026gt; pl) { log.info(\u0026#34;track {} has been played more than twice, skip this track\u0026#34;, trackNumber); // change the behavior of pointcut method  CompactDisk target = (CompactDisk) jp.getTarget(); target.playTrack(-1); }else{ jp.proceed(); } } }   使用@Aspect注解将TrackCounter bean声明为一个切面，同时使用@Pointcut注解声明切点，再使用对应的通知注解声明通知\n @Before @After @AfterReturning @AfterThrowing @Around  若使用xml配置切面，那么TrackCounter类看起来和普通的java bean没有差别，稍后会在xml配置文件中将其配置为一个切面\n注意上面的切面表达式：\n1  execution( * com.wangy.aop.disk.BlankDisk.playTrack(int)) \u0026amp;\u0026amp; args(trackNumber)   前半部分是常见的切面表达式，用于指定切入点；\n 第一个 * 指示任意返回类型 使用全限定名指定类和方法名，括号内的int指定参数列表，可以使用(..)来匹配任意参数  更多关于切入点表达式的内容：\n https://www.cnblogs.com/liaojie970/p/7883687.html https://howtodoinjava.com/spring-aop/aspectj-pointcut-expressions/ https://www.baeldung.com/spring-aop-pointcut-tutorial  \u0026amp;\u0026amp;连接符后面的内容是什么意思？\n这里需要提及的是， Spring AOP支持AspectJ切点指示器的子集，除了最常用的execution()指示器之外，还有其他的指示器：\n   AspectJ指示器 描述     args() 限制连接点匹配参数为指定类型的执行方法   @args() 限制连接点匹配参数由指定注解标注的执行方法   execution() 用于匹配是连接点的执行方法   this() 限制连接点匹配AOP代理的bean引用为指定类型的类   target 限制连接点匹配目标对象为指定类型的类   @target() 限制连接点匹配特定的执行对象，这些对象对应的类需要有指定类型的注解   within() 限制连接点匹配指定的类型   @within() 限制连接点匹配指定注解所标注的类型（当使用Spring AOP时，方法定义在由指定的注解所标注的类里）   @annotation 限制匹配带有指定注解的连接点    这里的arg(trackNumber)限定符，表明传递给连接点（切入点）playTrack(int)的int类型参数也会传递到通知中去。\n 关于args()条件的作用，sping官方文档有说明：\nhttps://docs.spring.io/spring-framework/docs/current/reference/html/core.html#aop-ataspectj-advice-params\n需要注意到启动类中使用了@EnableAspectJAutoProxy注解，\n这意味着开启AspectJ自动代理，使得Spring框架拥有AOP能力：\n 1 2 3 4 5 6 7  @SpringBootApplication @EnableAspectJAutoProxy public class AopApplication { public static void main(String[] args) { SpringApplication.run(AopApplication.class, args); } }   2.2 基于xml文件的配置 xml配置如下1：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  \u0026lt;beans profile=\u0026#34;xc\u0026#34;\u0026gt; \u0026lt;aop:aspectj-autoproxy/\u0026gt; \u0026lt;bean id=\u0026#34;xtrackCounter\u0026#34; class=\u0026#34;com.wangy.aop.TrackCounter\u0026#34; name=\u0026#34;xtc\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;xcd\u0026#34; class=\u0026#34;com.wangy.aop.disk.BlankDisk\u0026#34; name=\u0026#34;xcd\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;title\u0026#34; value=\u0026#34;Save Rock And Roll\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;artist\u0026#34; value=\u0026#34;Fall Out Boy\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;tracks\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;The Phoenix\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;My Songs Know What You Did In the Dark (Light Em Up)\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Alone Together\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Where Did the Party Go\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Just One Yesterday (feat. Foxes)\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;The Mighty Fall (feat. Big Sean)\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Missing You\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;Death Valley\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;aop:config\u0026gt; \u0026lt;aop:aspect ref=\u0026#34;xtrackCounter\u0026#34;\u0026gt; \u0026lt;aop:pointcut id=\u0026#34;tc\u0026#34; expression=\u0026#34;execution(* com.wangy.aop.disk.BlankDisk.playTrack(int)) and args(trackNumber))\u0026#34;/\u0026gt; \u0026lt;aop:after-returning pointcut-ref=\u0026#34;tc\u0026#34; method=\u0026#34;countTrack\u0026#34;/\u0026gt; \u0026lt;aop:around method=\u0026#34;aroundTest\u0026#34; pointcut-ref=\u0026#34;tc\u0026#34;/\u0026gt; \u0026lt;/aop:aspect\u0026gt; \u0026lt;/aop:config\u0026gt; \u0026lt;/beans\u0026gt;   对应前文中的JavaBean配置中使用的profile，在xml中将所有的配置声明为一个叫\u0026rsquo;xc\u0026rsquo;的profile。\n3 测试 测试包中提供了2个测试类，分别用于测试基于JavaBean+注解、基于xml文件的aop配置；\n [TrackCounterTest]用于测试基于javaBean和注解实现的aop，这是推荐的方式 [TrackCountTestWithXml]用于测试基于xml配置的aop，在运行此测试时，需要注释掉TrackCount类上的@Aspect注解，以免Application Context注入2个切面  以下是使用xml配置的测试样例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  @SpringBootTest @SpringJUnitConfig(locations = {\u0026#34;classpath:spring-aop.xml\u0026#34;}) @ActiveProfiles(\u0026#34;xc\u0026#34;) public class TrackCountTestWithXml { @Autowired private CompactDisk cd; @Autowired private TrackCounter tc; @Test public void testTc() { cd.playTrack(1); cd.playTrack(1); cd.playTrack(1); cd.playTrack(2); cd.playTrack(4); cd.playTrack(4); cd.playTrack(6); cd.playTrack(6); cd.playTrack(6); try { cd.playTrack(6); } catch (Exception e) { //ignore  } assertEquals(3, tc.getPlayCount(1)); assertEquals(1, tc.getPlayCount(2)); assertEquals(0, tc.getPlayCount(3)); assertEquals(2, tc.getPlayCount(4)); assertEquals(0, tc.getPlayCount(5)); assertEquals(3, tc.getPlayCount(6)); } }   4 参考   demo地址：https://github.com/wangy325/simple_springboot_aop_demo\n  切入点表达式使用总结：https://www.cnblogs.com/zhangxufeng/p/9160869.html\n   xml配置并未使用TrackCounter中的全部通知 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文是SpringBoot基于JavaBean和xml配置的aop应用实践。","id":43,"section":"posts","tags":["AOP"],"title":"SpringBoot使用AOP的简单示例","uri":"http://wangy325.top/zh/posts/java/spring/springboot-aop-demo/"},{"content":"本文简单记录了2个在安装单机版fdfs服务遇到的问题，虽然报错信息不同，但是问题出在同一个地方：\n nginx版本与ngx_http_fastdfs_module版本\nnginx版本1.16.1\nmodule版本1.20\n 这个版本的混用会导致编译和配置时分别遇到致命错误\n  nginx1.12编译出现 /usr/include/fastdfs/fdfs_define.h:15:27: fatal error: common_define.h: No such file or directory\n  按照1法解决编译问题之后，紧接着会出现配置文件错误 unknown directive \u0026quot;ngx_http_fastdfs_module\u0026quot;，个人推测虽然在解决第一个问题（通过修改fdfs_module的配置文件使得编译通过）时，nginx的模块实际上没有安装成功\n  模块安装成功的标志是\n [root@shell ~]# nginx -V nginx version: nginx/1.12.1 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) configure arguments: --add-module=/opt/fdfs/fastdfs-nginx-module-revise/src   最后使用nginx-1.12.0以及\n# 这里为啥这么长一串呢，因为最新版的master与当前nginx有些版本问题 # wget https://github.com/happyfish100/fastdfs-nginx-module/archive/5e5f3566bbfa57418b5506aaefbe107a42c9fcb1.zip # 解压 # unzip 5e5f3566bbfa57418b5506aaefbe107a42c9fcb1.zip # 重命名 # mv fastdfs-nginx-module-5e5f3566bbfa57418b5506aaefbe107a42c9fcb1 fastdfs-nginx-module-master 解决问题：\ncentOS上安装nginx有2种方式1\n 通过包管理器（yum命令）安装（未测试） 通过源码安装  这里说一下通过源码安装的几个点：\n  网络上的其他教程说的比较细致了，几个依赖一定要先安装\nyum install gcc-c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel   如果./configure命令后面不接任何参数的话，nginx默认安装在/usr/local/nginx下，以及nginx启动需要的作用资源均在此目录下\n[root@shell nginx-1.12.1]# ./configure --help --help print this message --prefix=PATH set installation prefix --sbin-path=PATH set nginx binary pathname --modules-path=PATH set modules path --conf-path=PATH set nginx.conf pathname --error-log-path=PATH set error log pathname --pid-path=PATH set nginx.pid pathname --lock-path=PATH set nginx.lock pathname ...省略内容 ... 如上可以自定义编译nginx的参数，这也是能为nginx添加ngx_http_fastdfs_modul模块的原因。\n题外：如果安装过程完全参照这篇文章的话，或许就不会有这个问题了\n   使用nginx官网推荐的方式安装最方便 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文记录了安装fdfs单机文件服务时，遇到的问题，主要是nginx的配置上。","id":44,"section":"posts","tags":[""],"title":"安装单机版fdfs服务遇到的问题","uri":"http://wangy325.top/zh/posts/java/sql/%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88fdfs%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"在使用jenkins自动构建node.js项目的时候，由于对forever的不熟悉，构建脚本一直存在一点小问题。\n现在简单记录下整个node环境搭建以及部署的流程。\n1. node环境的安装 最简单的方法是直接使用node已经编译好的可执行文件, 解压之后，将可执行文件链接到$PATH中：\nwget https://nodejs.org/dist/v10.16.3/node-v10.16.3-linux-x64.tar.xz # unarchive file to /usr/local tar -xf node-v10.16.3-linux-x64.tar.xz -C /usr/local # create link, so you can run node everywhere ln -sf /usr/local/node-v10.16.3-linux-x64/bin/node /usr/bin ln -sf /usr/local/node-v10.16.3-linux-x64/bin/npm /usr/bin # check whether node install successful node 10.16.3 2. 安装forever 1 2  npm install forever -g ln -sf /usr/local/node-v10.16.3-linux-x64/bin/forever /usr/bin   说明：直接全局安装forever之后，运行forever会出现command not found错误，同上，执行ln ..就可以了。\n3. 使用forever启动脚本 1  forever start -l /locate/of/log/alog.log -a /locate/of/startScript/satrt.js   上述命令可以使用相对路径。\n启动成功后，我们看一下后台进程和forever的list：\n1 2 3 4 5 6 7 8 9  ps aux | grep node root 25573 0.0 0.9 571244 35412 ? Ssl 15:50 0:00 /usr/local/node-v10.15.3-linux x64/bin/node /usr/local/node-v10.15.3-linux-x64/lib/node_modules/forever/bin/monitor ./bin/dev.js root 25580 0.0 0.8 604868 34252 ? Sl 15:50 0:01 /usr/local/node-v10.15.3-linux-x64/bin/node /opt/webManager/bin/dev.js root 26236 0.0 0.0 112708 984 pts/1 S+ 17:43 0:00 grep --color=auto node forever list info: Forever processes running data: uid command script forever pid id logfile uptime data: [0] UNdQ /*/node bin/dev.js 25573 25580 /*/a.log 0:2:18:18   可以看到一个node进程和一个monitor进程。\n我们在重新构建的时候，一般会选择杀掉服务进程，然后重启服务。此时，面对2个进程，只杀掉一个进程，是不行的。\n 如果单独杀掉monitor进程，node进程还在，也就是说项目并没有停止运行，此时，如果再次使用forever启动，脚本也不会启动。此时，forever list显示的uptime 为 STOPED 如果单独杀掉node进程， forever monitor会自动重新启动脚本  因此，在重新构建时，应该杀掉monitor和node两个进程。\nEDIT：或者可以直接使用forever安全停止脚本\n1  forever stop 0   ","description":"node.js的安装以及forever脚本的使用。","id":45,"section":"posts","tags":["forever"],"title":"关于forever启动node服务的问题","uri":"http://wangy325.top/zh/posts/js/%E5%85%B3%E4%BA%8Eforever%E5%90%AF%E5%8A%A8node%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"在使用匿名内部类比较器的时候，idea提供了几个层次的比较器代码优化，给👴整懵逼了。\nHere is the original code:\n1 2 3 4 5 6 7 8 9 10 11 12 13  // sort by time barList.sort(new Comparator\u0026lt;MarketDataBar\u0026gt;() { @Override public int compare(MarketDataBar o1, MarketDataBar o2) { if (o1.getTime().getTime() \u0026gt; o2.getTime().getTime()) { return 1; } if (o1.getTime().getTime() \u0026lt; o2.getTime().getTime()) { return -1; } return 0; } });   Firstly, we could use Long.compare() to replace the if statement, it looks like:\n1 2 3 4 5 6 7  // sort by time barList.sort(new Comparator\u0026lt;MarketDataBar\u0026gt;() { @Override public int compare(MarketDataBar o1, MarketDataBar o2) { return Long.compare(o1.getTime().getTime(), o2.getTime().getTime()); } });   So far, the code is much simplified then before.\nBut also, we coulde use lamda replace anonymous innner class, after doing that, it looks like:\n1 2  // sort by time barList.sort((o1, o2) -\u0026gt; Long.compare(o1.getTime().getTime(), o2.getTime().getTime()));   though we used lambda, we could replace the comparator with Comparator.comparingLong:\n1 2  // sort by time barList.sort(Comparator.comparingLong(o -\u0026gt; o.getTime().getTime()));   this is the ultimate version of a comparator, a \u0026lsquo;one line compartor\u0026rsquo;.\n","description":"Java8对Comparable和Comparator接口的方法提供了Lambda表达式支持，同时接口新增了默认方法，可以简化操作。","id":46,"section":"posts","tags":["lambda"],"title":"比较器的「退化」","uri":"http://wangy325.top/zh/posts/java/basic/%E6%AF%94%E8%BE%83%E5%99%A8%E7%9A%84%E9%80%80%E5%8C%96/"},{"content":"文章介绍了在centOS7上安装mysql数据库服务的配置及简单优化过程。在服务器上安装mysql服务网络上能够找到的资源很多了，因此本文没有作详细介绍，本文的重点在于后续的优化配置方面。\n安装MySQL  在centOS上安装mysql 5.7-juejin 通过yum命令安装并进行初始化设置-dev.mysql.com  配置 mysql的配置文件在/etc/my.cnf， 只是简单地配置了数据库编码为utf8；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  ### my.cnf配置内容 # For advice on how to change settings please see # http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html [client] default-character-set=utf8 [mysql] default-character-set=utf8 [mysqld] collation-server = utf8_unicode_ci collation-server = utf8_bin collation-server = utf8_general_ci init-connect=\u0026#39;SET NAMES utf8\u0026#39; character-set-server = utf8 default-storage-engine = INNODB datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock   mysql有默认配置账户以及测试数据库， root账户也会默认分配密码， 安装指引链接2官方文档中说明了默认账户密码:\n1） 在 /var/log/mysqld.log中记录了mysql root账户的默认密码\n1 2 3  [root@simple ~] cat /var/log/mysqld.log | grep -i \u0026#39;temporary password\u0026#39; # 2019-10-15T07:08:33.627866Z 1 [Note] A temporary password is generated for # root@localhost: I6cpDa!wj.6\u0026amp;   2） 可以使用mysql_secure_installation命令进行初始化设置，程序会询问一些默认设置，包括重置密码，删除匿名账户，禁止root远程登录等等配置\n1 2  [root@simple ~] mysql_secure_installation ...   还可以通过set password或者mysqladmin修改密码:\n  SET PASSWORD FOR 'username'@'scope' = PASSWORD('newpasswd')  mysqladmin -uroot -poldpass password newpass;   其他的配置 比如设置数据库时间为服务器时间(默认为UTC时间)并没有成功  账户与权限 前已述及，mysql默认配置root账户，并且已经只能本地登录(出于安全考虑)，并且不建议使用root账户进行数据库连接；\n因此，需要新账户，并且要控制账户权限，防止一些不可预见的错误出现；\n同时，账户创建之后需赋予适当的权限；\n账户 使用以下命令创建账户:\n1  create user username@\u0026#39;scope\u0026#39; IDENTIFIED BY \u0026#39;passwd@\u0026#39;;   关于账户说明\n  mysql 5.7加入了validate_password机制，该机制迫使用户使用[强密码]\u0026ndash;至少8位，且至少包含一个大写字母，一个小写字母，一个数字，一个特殊符号；若想关闭此功能，可在my.cnf中的[mysqld]栏下配置validate_password=Off；\n  scope项指定用户可以从哪里登录，一般localhost只允许本地(或ssh登录)，%允许任意ip位置登录，\n  权限 mysql的权限可以简单介绍为:\n   权限 描述     全局权限 privilege for all schemas； 信息保存在mysql.user表中   schema权限 privilege for all tables； 信息保存在mysql.db中   table权限 privilege for all columns； 信息保存在mysql.tables_priv中   column权限 privilege for column；信息保存在mysql.columns_priv中   子程序权限 ?    权限的细致说明以及，各类权限所保存的表，可参考:\n MySQL 查看用户授予的权限 Privileges Provided by MySQL Grant Tables  最简单的查看用户权限的方法\n1 2 3 4 5 6 7 8 9 10 11  show grants for user; show grants for user@\u0026#39;localhost\u0026#39;; # 查看root的权限 mysql\u0026gt; show grants for root@\u0026#39;localhost\u0026#39;; +---------------------------------------------------------------------+ | Grants for root@localhost | +---------------------------------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | | GRANT PROXY ON \u0026#39;\u0026#39;@\u0026#39;\u0026#39; TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION | +---------------------------------------------------------------------+ 2 rows in set (0.00 sec)   从上面可以看出，root有[*.*的所有权限]，至于*.*，代表了ALLDB.ALLTABLES-即所有数据库的所有表，这是最高权限。\n或者，可以通过查询mysql.user表来获取权限信息\n1 2 3 4 5 6 7 8 9  select * from mysql.user where user=\u0026#39;root\u0026#39;\\G; *************************** 1. row *************************** Host: localhost User: root Select_priv: Y Insert_priv: Y Update_priv: Y Delete_priv: Y # ignore others   给用户授予权限 假设我们创建了一个用户test，并且没有授予任何权限，name，这个用户的权限是这样的；\n1 2 3 4 5 6 7  mysql\u0026gt; show grants for test; +---------------------------------------+ | Grants for hc_future@% | +---------------------------------------+ | GRANT USAGE ON *.* TO \u0026#39;hc_future\u0026#39;@\u0026#39;%\u0026#39; | +---------------------------------------+ 1 row in set (0.00 sec)   可以看到，实际上test并没有任何权限；\n1 2 3 4 5 6 7 8 9  mysql\u0026gt; select * from user where user=\u0026#39;test\u0026#39;\\G; *************************** 1. row *************************** Host: % User: hc_future Select_priv: N Insert_priv: N Update_priv: N Delete_priv: N *************************** 1. row ***************************   尝试使用该账户对mysql进行任何操作都会得到一个错误信息：\n1  [42000][1044] Access denied for user \u0026#39;hc_future\u0026#39;@\u0026#39;%\u0026#39; to database \u0026#39;test\u0026#39;   显然，我们应该给用户授予部分权限，已让其完成操作，mysql使用grant来给用户授予权限\n若我想给test授予全局select，update权限:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  mysql\u0026gt; grant select， update on *.* to test@\u0026#39;%\u0026#39; identified by \u0026#39;testT123!@#\u0026#39;; Query OK， 0 rows affected， 1 warning (0.00 sec) mysql\u0026gt; show grants for test; +------------------------------------------------+ | Grants for test@% | +------------------------------------------------+ | GRANT SELECT， UPDATE ON *.* TO \u0026#39;test\u0026#39;@\u0026#39;%\u0026#39; | +------------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from user where user =\u0026#39;test\u0026#39;\\G; *************************** 1. row *************************** Host: % User: hc_future Select_priv: Y Insert_priv: N Update_priv: Y Delete_priv: N Create_priv: N # ignore others   mysql 5.7.28中， 如果grant命令执行的用户没有被创建，会默认创建该用户\n更多关于grant的使用，参考官方文档GRANT Syntax\n数据备份与导入 主要使用mysqldump和source来进行数据库的备份和恢复\n数据库的备份主要分为结构和数据的备份，备份为x.sql形式的文件\n从备份的结果来看，\n 备份结构主要生成create table语句 备份数据生成insert into语句  除此之外，备份的范围可从库到表之间多级变化， 总言之， mysqldump满足绝大多数备份需求；\n需要说明的是，若数据库中有视图，则需要谨慎行事了， 因为视图中存在一些对原数据库表的引用以及对执行用户的DEFINER， 若恢复的数据库和备份的数据库名字以及用户一致，则不会存在问题，否则可能会出现找不到表的错误\n而数据库的恢复则简单了，source x.sql即可\n更多关于数据库备份恢复的细节，查看: mysqldump 导入/导出 结构\u0026amp;数据\u0026amp;存储过程\u0026amp;函数\u0026amp;事件\u0026amp;触发器\n使用SSL加密连接 在jdbc连接数据库的过程中可能会出现这样的警告:\n Establishing SSL connection without server\u0026rsquo;s identity verification is not recommended.\nAccording to MySQL 5.5.45+， 5.6.26+ and 5.7.6+ requirements SSL connection must be\nestablished by default if explicit option isn\u0026rsquo;t set. For compliance with existing applications\nnot using SSL the verifyServerCertificate property is set to \u0026lsquo;false\u0026rsquo;. You need either to\nexplicitly disable SSL by setting useSSL=false， or set useSSL=true and provide\ntruststore for server certificate verification.\n 有时候，设置useSSL=true又会遇到这样的错误:\n1 2 3 4 5 6 7 8  Caused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1946) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:316) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:310) ... 67 more   上述错误的大意是没找到ssl证书， 那么问题出在了mysql配置服务端或者客户端的配置上\n由于mysql 5.7以上默认开启了ssl，验证一下\n查看mysql SSL状态信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  # 使用root账户登录 mysql -u root -p # 查看ssl信息 # Server version: 5.7.28 MySQL Community Server (GPL) mysql\u0026gt; show global variables like \u0026#39;%ssl%\u0026#39;; +---------------+-----------------+ | Variable_name | Value | +---------------+-----------------+ | have_openssl | YES | | have_ssl | YES | | ssl_ca | ca.pem | | ssl_capath | | | ssl_cert | server-cert.pem | | ssl_cipher | | | ssl_crl | | | ssl_crlpath | | | ssl_key | server-key.pem | +---------------+-----------------+ 9 rows in set (0.00 sec) #have_ssl = YES， 说明ssl已经启用 #查看当前用户的连接信息 mysql\u0026gt; \\s; -------------- mysql Ver 14.14 Distrib 5.7.28， for Linux (x86_64) using EditLine wrapper Connection id:\t157 Current database: Current user:\troot@localhost SSL:\tNot in use Current pager:\tstdout Using outfile:\t\u0026#39;\u0026#39; Using delimiter:\t; Server version:\t5.7.28 MySQL Community Server (GPL) Protocol version:\t10 Connection:\tLocalhost via UNIX socket Server characterset:\tutf8 Db characterset:\tutf8 Client characterset:\tutf8 Conn. characterset:\tutf8 UNIX socket:\t/var/lib/mysql/mysql.sock Uptime:\t23 hours 21 min 57 sec Threads: 5 Questions: 10325 Slow queries: 0 Opens: 5061 Flush tables: 1 Open tables: 1543 Queries per second avg: 0.122 --------------  ERROR: No query specified #SSL=Not in use 说明没有使用ssl连接   结果显示， mysql 5.7.28已经启用了ssl，并且可以不使用ssl登录\n根据上面的错误， jdbc连接错误的原因是由于证书错误， 做个测试:\n1 2 3  [root@iZbp17pma26sz5vqqwb1v3Z ~]# mysql -u root -p --ssl-ca= Enter password: ERROR 2026 (HY000): SSL connection error: SSL_CTX_set_default_verify_paths failed   当使用SSL登录而不指定证书的时候我们无法登录\n 如果你的mysql没有开启SSL，当使用mysql -u root -p --ssl登录的时候，会得到如下错误:\nERROR 2026(HY000): SSL connection error: SSL is required but the server doesn't support it\n 配置SSL安全连接 那么， mysql的证书在哪里? 可能根据安装方式不同， 配置文件路径不一样， 使用yum源安装mysql时，实际上可以在var/lib/mysql里找到mysql的证书文件:\n1 2 3 4 5 6 7 8 9  [root@sample ~]# ll /var/lib/mysql/*.pem -rw------- 1 mysql mysql 1676 Oct 15 15:08 /var/lib/mysql/ca-key.pem -rw-r--r-- 1 mysql mysql 1112 Oct 15 15:08 /var/lib/mysql/ca.pem -rw-r--r-- 1 mysql mysql 1112 Oct 15 15:08 /var/lib/mysql/client-cert.pem -rw------- 1 mysql mysql 1680 Oct 15 15:08 /var/lib/mysql/client-key.pem -rw------- 1 mysql mysql 1680 Oct 15 15:08 /var/lib/mysql/private_key.pem -rw-r--r-- 1 mysql mysql 452 Oct 15 15:08 /var/lib/mysql/public_key.pem -rw-r--r-- 1 mysql mysql 1112 Oct 15 15:08 /var/lib/mysql/server-cert.pem -rw------- 1 mysql mysql 1680 Oct 15 15:08 /var/lib/mysql/server-key.pem   我们指定证书试试看:\n1 2 3 4 5  [root@sample ~]# mysql -u root -p --ssl-ca=/var/lib/mysql/ca.pem Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 161 Server version: 5.7.28 MySQL Community Server (GPL)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  mysql\u0026gt; \\s; -------------- mysql Ver 14.14 Distrib 5.7.28， for Linux (x86_64) using EditLine wrapper Connection id:\t161 Current database: Current user:\troot@localhost **SSL:\tCipher in use is ECDHE-RSA-AES128-GCM-SHA256** Current pager:\tstdout Using outfile:\t\u0026#39;\u0026#39; Using delimiter:\t; Server version:\t5.7.28 MySQL Community Server (GPL) Protocol version:\t10 Connection:\tLocalhost via UNIX socket Server characterset:\tutf8 Db characterset:\tutf8 Client characterset:\tutf8 Conn. characterset:\tutf8 UNIX socket:\t/var/lib/mysql/mysql.sock Uptime:\t1 day 14 min 19 sec Threads: 3 Questions: 10335 Slow queries: 0 Opens: 5061 Flush tables: 1 Open tables: 1543 Queries per second avg: 0.118 --------------  ERROR: No query specified   可以看到， 连接信息的SSL信息变成了Cipher in use is ECDHE-RSA-AES128-GCM-SHA256， 说明mysql可以使用SSL登录\n关于mysql ssl证书的生成，参考creating-ssl-files-using-openssl\n既然可以指定证书使用SSL， jdbc为什么报错?\n/etc/my.cnf里没有ssl配置?\n如何使用SSL连接，参考Use Encrypted Connections\n在/etc/my.cnf中添加\n[mysqld] ssl-ca=ca.pem ssl-cert=server-cert.pem ssl-key=server-key.pem 使用service mysqld restart重启mysql server， 让后看看服务端ssl配置是否生效:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  [root@sample ~]# service mysqld restart Redirecting to /bin/systemctl restart mysqld.service [root@sample ~]# mysql -u root -p --ssl WARNING: --ssl is deprecated and will be removed in a future version. Use --ssl-mode instead. Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.28 MySQL Community Server (GPL) mysql\u0026gt; \\s; -------------- mysql Ver 14.14 Distrib 5.7.28， for Linux (x86_64) using EditLine wrapper Connection id:\t2 Current database: Current user:\troot@localhost SSL:\tCipher in use is ECDHE-RSA-AES128-GCM-SHA256 Current pager:\tstdout Using outfile:\t\u0026#39;\u0026#39; Using delimiter:\t; Server version:\t5.7.28 MySQL Community Server (GPL) Protocol version:\t10 Connection:\tLocalhost via UNIX socket Server characterset:\tutf8 Db characterset:\tutf8 Client characterset:\tutf8 Conn. characterset:\tutf8 UNIX socket:\t/var/lib/mysql/mysql.sock Uptime:\t12 sec Threads: 1 Questions: 5 Slow queries: 0 Opens: 105 Flush tables: 1 Open tables: 98 Queries per second avg: 0.416 \\--------------   看到，我们使用ssl登录mysql，这一次并没有指定证书，而mysql连接成功，说明mysql服务端ssl配置成功了\n事实上，做到此步后，jdbc里使用\n1  jdbc:mysql://47.110.226.247:3306/hcfuture_bundule?useUnicode=true\u0026amp;characterEncoding=UTF-8\u0026amp;zeroDateTimeBehavior=convertToNull\u0026amp;useSSL=true   这样的数据库url仍然得到同样的错误；个人认为是由于当客户端设置useSSL=true时，同样需要配置客户端的SSL证书信息\n如何在客户端使用SSL，可以参考connector-j-reference-using-ssl\n以下内容摘自(https://www.sojpt.com/feedback/5723):\n 首先mysql服务端要支持ssl，支持ssl需要以下条件：\n  创建ssl证书和密钥\u0026ndash;生成ca.pem server-cert.pem client-cert.pem 文件\nmysql提供两种方式\n一种方式用openssl编译的mysql版本可以在启动时生成（参考链接：https://dev.mysql.com/doc/refman/5.7/en/creating-ssl-rsa-files-using-mysql.html）；\n第二种方式用openssl生成（采用的方式），（参考链接：https://dev.mysql.com/doc/refman/5.7/en/creating-ssl-files-using-openssl.html）\n  配置服务器支持（参考链接：https://dev.mysql.com/doc/refman/5.7/en/using-encrypted-connections.html）\n主要时需要在my.cnf中需要添加以下配置，文件路径自行修改；还可以指定某个用户必须使用ssl链接等，详情参考官方的链接\n  [mysqld] ssl-ca=ca.pem ssl-cert=server-cert.pem ssl-key=server-key.pem require_secure_transport=ON 客户端链接需要以下几个步骤\n 需要将服务端的pem证书转换成java支持的JKS证书，得到keystore.jks和truststore.jks：\n参考链接1：（可用）https://biteeniu.github.io/ssl/convert_pem_to_jks/\n参考链接2：（官方但连不上不知道什么原因）https://dev.mysql.com/doc/connector-j/5.1/en/connector-j-reference-using-ssl.html 修改mysql链接，指定链接方式为ssl\njdbc:mysql://127.0.0.1:3306/test?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;verifyServerCertificate=true\u0026amp;useSSL=true\u0026amp;requireSSL=true 加载生成的jks证书和密码到系统属性，要在ActiveRecordPlugin之前\n// keystore.jks和truststore.jks所在的路径，及创建时的密码\nSystem.setProperty(\u0026ldquo;javax.net.ssl.keyStore\u0026rdquo;， \u0026ldquo;path/keystore.jks\u0026rdquo;);\nSystem.setProperty(\u0026ldquo;javax.net.ssl.keyStorePassword\u0026rdquo;， \u0026ldquo;password\u0026rdquo;);\nSystem.setProperty(\u0026ldquo;javax.net.ssl.trustStore\u0026rdquo;，\u0026ldquo;path/truststore.jks\u0026rdquo;);\nSystem.setProperty(\u0026ldquo;javax.net.ssl.trustStorePassword\u0026rdquo;， \u0026ldquo;password\u0026rdquo;);   实在是很繁琐，不过我估计此法是可行的，实际上是配置客户端的certificate，我嫌繁琐并没有尝试\n实际上，我在官方文档里看到了此段话:\n By default， Connector/J establishes secure connections with the MySQL servers. Note that MySQL servers 5.7 and 8.0， when compiled with OpenSSL， can automatically generate missing SSL files at startup and configure the SSL connection accordingly.\nAs long as the server is correctly configured to use SSL， there is no need to configure anything on the Connector/J client to use encrypted connections (the exception is when Connector/J is connecting to very old server versions like 5.6.25 and earlier or 5.7.5 and earlier， in which case the client must set the connection property useSSL=true in order to use encrypted connections). The client can demand SSL to be used by setting the connection property requireSSL=true; the connection then fails if the server is not configured to use SSL. Without requireSSL=true， the connection just falls back to non-encrypted mode if the server is not configured to use SSL.\n 实际上，此前我们mysql server的SSL已经成功配置，已经验证通过mysql -u test -p -h your serverip远程登录mysql后，通过status查看连接信息可以看到是通过SSL连接的\n结合此段声明， mysql 5.7以后的连接是加密的(需要服务端开启SSL)，故无需费时在客户端进行ssl配置(特殊需求除外)\n如果想使用jdbc连接配置SSL， 而不使用编码方式，可以参考connector-j-reference-configuration-properties\n","description":"MySQL服务的安装与配置实践。","id":47,"section":"posts","tags":null,"title":"在centOS上安装并配置mysql数据库","uri":"http://wangy325.top/zh/posts/java/sql/%E5%9C%A8centos%E4%B8%8A%E5%AE%89%E8%A3%85%E5%B9%B6%E9%85%8D%E7%BD%AEmysql%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"content":"Redis v2.8 之后提供了高可用实现Redis Sentinel，实现了主从复制以及被动主备切换。v3.0 之后提供了分布式实现Redis Cluster。\n本文讨论的是使用Sentinel搭建Redis高可用服务。\n If all redis and sentinel instances were deployed in same host, you just build a fake redis-sentinel High-Availability environment1.\n 1 准备 1.1 linux主机 本文使用centOS7，需安装gcc：\n1 2 3  yum install gcc # or on ubuntu apt-get install gcc   1.2 Redis 源码 本文使用v4.0.0.11，版本号应大于2.8.0。\n可以使用如下命令来获取指定版本的redis：\n1  wget http://download.redis.io/releases/redis-4.0.11.tar.gz   1.3 了解linux防火墙的基本知识 centOS7和centOS6使用不同的防火墙机制，前者使用firewall，后者使用iptables。\n1.4 master，slave和sentinel 如果只想搭建一个单机(standalone)实例2来学习redis的数据结构，只需要阅读安装redis实例就好。\n多个standalone加之合适的配置便组成了master-slave结构，一般而言，此时已经具备了「主从复制」的能力。\n所谓Sentinel，并不是所谓「新技术」名词，只是一个用来做特定事情3的redis实例而已，故此我们也可以将其称作「服务」。如果需要搭建Sentinel服务，你需要先具备master-slave结构，也就是说，你至少需要搭建2个redis实例，并且将其中一台配置为另一台的slave。\n了解更多关于redis-sentinel的相关内容，请参考redis哨兵与高可用架构。\nredis的主从模式和哨兵模式:   2 安装配置Redis 接下来会依次安装Redis并且配置多个Redis实例\n2.1 编译源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  tar -zxf redis-4.0.11.tar.gz # compile source code cd redis-4.0.11 # redis was recommended to install in /usr/local/redis mkdir /usr/local/redis make install PREFIX=/usr/local/redis # --- # if all operations are right, you will see the output below: [root@shell ~]# cd /usr/local/redis ; ll total 68 #the redis executable binary file folder drwxr-xr-x 2 root root 4096 Aug 4 15:19 bin # the (RDB)dump file of redis database, You can config where to save it later -rw-r--r-- 1 root root 93 Aug 4 16:54 dump.rdb # the config file of a particular redis instance -rw-r--r-- 1 root root 58905 Aug 7 13:56 redis.conf [root@shell redis]# cd /usr/local/redis/bin ; ll  total 21876 # redis test tool -rwxr-xr-x 1 root root 2452168 Aug 4 15:19 redis-benchmark # redis AOF persistent check tool -rwxr-xr-x 1 root root 5775312 Aug 4 15:19 redis-check-aof # redis RBD persistent check tool -rwxr-xr-x 1 root root 5775312 Aug 4 15:19 redis-check-rdb # launch a redis client -rwxr-xr-x 2 root root 2618192 Aug 4 15:19 redis-cli # link to redis-server, launch a redis sentinel lrwxrwxrwx 1 root root 12 Aug 4 15:19 redis-sentinel -\u0026gt; redis-server server #launch a redis server(instance) -rwxr-xr-x 3 root root 5775312 Aug 4 15:19 redis-server   两个ll命令显示了一个redis的全部内容。本文用到的几个文件分别是：\n redis.conf： 配置文件，绝对的主角，它的戏谁都抢不走 redis-server： 用于启动redis缓存服务 redis-client：command-line client tool  2.2 其他配置项 如果上述操作没有问题这么简单也不会有问题，理论上，一个standalone实例已经安装完成了，可以通过「命令 配置文件」的方式启动redis服务：\n1  /usr/local/redis/bin/redis-server /usr/local/redis/redis.conf   但是为了方便启动服务，还需要做一些额外的操作：\n1. 复制redis二进制程序到系统环境变量 1 2  cd /usr/local/redis/bin/ cp redis-server redis-cli redis-sentinel /usr/local/bin   如此，启动redis的时候便不需要指定程序路径; 此时，已经可以直接在终端运行redis-server了\n2. 将redis设置为开机启动： 1 2  # 安装完成后可以添加多个命令启动redis主从-哨兵系统 echo \u0026#34;redis-server /usr/local/redis.conf\u0026#34; \u0026gt;\u0026gt; /etc/rc.local   3. 开放防火墙端口 若主机未开启防火墙，则无需操作  如果你的主机开启了防火墙，其他主机是无法连接上你的redis-server的，此时需要为其开放端口。\n前面说到，centOS7和centOS6的防火墙机制不一样，需要分别处理。\n若需知晓防火墙状态，请运行4\n1  systemctl status serviceName   centOS7 和centOS6的防火墙服务名分别为 firewalld和iptables\n对于centOS 7： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 查看开放端口 [root@shell ~]# firewall-cmd --list-all public target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http ports: 6379/tcp protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: # 如果6379端口不在返回结果中，那么将6379添加到开放端口列表中 [root@shell ~]# firewall-cmd --permanent --add-port=6379/tcp [root@shell ~]# firewall-cmd --reload   centOS 6 1 2 3 4 5 6  # 添加规则 iptables -I INPUT -p tcp -m tcp --dport 6379 -j ACCEPT # 保存规则 service iptables save # 重启iptables service iptables restart   2.3 配置文件redis.conf 在redis的安装文件夹内，有一个系统预配置文件redis.conf，我们需要修改此配置文件以满足需求。\n以下列出了(redis-standalone)常见配置列表4：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  # redis进程是否以守护进程的方式(后台)运行(不以守护进程的方式运行会占用一个终端) daemonize yes # 指定redis进程的PID文件存放位置 pidfile /var/run/redis.pid # redis进程的端口号 port 6379 # 允许任何ipv4的主机连接； bind 0.0.0.0 # 客户端闲置多长时间(s)后关闭连接，默认此参数为0即关闭此功能 timeout 300 # redis日志级别，可用的级别有debug.verbose.notice.warning loglevel verbose # log文件输出位置，如果进程以守护进程的方式运行，此处又将输出文件设置为stdout的话， # 就会将日志信息输出到/dev/null里面去了 logfile /var/log/redis/redis_6379.log # 设置数据库的数量，默认为0可以使用select \u0026lt;dbid\u0026gt;命令在连接上指定数据库id databases 16 # 保存db到磁盘，可配置多条，表示不同级别的数据改动 # 如下配置表示至少有一个key-value发生改动时，900s之后将其保存到磁盘； # 如果至少有10个key-value发生改动，那么300s后将其保存到磁盘； save 900 1 save 300 10 # 指定存储至本地数据库时是否压缩文件，默认为yes即启用存储 rdbcompression yes # 指定本地数据库文件名 dbfilename dump.db # 指定本地数据文件存放位置，以下配置表示保存在redis安装目录 dir ./ # 指定当本机为slave服务，配置为master的IP及端口，在redis启动的时候他会自动跟master进行数据同步 slaveof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt; # 当master设置了密码保护时，slave服务连接master的密码 masterauth \u0026lt;master-password\u0026gt; # 设置redis连接密码，如果配置了连接密码，客户端在连接redis是需要通过AUTH\u0026lt;password\u0026gt;命令 # 提供密码，默认关闭 requirepass password # 设置同一时间最大客户连接数，默认无限制。redis可以同时连接的客户端数为redis程序可以打开的最大 # 文件描述符，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的 # 连接并向客户端返回 max number of clients reached 错误信息 maxclients 128 # 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除 # 已到期或即将到期的Key。当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以 # 进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory \u0026lt;bytes\u0026gt; # 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可 # 能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以 # 有的数据会在一段时间内只存在于内存中。默认为no。 appendonly no # 指定跟新日志文件名默认为appendonly.aof appendfilename appendonly.aof # 指定更新日志的条件，有三个可选参数 - no：表示等操作系统进行数据缓存同步到磁盘(快)，always：表示每次 # 更新操作后手动调用fsync()将数据写到磁盘(慢，安全)， everysec：表示每秒同步一次(折衷，默认值)； appendfsync everysec   ⚠️注意：关于bind指令的描述可以配置指定ip来允许指定连接，多个ip使用空格分隔，关于bind的意义，参考redis配置外网访问\n3 启动redis redis.conf文件配置无差的话，即可指定配置文件启动redis服务：\n1  redis-server /usr/local/redis/redis.conf   启动日志：\n27552:C 04 Aug 16:12:58.912 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 27552:C 04 Aug 16:12:58.912 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=27552, just started 27552:C 04 Aug 16:12:58.912 # Configuration loaded _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 4.0.11 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 27553 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 27553:M 04 Aug 16:12:58.915 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 27553:M 04 Aug 16:12:58.916 # Server initialized 27553:M 04 Aug 16:12:58.916 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect. 27553:M 04 Aug 16:12:58.916 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 27553:M 04 Aug 16:12:58.916 * Ready to accept connections 可以看到，一个standalon已经运行成功，但是有3个WARNING[^V5]:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. # solution [root@shell ~]# echo 511 \u0026gt;/proc/sys/net/core/somaxconn [root@shell ~]# echo \u0026#34;net.core.somaxconn = 551\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. #solution [root@shell ~]# echo 1 \u0026gt; /proc/sys/vm/overcommit_memory [root@shell ~]# echo \u0026#34;vm.overcommit_memory=1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command \u0026#39;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026#39; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. #solution [root@shell ~]# echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled [root@shell ~]# vi /etc/rc.local if test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled fi if test -f /sys/kernel/mm/transparent_hugepage/defrag; then echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/defrag fi   4 使用redis-cli redis服务启动成功之后，便可以通过redis-cli与服务进行交互。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # 连接redis-server，若-h和-p参数缺省，则默认连接localhost:6379 redis-cli -h 127.0.0.1 -p 6379 127.0.0.1:6379\u0026gt; # 若redis-server requirepass设置了密码，那么需要认证 127.0.0.1:6379\u0026gt; auth yourpassword OK # ping-PONG说明redis服务正常 127.0.0.1:6379\u0026gt; ping 127.0.0.1:6379\u0026gt; PONG # 获取帮助 127.0.0.1:6379\u0026gt; help redis-cli 4.0.11 To get help about Redis commands type: \u0026#34;help @\u0026lt;group\u0026gt;\u0026#34; to get a list of commands in \u0026lt;group\u0026gt; \u0026#34;help \u0026lt;command\u0026gt;\u0026#34; for help on \u0026lt;command\u0026gt; \u0026#34;help \u0026lt;tab\u0026gt;\u0026#34; to get a list of possible help topics \u0026#34;quit\u0026#34; to exit To set redis-cli preferences: \u0026#34;:set hints\u0026#34; enable online hints \u0026#34;:set nohints\u0026#34; disable online hints Set your preferences in ~/.redisclirc 127.0.0.1:6379\u0026gt; help shutdown SHUTDOWN [NOSAVE|SAVE] summary: Synchronously save the dataset to disk and then shut down the server since: 1.0.0 group: server 127.0.0.1:6379\u0026gt; # 退出客户端 127.0.0.1:6379\u0026gt; exit   5 关闭redis-server 不要使用kill -9 pid关闭redis server，这样会可能会丢失数据完整性  1 2  #关闭redis-server 可选参数nosave|save意为关闭服务之前是否保存数据到磁盘 127.0.0.1:6379\u0026gt; shutdown [nosave|save]   6 艺术就是复制 以下配置是基于一台服务器的演示，如果要部署高可用环境，需要在不同的服务器上安装redis并作如下配置  经过上述操作，一个redis-standalone服务就配置好了，如果要将redis系统高可用，只需要「复制」就好了。\n前面说过，redis-server是通过可执行文件 + 配置文件的方式启动，可执行文件已经解压得到，那么只需要复制配置文件就可以了。\n以下是本次slave和sentinel的配置：\n   Role Address Port     Master localhost 6379   Slave localhost 16379, 26379   Sentinel localhost 6380, 16380, 26380    1 2 3 4 5 6 7 8  # current workDir cd /usr/local # 创建文件夹存放slave和sentinel配置文件 mkdir redis-slave redis-sentinel cp -r redis/redis.conf redis-slave cp -r redis/redis.conf redis-sentinel # slave配置文件 mv redis-slave/redis.conf redis-slave/slave-16379.conf   6.1 配置redis-salve slave的配置大抵和standalone一致，需要注意配置几个地方：\n logfile的保存地址配置自行配置 masterauth和requirepass配置master的密码 slaveof指明了其是哪个「主」的「从」 slave-read-only指明从服务器只读  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  vim redis-slave/slave-16379.conf \u0026lt;\u0026lt;\u0026lt; daemonize yes pidfile /var/run/redis-16379.pid logfile /var/log/redis/redis-16379.log port 16379 bind 0.0.0.0 timeout 300 databases 16 dbfilename dump-16379.db dir ./ masterauth yourpassword requirepass yourpassword slave-read-only yes slaveof 127.0.0.1 6379   1 2  # 再多配一个slave cp redis-slave/slave-16379.conf redis-slave/slave-26379.conf   同样地，只需要更改部分配置内容（端口，文件名）就可以了。\n6.1.1 salve启动日志 以下是配置成功的slave启动日志：\n30463:C 05 Aug 11:33:34.536 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 30463:C 05 Aug 11:33:34.537 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=30463, just started 30463:C 05 Aug 11:33:34.537 # Configuration loaded _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 4.0.11 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 26379 | `-._ `._ / _.-' | PID: 30464 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 30464:S 05 Aug 11:33:34.539 # Server initialized 30464:S 05 Aug 11:33:34.539 * Ready to accept connections # 注意以下输出： 30464:S 05 Aug 11:33:34.539 * Connecting to MASTER 127.0.0.1:6379 30464:S 05 Aug 11:33:34.539 * MASTER \u0026lt;-\u0026gt; SLAVE sync started 30464:S 05 Aug 11:33:34.539 * Non blocking connect for SYNC fired the event. 30464:S 05 Aug 11:33:34.539 * Master replied to PING, replication can continue... 30464:S 05 Aug 11:33:34.539 * Partial resynchronization not possible (no cached master) 30464:S 05 Aug 11:33:34.540 * Full resync from master: 4e99dfc708f2035b3b39f34796434de5889f667b:308 30464:S 05 Aug 11:33:34.543 * MASTER \u0026lt;-\u0026gt; SLAVE sync: receiving 177 bytes from master 30464:S 05 Aug 11:33:34.543 * MASTER \u0026lt;-\u0026gt; SLAVE sync: Flushing old data 30464:S 05 Aug 11:33:34.543 * MASTER \u0026lt;-\u0026gt; SLAVE sync: Loading DB in memory 30464:S 05 Aug 11:33:34.543 * MASTER \u0026lt;-\u0026gt; SLAVE sync: Finished with success slave的启动日志有几个信息值得关注：\n redis启动警告信息消除，说明我们之前的配置生效了； slave server 初始化成功之后，便开始连接master； master 连接成功之后，便开始从主数据库同步数据； 之后，从数据库一直监听机制主数据库的改动并同步数据  6.1.2 验证主从数据同步 可以通过在主数据库写入数据，通过从服务器读取数据来验证主从关系是否正常。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  [root@shell ~]# redis-cli -h localhost -p 6379 localhost:6379\u0026gt; auth yourpassword OK localhost:16379\u0026gt; get count \u0026#34;6\u0026#34; localhost:16379\u0026gt; decr count (integer) 5 localhost:16379\u0026gt; exit [root@ ~]# redis-cli -h localhost -p 16379 localhost:6379\u0026gt; auth yourpassword OK localhost:6379\u0026gt; get count \u0026#34;5\u0026#34; localhost:6379\u0026gt; incr count (error) READONLY You can\\\u0026#39;t write against a read only slave.   可以看到，主服务器将count值自减1之后，从服务器获取的count值也是自减后的值；同时，如果在从服务器上对count进行自增操作，会得到一条\n(error) READONLY You can't write against a read only slave. 的错误消息，说明\n  端口16379的redis服务是slave；\n  我们配置的从服务器只读生效了\n  以上，即可完成配置经典的一主多备的redis服务部署。\n6.2 配置redis-sentinel 同slave的配置一样，复制配置文件，少许改动即可，以下列出了sentinel的异于slave的配置项5：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # 哨兵sentinel监控的redis主节点的 ## quorum：当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了  # sentinel monitor \u0026lt;master-name\u0026gt; \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; \u0026lt;quorum\u0026gt;  sentinel monitor master 127.0.0.1 6379 2 # 当在Redis实例中开启了requirepass \u0026lt;foobared\u0026gt;，所有连接Redis实例的客户端都要提供密码 # sentinel auth-pass \u0026lt;master-name\u0026gt; \u0026lt;password\u0026gt;  sentinel auth-pass master yourpassword # 指定主节点应答哨兵sentinel的最大时间间隔，超过这个时间，哨兵主观上认为主节点下线，默认30秒  # sentinel down-after-milliseconds \u0026lt;master-name\u0026gt; \u0026lt;milliseconds\u0026gt; sentinel down-after-milliseconds master 30000 # 指定了在发生failover主备切换时，最多可以有多少个slave同时对新的master进行同步。 # 这个数字越小，完成failover所需的时间就越长；反之，但是如果这个数字越大，就意味着越多的 # slave因为replication而不可用。可以通过将这个值设为1，来保证每次只有一个slave，处于不能 # 处理命令请求的状态。 # sentinel parallel-syncs \u0026lt;master-name\u0026gt; \u0026lt;numslaves\u0026gt; sentinel parallel-syncs master 1 # 故障转移的超时时间failover-timeout，默认三分钟，可以用在以下这些方面： ## 1. 同一个sentinel对同一个master两次failover之间的间隔时间。  ## 2. 当一个slave从一个错误的master那里同步数据时开始，直到slave被纠正为从正确的master # 那里同步数据时结束。  ## 3. 当想要取消一个正在进行的failover时所需要的时间。 ## 4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时， # slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来同步数据了 # sentinel failover-timeout \u0026lt;master-name\u0026gt; \u0026lt;milliseconds\u0026gt;  sentinel failover-timeout master 180000   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # sentinel配置文件 mv redis-sentinel/redis.conf redis-sentinel/sentinel-6380.conf vim redis-sentinel/sentinel-6380.conf \u0026lt;\u0026lt;\u0026lt; protected-mode no bind 0.0.0.0 port 16380 daemonize yes sentinel monitor master 127.0.0.1 6379 2 sentinel down-after-milliseconds master 5000 sentinel failover-timeout master 180000 sentinel parallel-syncs master 1 sentinel auth-pass master yourpassword logfile /var/log/redis/sentinel-16380.log   同理，可以再配置其他2个sentinel服务。\n6.2.1 sentinel启动日志 启动sentinel6\n1 2 3  redis-sentinel /usr/local/redis-sentinel/sentinel-6380.conf # 或者 redis-server /usr/local/redis-sentinel/sentinel-6380.conf --sentinel   以下是配置成功的sentinel启动日志其一\n8550:X 05 Aug 14:29:38.696 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 8550:X 05 Aug 14:29:38.696 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=8550, just started 8550:X 05 Aug 14:29:38.696 # Configuration loaded _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 4.0.11 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._ ( ' , .-` | `, ) Running in sentinel mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6380 | `-._ `._ / _.-' | PID: 8551 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 8551:X 05 Aug 14:29:38.702 # Sentinel ID is c3776869c9bc3998e45158d3933d8e7b7c60ea84 8551:X 05 Aug 14:29:38.702 # +monitor master master 127.0.0.1 6379 quorum 2 通过观查启动日志，我们可以看到：\n 此实例的启动模式为sentinel mode，端口为6380 sentinel已经成功监控master端口6379了  全部哨兵系统搭建起来并运行之后，再去查看sentinel的配置文件，会有如下自动配置的内容：\n# Generated by CONFIG REWRITE sentinel auth-pass master yourpassword sentinel config-epoch master 1 sentinel leader-epoch master 1 sentinel known-slave master 127.0.0.1 16379 sentinel known-slave master 127.0.0.1 26379 sentinel known-sentinel master 127.0.0.1 26380 e615ce sentinel known-sentinel master 127.0.0.1 6380 dcc9d7 sentinel current-epoch 1 上面的配置列出了\n 主服务器的密码 以及当前世代（每发生一次主备切换称为一次世代，epoch加1） 当前所有从服务器的地址和端口信息 当前所以其他已知哨兵的端口和id信息  6.2.2 使用redis-cli查看系统信息 sentinel哨兵系统搭建起来之后，可以任一通过客户端查看系统内的实例信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  127.0.0.1:16380\u0026gt; sentinel master master 1) \u0026#34;name\u0026#34; 2) \u0026#34;master\u0026#34; 3) \u0026#34;ip\u0026#34; 4) \u0026#34;127.0.0.1\u0026#34; 5) \u0026#34;port\u0026#34; 6) \u0026#34;6379\u0026#34; 7) \u0026#34;runid\u0026#34; 8) \u0026#34;dfefe0ba7435f7c2c193698f17b7e46f7450d5ce\u0026#34; 9) \u0026#34;flags\u0026#34; 10) \u0026#34;master\u0026#34; ... 127.0.0.1:16380\u0026gt; sentinel slaves master 1) 1) \u0026#34;name\u0026#34; 2) \u0026#34;127.0.0.1:16379\u0026#34; 3) \u0026#34;ip\u0026#34; 4) \u0026#34;127.0.0.1\u0026#34; 5) \u0026#34;port\u0026#34; 6) \u0026#34;16379\u0026#34; 7) \u0026#34;runid\u0026#34; 8) \u0026#34;fdda882f98724c46359a4deb9390b6ae4de13320\u0026#34; 9) \u0026#34;flags\u0026#34; 10) \u0026#34;slave\u0026#34; ... 2) 1) \u0026#34;name\u0026#34; 2) \u0026#34;127.0.0.1:26379\u0026#34; 3) \u0026#34;ip\u0026#34; 4) \u0026#34;127.0.0.1\u0026#34; 5) \u0026#34;port\u0026#34; 6) \u0026#34;26379\u0026#34; 7) \u0026#34;runid\u0026#34; 8) \u0026#34;4a2c286c0c99c3a1202eec142599193a85671f6c\u0026#34; 9) \u0026#34;flags\u0026#34; 10) \u0026#34;slave\u0026#34; ...   6.2.3 模拟主备切换 哨兵的存在就是为了解决master-slave系统中由于master宕机引起的系统瘫痪问题。\n在哨兵系统中，一旦哨兵发现当前master宕机，哨兵会在余下的slaves中选举一个「继任」为新一代的master，从而保证系统的高可用。\n现在我们通过主动关闭当前master服务的方式来模拟master宕机，看看哨兵会做什么：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # 关闭master服务 redis-cli -p 6379 127.0.0.1:6379\u0026gt; auth yourpassword OK 127.0.0.1:6379\u0026gt; shutdown save 127.0.0.1:6379\u0026gt; exit # 查看sentinel日志 less /var/log/redis/sentinel-6380.log \u0026lt;\u0026lt;\u0026lt; 29649:X 23 Aug 17:14:02.326 # +sdown master master 127.0.0.1 6379 29649:X 23 Aug 17:14:02.389 # +new-epoch 1 29649:X 23 Aug 17:14:02.391 # +vote-for-leader 503d5371452f8e110df0f12c236da3e51b55b03a 1 29649:X 23 Aug 17:14:03.444 # +odown master master 127.0.0.1 6379 #quorum 3/2 29649:X 23 Aug 17:14:03.444 # Next failover delay: I will not start a failover before Fri Aug 23 17:14:38 2019 29649:X 23 Aug 17:14:03.488 # +config-update-from sentinel 503d5371452f8e110df0f12c236da3e51b55b03a 172.16.16.203 16380 @ master 127.0.0.1 6379 29649:X 23 Aug 17:14:03.488 # +switch-master master 127.0.0.1 6379 127.0.0.1 26379 29649:X 23 Aug 17:14:03.488 * +slave slave 127.0.0.1:16379 127.0.0.1 16379 @ master 127.0.0.1 26379 29649:X 23 Aug 17:14:03.488 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ master 127.0.0.1 26379 29649:X 23 Aug 17:14:08.536 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ master 127.0.0.1 26379 29649:X 23 Aug 17:15:42.868 # -sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ master 127.0.0.1 26379 29649:X 23 Aug 17:15:52.888 * +convert-to-slave slave 127.0.0.1:6379 127.0.0.1 6379 @ master 127.0.0.1 26379   通过24行sentinel日志，我们可以看到的信息有哪些呢？\n master主观下线7； 系统进入新世代； 3/2投票认为master下线，master客观下线8； 切换主服务器：从6379切换为26379； 同时6379和16379切换为26379的从节点  此时，我们如果查看redis的配置文件，会发现原6379的主服务器配置文件多了一行\nslaveof 127.0.0.1 26379 同时，16379和26379端口的服务的slaveof配置项也作了相应修改。\n7 结束语 至此，基于sentinel的redis高可用集群就搭建完成了。虽然篇幅较长，实际上搭建一个这样的系统的逻辑是比较简单的。\n主要易于混淆的是6不个redis实例的配置，细心点就好了。\n想用好这个高可用系统，你可能还需要了解更多关于sentinel的内容。\n 本文是在所有服务均配置完成之后所作的记录，并非同步记录，部分操作可能存在错误 \u0026#x21a9;\u0026#xfe0e;\n 下文会多次提到实例这个概念，它在本文中指一个运行的Redis数据库服务 \u0026#x21a9;\u0026#xfe0e;\n 监控master状态，如果宕机，则执行主备切换 \u0026#x21a9;\u0026#xfe0e;\n 搭建redis单机服务 \u0026#x21a9;\u0026#xfe0e;\n redis哨兵与高可用 \u0026#x21a9;\u0026#xfe0e;\n redis-server man page \u0026#x21a9;\u0026#xfe0e;\n 仅当前哨兵接收不到master的心跳，称为主观下线 \u0026#x21a9;\u0026#xfe0e;\n 经过投票之后，满足配置个数的哨兵认为master下线，则master被认为客观下线，触发主备切换 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"本文是redis主从以及哨兵集群模式在服务器上的安装配置实践。","id":48,"section":"posts","tags":["redis"],"title":"Redis Sentinel高可用实现","uri":"http://wangy325.top/zh/posts/java/redis/build-redis-sentinel/"},{"content":" Hugo 博客主题 森亮号航海见识 赫赫文王 独影 琼·岗鉴 阮一峰的个人站 廖雪峰的官方网站 谢益辉  ","description":"","id":49,"section":"","tags":null,"title":"优秀的博客","uri":"http://wangy325.top/zh/friend/"},{"content":"cron表达式常用于配置定时任务。cron表达式实际上是由七个子表达式组成。这些表达式之间用空格分隔：\n Seconds （秒） Minutes（分） Hours（小时） Day-of-Month （天） Month（月） Day-of-Week （周） Year（年）   例：表达式0 0 12 ? \\* WED 意思是：每个星期三的中午12点执行。\n 个别子表达式可以包含范围或者列表。例如：上面例子中的WED可以换成MON-FRI，MON,WED,FRI\u0026quot;，甚至MON-WED,SAT\n下表列出了Cron子表达式的取值范围：\n         Seconds 0~59   Minutes 0~59   Hours 0~23   Day-of-Month 1~31,但是要注意有些月份没有31天   Month (0~11，或者JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV,DEC   Day-of-Week 1~7,或者SUN(=1), MON, TUE, WED, THU, FRI, SAT   Year 1970~2099    格式 Cron表达式的格式：秒 分 时 日 月 周 年(可选)\n   字段名 允许的值 允许的特殊字符     秒 0-59 , - * /   分 0-59 , - * /   时 0-23 , - * /   日 1-31 , - * ? / L W C   月 1-12 or JAN-DEC , - * /   周几 1-7 or SUN-SAT , - * ? / L C #   年（可选） empty 1970-2099 , - * /    通配/特殊字符的含义 * ：代表所有可能的值。因此，*在Month中表示每个月，在Day-of-Month中表示每天，在Hours表示每小时。\n- ：表示指定范围。\n, ：表示列出枚举值。例如：在Minutes子表达式中，5,20表示在5分钟和20分钟触发。\n/ ：被用于指定增量。例如：在Minutes子表达式中，0/15表示从0分钟开始，每15分钟执行一次；3/20表示从第三分钟开始，\n每20分钟执行一次，和3,23,43（表示第3，23，43分钟触发）的含义一样。\n? ：用在Day-of-Month和Day-of-Week中，指没有具体的值。当两个子表达式其中一个被指定了值以后，为了避免冲突，\n需要将另外一个的值设为?。例如：想在每月20日触发调度，不管20号是星期几，只能用如下写法：0 0 0 20 * ?，\n其中最后一位只能用?，而不能用*。\nL ：用在Day-of-Month和Day-of-Week字串中。它是单词“last”的缩写。它在两个子表达式中的含义是不同的。\n在Day-of-Month中，L表示一个月的最后一天，如1月31号，3月30号。 在Day-of-Week中，L表示一个星期的最后一天，也就是“7”或者“SAT”。\n但是如果L前有具体内容，它就有其他的含义了。例如：6L表示这个月的倒数第六天。FRIL表示这个月的最后一个星期五。\n注意：在使用L参数时，不能指定列表或者范围，这样会出现问题。\nW ：Weekday的缩写。只能用在Day-of-Month字段。用来描叙最接近指定天的工作日（周一到周五）。\n例如：在Day-of-Month字段用15W指最接近这个月第15天的工作日，即如果这个月第15天是周六，那么触发器将会在这个月第14天即周五触发；\n如果这个月第15天是周日，那么触发器将会在这个月第 16天即周一触发；如果这个月第15天是周二，那么就在触发器这天触发。\n注意一点：这个用法只会在当前月计算值，不会越过当前月。W字符仅能在 Day-of-Month指明一天，不能是一个范围或列表。\n也可以用LW来指定这个月的最后一个工作日，即最后一个星期五。\n# ：只能用在Day-of-Week字段。用来指定这个月的第几个周几。例：在Day-of-Week字段用6#3 or FRI#3指这个月第3个周五（6指周五，3指第3个）。如果指定的日期不存在，触发器就不会触发。\n常见表达式示例 0 * * * * ? 每1分钟触发一次\n0 0 * * * ? 每天每1小时触发一次\n0 0 10 * * ? 每天10点触发一次\n0 * 14 * * ? 在每天下午2点到下午2:59期间的每1分钟触发\n0 30 9 1 * ? 每月1号上午9点半\n0 15 10 15 * ? 每月15日上午10:15触发\n*/5 * * * * ? 每隔5秒执行一次\n0 */1 * * * ? 每隔1分钟执行一次\n0 0 5-15 * * ? 每天5-15点整点触发\n0 0/3 * * * ? 每三分钟触发一次\n0 0-5 14 * * ? 在每天下午2点到下午2:05期间的每1分钟触发\n0 0/5 14 * * ? 在每天下午2点到下午2:55期间的每5分钟触发\n0 0/5 14,18 * * ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发\n0 0/30 9-17 * * ? 朝九晚五工作时间内每半小时\n0 0 10,14,16 * * ? 每天上午10点，下午2点，4点\n0 0 12 ? * WED 表示每个星期三中午12点\n0 0 17 ? * TUES,THUR,SAT 每周二、四、六下午五点\n0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发\n0 15 10 ? * MON-FRI 周一至周五的上午10:15触发\n0 0 23 L * ? 每月最后一天23点执行一次\n0 15 10 L * ? 每月最后一日的上午10:15触发\n0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发\n0 15 10 * * ? 2005 2005年的每天上午10:15触发\n0 15 10 ? * 6L 2002-2005 2002年至2005年的每月的最后一个星期五上午10:15触发\n0 15 10 ? * 6#3 每月的第三个星期五上午10:15触发\n","description":"cron表达式速查手册。","id":50,"section":"posts","tags":["cron"],"title":"cron表达式速查","uri":"http://wangy325.top/zh/posts/java/job/%E5%B8%B8%E8%A7%81cron%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%A4%BA%E4%BE%8B/"},{"content":"代理可以简单理解为，B类托管A类的功能，并根据需求，对A类的访问作控制，这里的控制可以理解为对A类方法执行的流程的影响，包括但不限于：\n 在方法执行之前，先做其他事（前置通知）\n在方法执行之后，再做某事（后置通知）\n决定方法是否执行（环绕通知）\n\u0026hellip;\n java中代理的主要应用体现在权限控制,日志管理,事务控制等\njava 代理模式简单图解\n 静态代理  静态代理的作用，可扩展性，可维护性相对较差。典型的静态代理可以通过继承和包装器两种方式来实现，包装器方式比起继承方式稍方便。\n 继承方式的静态代理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  /** * @author:wangy * @date: 2018/9/21 / 15:15 * @description: 通过继承的方式实现java静态代理, 主要在于理解所谓\u0026#34;代理\u0026#34;的概念 */ public interface CellPhone { void sendMessage(); } /** * 模拟被代理类对象 */ public class Iphone5 implements CellPhone { @Override public void sendMessage() { System.out.println(\u0026#34;the sending message is in the air.\u0026#34;); } } /** * 模拟代理类对象 */ public class Iphone5S extends Iphone5 { @Override public void sendMessage() { System.out.println(\u0026#34;you need to unlock your phone first.\u0026#34;); super.sendMessage(); // 模拟短信发送  try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;message sent successful.\u0026#34;); } } /** *客户端 */ public class Client { public static void main(String[] args) { CellPhone phone = new Iphone5S(); phone.sendMessage(); } } ///:~ you need to unlock your phone first. the sending message is in the air. message sent successful.   上例中，Iphone5S 类继承了Iphone5，并对5的功能“加了点椰果”，这就是最简单的代理模式。但是，如果我还想“加点奶油”，那么就需要再创建一个类，给5“加奶油”，如果有很多手机，要加很多功能，只能通过“硬编码”来完成，这样显然是不合适的。\n包装器方式的静态代理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  /** * @author:wangy * @date: 2018/9/21 / 15:15 * @description: 通过包装器的方式实现java静态代理 */ public interface IceCream { void iceCreamMaker(); } /** * 模拟被代理类对象 */ public class BerryCream implements IceCream { @Override public void iceCreamMaker() { System.out.println(\u0026#34;this is a IceCream with blueberry juice.\u0026#34;); } } /** * 模拟代理类对象 */ public class Jelly implements IceCream { // 代理对象中封装了被代理对象  private BerryCream berryCream; public Jelly(BerryCream berryCream) { this.berryCream = berryCream; } @Override public void iceCreamMaker() { System.out.println(\u0026#34;add Grass jelly into Berry IceCream\u0026#34;); berryCream.iceCreamMaker(); System.out.println(\u0026#34;now it\u0026#39;s a Grass-jelly-Berry-IceCream\u0026#34;); } } /** * 模拟客户端 */ public class Client { public static void main(String[] args) { IceCream iceCream = new Jelly(new BerryCream()); iceCream.iceCreamMaker(); } } /* add Grass jelly into Berry IceCream this is a IceCream with blueberry juice. now it\u0026#39;s a Grass-jelly-Berry-IceCream *///:~   在包装器模型中，被代理类对象被封装在代理类对象中。通过这种形式，如果我需要在“莓派冰激凌”上加上“烧仙草”和“珍珠果”，只需要将代码作一些改动，并且，其相对于继承模式的又是在于：继承是类似于一个链式的叠加，并且对于功能的改动比较麻烦（比如想先加珍珠果再加烧仙草，就需要改动继承关系）。而包装器设计就相对比较灵活了，只需要作简单改动：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  // 将代理类对象1的封装类直接改为接口 public class Jelly implements IceCream { private IceCream iceCream; public Jelly(IceCream iceCream) { this.iceCream = iceCream; } @Override public void iceCreamMaker() { System.out.println(\u0026#34;add Grass jelly into Berry IceCream\u0026#34;); iceCream.iceCreamMaker(); System.out.println(\u0026#34;now it\u0026#39;s a Grass-jelly-Berry-IceCream\u0026#34;); } } // 添加代理对象2 public class Pearl implements IceCream { private IceCream iceCream; public Pearl(IceCream iceCream) { this.iceCream = iceCream; } @Override public void iceCreamMaker() { System.out.println(\u0026#34;add pearl fruit into Berry Ice Cream.\u0026#34;); iceCream.iceCreamMaker(); System.out.println(\u0026#34;now it\u0026#39;s a what a icecream!\u0026#34;); } } // 测试类 public class Client { public static void main(String[] args) { // 如果想改变“加料”的顺序，只需要改变对象初始化的顺序就ok  IceCream iceCream = new BerryCream(); Pearl pearl = new Pearl(iceCream); Jelly jelly = new Jelly(pearl); jelly.iceCreamMaker(); } } ///:~ add Grass jelly into Berry IceCream add pearl fruit into Berry Ice Cream. this is a IceCream with blueberry juice. now it\u0026#39;s a what a icecream! now it\u0026#39;s a Grass-jelly-Berry-IceCream   动态代理 相较于静态代理，动态代理带来的好处是：一个代理工具（或者叫代理处理程序），能够有效地实现对不同委托类的代理，这样使代码更加灵活。代理模式一定程度上可以看作“功能增强”，而“功能增强”的需求本质上就是相对灵活的，这和动态代理的初衷相契合。\nJDK 动态代理 JDK 动态代理是比较常见的代理模式。其实现方法可大致总结为:\n 1.创建一个实现接口InvocationHandler的类，它必须实现invoke方法 2.创建被代理的类以及接口 3.通过Proxy的静态方法 newProxyInstance(ClassLoaderloader, Class[] interfaces, InvocationHandler h)创建一个代理类实例 4.通过代理类实例调用委托类方法  1. 动态代理需要一个接口 这个接口供所有需要被代理的类实现\n1 2 3 4  public interface Subject { void sayHallo(); }   2. 和一个简单的实现类 1 2 3 4 5 6  public class RealSubject implements Subject { @Override public void sayHallo() { System.out.println(\u0026#34;大家好!\u0026#34;); } }   3. 自定义代理处理程序，须实现 InvocationHandler 接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  public class MyProxyHandler implements InvocationHandler { private Subject subject; MyProxyHandler() { } MyProxyHandler(Subject subject) { this.subject = subject; } /** * 此方法用于生成一个指定接口的代理类实例, 该接口可以将方法调用指派到 [指定的调用处理程序], * 这个所谓的 [调用处理程序] 就是 InvocationHandler的invoke()方法 * * @param subject 需要被代理的类的实例对象(被代理接口的实现类) * @return 一个指定接口的代理类实例 * 这里, 指定接口就是说的是 Subject 接口, 常说的JDK动态代理需要有一个接口,就是这个原因 */ Object bind(Subject subject) { this.subject = subject; return Proxy.newProxyInstance(subject.getClass().getClassLoader(), subject.getClass().getInterfaces(), this); // 此Proxy类的静态方法等价于  /*try { // 获取实现指定接口的被代理类实例对象 Class\u0026lt;?\u0026gt; proxyClass = Proxy.getProxyClass(Subject.class.getClassLoader(), Subject.class.getInterfaces()); // 获取指定的 [调用处理程序对象] 的构造器 Constructor\u0026lt;?\u0026gt; proxyClassConstructor = proxyClass.getConstructor(MyProxyHandler.class); // 通过指定的InvocationHandler实例创建实现指定接口的代理类实例对象 return proxyClassConstructor.newInstance(new MyProxyHandler(subject)); }catch(Exception e){ e.printStackTrace(); }*/ } /* ******************************************** * java.lang.reflect.Proxy [extends Object implements Serializable] 类 * -- 该类提供用于创建动态代理类和实例的静态方法, 它是由这些静态方法创建的动态代理类的超类 * -- 动态代理类(以下称为代理类)是一个实现 [在创建类时在运行时指定的接口列表] 的类 * -- 代理接口(Subject)是代理类实现的一个接口 * -- 代理实例是代理类的一个实例, 每个代理实例都有一个关联的 [调用处理程序] 对象, 其实现接口 InvocationHandler * -- 代理实例调用方法(sayHallo())时, 会被指派到 [调用处理程序] 对象的 invoke() 方法 * ********************************************/ /** * @param proxy 代理类对象 * @param method 被代理类的方法实例 * @param args 被代理类对象(subject)的方法实例method的参数 * @return null * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\u0026#34;before...\u0026#34;); method.invoke(subject, args); System.out.println(\u0026#34;after...\u0026#34;); return null; } }   4. 客户端生成代理类对象并且调用委托类的方法 这个client介绍了3种创建动态代理类的方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  public class Client { /** * 被代理类对象(接口) */ private static Subject subject = new RealSubject(); /** * 代理实例关联的调用处理程序对象实例 */ private static InvocationHandler handler = new MyProxyHandler(subject); /** * 代理实例关联的调用处理程序对象, 一般是自定义的InvocationHandler类的实现类 */ private static MyProxyHandler my_proxy = new MyProxyHandler(); public static void main(String[] args) { m1(); m2(); m3(); } /** * 通过 [代理类实例] 调用 [被代理类] 实例的指定方法时, 会被[自定义代理类处理程序]指派给 [调用处理程序](即invoke()方法),并且执行invoke方法的增强代码 */ private static void m3() { Subject proxySubject = (Subject) my_proxy.bind(subject); proxySubject.sayHallo(); } private static void m2() { Subject proxy_subject = (Subject) Proxy.newProxyInstance(subject.getClass().getClassLoader(), subject.getClass().getInterfaces(), handler); proxy_subject.sayHallo(); } private static void m1() { Subject proxySubject = null; try { Class\u0026lt;?\u0026gt; proxyClass = Proxy.getProxyClass(Subject.class.getClassLoader(), Subject.class); Constructor\u0026lt;?\u0026gt; constructor = proxyClass.getConstructor(InvocationHandler.class); proxySubject = (Subject) constructor.newInstance(handler); } catch (Exception e) { e.printStackTrace(); } proxySubject.sayHallo(); }   cglib 动态代理 与JDK动态代理不同的是，cglib动态代理不需要委托类实现某个接口，其生成的代理类是委托类的子类。当然，cglib也有其局限：\n  final 类不能通过cglib代理 final 修饰的方法不能通过cglib作增强处理   cglib实现动态代理可简单地归纳为：\n 1.创建委托类对象 2.创建[自定义代理类生成程序]类，该类须实现MethodInterceptor 3.通过Enhancer来创建代理类实例 4.通过代理类实例调用委托类方法  1.创建委托类 1 2 3 4 5  public class Flower { public void bloom(){ System.out.println(\u0026#34;the flower will bloom...\u0026#34;); } }   2. 自定义代理类生成程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class ProxyInterceptor implements MethodInterceptor { private Enhancer enhancer = new Enhancer(); Object getProxyClass(Class clazz){ enhancer.setSuperclass(clazz); enhancer.setCallback(this); return enhancer.create(); } @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(\u0026#34;after you fertilized...\u0026#34;); methodProxy.invokeSuper(o, objects); System.out.println(\u0026#34;and you will have a harvest.\u0026#34;); return null; } }   3. 客户端 1 2 3 4 5 6 7  public class Client { private static ProxyInterceptor proxyInterceptor = new ProxyInterceptor(); public static void main(String[] args) { Flower proxyClass = (Flower) proxyInterceptor.getProxyClass(Flower.class); proxyClass.bloom(); } }   JDK动态代理和cglib动态代理的区别    代理 特点 优点 缺点     JDK 代理类与委托类实现同一接口，主要是通过代理类实现InvocationHandler并重写invoke方法来进行动态代理的，在invoke方法中将对方法进行增强处理，底层使用反射机制进行方法的调用 不需要硬编码接口，代码复用率高 只能够代理实现了接口的委托类   cglib 代理类将委托类作为自己的父类并为其中的非final委托方法创建两个方法，一个是与委托方法签名相同的方法，它在方法中会通过super调用委托方法；另一个是代理类独有的方法。在代理方法中，它会判断是否存在实现了MethodInterceptor接口的对象，若存在则将调用intercept方法对委托方法进行代理，底层将方法全部存入一个数组中，通过数组索引直接进行方法调用 可以在运行时对类或者是接口进行增强操作，且委托类无需实现接口 不能对final类以及final方法进行代理     *JDK和cglib动态代理的简易区别，引自[jianshu.com@EakonZhao](https://www.jianshu.com/p/9a61af393e41?from=timeline\u0026amp;isappinstalled=0)*  解析JDK动态代理","description":"本文介绍了2中主要的代理模式，JDK动态代理以及cglib动态代理。","id":51,"section":"posts","tags":["代理模式"],"title":"代理模式","uri":"http://wangy325.top/zh/posts/java/design_pattern/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/"},{"content":"例如，我在执行以下sql语句的时候\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  SELECT projectId FROM lywl_equip_package WHERE salesId in ( SELECT t1.id FROM cmp_datapackage_user t1 LEFT JOIN cmp_datapackage t2 ON t1.datapackage_id = t2.id WHERE t1.sales_cycle \u0026gt; 1 AND t1.is_valid = 1 AND t1.is_share = 0 AND t1.sales_price \u0026lt;\u0026gt; 9999 AND t1.sales_name REGEXP \u0026#39;移动.*/(季度|半年|年)\u0026#39; AND t2.operator =1 AND t2.is_share = 1 AND t2.datapackage_cycle = 1 )   以上sql查询的是订购移动跨月销售品的设备id, 查询耗时 6.462s。\n由于 lywl_equip_package 数据量比较大, in 查询每次都将 lywl_equip_package 的数据与in 语句中的匹配, 耗时较为严重。\n但是作如下改动之后,sql的查询效率就快很多：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  SELECT tt2.projectId FROM ( SELECT t1.id FROM cmp_datapackage_user t1 LEFT JOIN cmp_datapackage t2 ON t1.datapackage_id = t2.id WHERE t1.sales_cycle \u0026gt; 1 AND t1.is_valid = 1 AND t1.is_share = 0 AND t1.sales_price \u0026lt;\u0026gt; 9999 AND t1.sales_name REGEXP \u0026#39;移动.*/(季度|半年|年)\u0026#39; AND t2.operator =1 AND t2.is_share = 1 AND t2.datapackage_cycle = 1 ) tt1 LEFT JOIN lywl_equip_package tt2 ON tt2.salesId = tt1.id   查询时间 0.246s\n以上的操作在于, 将IN查询中的结果储存为一张临时表,然后将其作为主表,左连接lywl_equip_package.以数据少的表作为主表,可以提升查询效率。\n","description":"sql查询过程中，如果数据量过大，而查询条件又很简略的时候，往往会导致查询过程非常耗时，这时，应该考虑SQL优化的问题了。","id":52,"section":"posts","tags":[""],"title":"一个简单的sql优化示例","uri":"http://wangy325.top/zh/posts/java/sql/%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84sql%E4%BC%98%E5%8C%96%E7%9A%84%E4%BE%8B%E5%AD%90/"},{"content":"回调模式在web开发中用的较多，本文简单介绍了Java的回调机制，理解此文可以在生产中写出适应业务的回调模型。\n模块之间的调用 在一个应用系统中，必然存在模块之间的调用，调用的方式有几种:\n1. 同步调用 \n​\t方法A()调用方法B(),并且等待方法B()的返回,然后A()再执行下一步操作\n此方法适用于B()方法执行的时间不长，如若不然，那么A()方法会长时间等待B()方法执行完成而处于阻塞状态，如此，可能会导致整个流程的阻塞。\n2. 异步调用 \n为了解决A()方法调用B()方法造成流程阻塞而出现的，最典型的方式就是开启新线程。这样的话，A()方法不必等待B()方法的返回而继续执行。\n但是这种方法存在一个问题：如果A()需要知道B()的执行结果(根据业务需求，有些操作如异步线程刷新缓存、推送通知等等不需要，而有些如更改状态的操作则需要)，则需要通过某种方式对B()的执行结果进行监听，在Java中可以通过Future+Callable来实现。\n3. 回调 \n在回调模式中，\n A()方法调用B()方法 B()方法执行完毕之后，调用A类的AA()方法（回调方法），将执行结果返回给A\n 要实现这个需求，有几点问题需要思考：\n A类中如何调用B类的方法（这个简单，字段注入即可） B类的方法执行完成之后，如何调用A类的callback方法（被调用的B类的方法，必须有A类对象作为形参） 如何提升代码的可复用性及可扩展性？（面向接口）  一个简单的例子： 场景描述：男孩需要向女孩表白，但羞于表达，只好借助神父传达心意，神父知道男孩的请求之后，将要对女孩说的话告诉男孩。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  /** * @author:wangy * @date: 2018/8/30 / 20:37 * @description: 这是那个男孩 * java 回调机制的引入 A--调用--\u0026gt;B(c) ---调用--\u0026gt;A(d) d 方法称之为回调方法 * 使用场景: A想完成某事, 但A不能独立完成,需要借助B的力量, B完成之后, 要将结果通知给A(通过调用A的方法实现) */ public class Kidd { private String name; private GodFather godFather; public Kidd(String name,GodFather godFather) { this.name = name; this.godFather = godFather; } public void askGodFather(){ godFather.witness(this); } public void confess(String voice){ System.out.println(this.name+\u0026#34;:\u0026#34;+ voice); } }   男孩类有两个方法：\n askGodFather() 方法用于调用神父类的witness()方法\nconfess()方法用于让神父类回调\n 1 2 3 4 5 6 7 8 9 10 11  /** * @author:wangy * @date: 2018/8/30 / 20:45 * @description: 这是神父类 */ public class GodFather { public void witness(Kidd kidd) { kidd.confess(\u0026#34;the moon light is gorgeous tonight\u0026#34;); } }   神父类比较简单,只有一个方法witness()，它有一个Kidd对象作为形参,这个对象用于回调男孩类的回调方法\n1 2 3 4 5 6  // 测试类 public class Test { public static void main(String[] args) { new Kidd(\u0026#34;Alex\u0026#34;,new GodFather()).askGodFather(); } }   返回:\n Alex:the moon light is gorgeous tonight  以上是一个最简单的Java 回调机制的模型，该模型还存在一些不限于以下列出的问题：\n B类的方法形参单一，上例中形参为Kidd对象，那么，换成Cat对象便又要写一个“神父类”； 同理，A类调用的B类方法单一，上例中需求的是“表白神父”*（功能A），如果换成“免灾神父”（功能B），又要写一个神父； 总结起来，就是通过‘类’的方式实现回调，代码的扩展性和可复用性较差  一个相对健壮的回调机制应该是这样的 以上的UML图解释了Java回调的实质：\n A类和B类分别为接口的实现类，这样代码的扩展性一下就提升了\n 另一个简单的例子： 场景描述:老师课堂点名学生回答问题，学生解答完毕之后回答老师  回调接口(A类需实现):\n1 2 3 4 5 6 7 8 9 10 11 12  /** * @author wangy * @desc 先定义一个回调接口,所有的A类要实现结果回调,必需实现该类并覆写回调方法,供B类调用 */ public interface Callback { /** * 回调接口是供B类来调用的,所以它的形参中必须包含A类调用B方法时候的返回值(对象) * @param a B类方法的返回值 * @param student 根据功能需求传递其他参数 */ void tellAnswer(Student student , int a); }   B类的接口:\n1 2 3 4 5 6 7 8 9 10 11 12 13  /** * @author wangy * @desc B 类, 抽象为一个接口,方便A类对不同实现类(不同功能需求)的回调 */ public interface Student { /** * 方法接收一个callback参数,用于指示B类执行方法之后,向谁\u0026#34;汇报\u0026#34; * @param callback */ void resolveAnswer(Callback callback); String getName(); }   A类实体:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  /** * @author:wangy * @date: 2018/9/18 / 10:17 * @description: A类, 实现回调接口并覆写方法 */ public class Teacher implements Callback { /** * 接口作为属性字段,便于扩展 */ private Student student; public Teacher(Student student) { this.student = student; } /** * askQuestion() 方法用于调用B类的方法 */ public void askQuestion() { student.resolveAnswer(this); } /** * 覆写的回调方法,用于供B类调用,以便通知执行结果 * * @param a */ @Override public void tellAnswer(Student student , int a) { System.out.println(\u0026#34;嗯,\u0026#34;+student.getName()+\u0026#34; 完成任务花了 \u0026#34; + a + \u0026#34; 秒\u0026#34;); } }   A类实体有2个方法\n askQuestion() 用于调用B类的方法 覆写的tellAnswer()方法,用于接收回调结果\n B类实体:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  /** * @author:wangy * @version:1.0 * @date: 2018/9/18 / 10:20 * @description: B类的(某种特殊功能)实现类 */ public class Rookie implements Student { private String name; public Rookie(String name) { this.name = name; } @Override public String getName() { return name; } @Override public void resolveAnswer(Callback callback) { // 模拟方法执行过程  try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } // 回调,给指定callback的实现类  callback.tellAnswer(this, 3); } }   B类实体有一个方法resolveAnswer(Callback callback)，接收一个callback参数，该参数用于调用A类的回调方法\n测试类:\n1 2 3 4 5 6 7  public class Test { public static void main(String[] args) { Teacher teacher = new Teacher(new Rookie(\u0026#34;alan\u0026#34;)); teacher.askQuestion(); } }   返回:\n嗯,alan 完成任务花了 3 秒  分析 上面的例子中，对A类和B类分别进行了抽象，这样做的好处就是：\n 抽象了A类之后，对于B类来说，不必要关心是“哪位老师”叫B类完成任务，只需要完成任务就好了，也就是说我B类的方法，可以复用； 抽象了B类之后，对于A类来说，相对更加灵活，其调用B类的方法不仅仅只限于“one-by-one”这种模式，而是一次可以对“多个学生”进行提问，只需要将A类中的字段修改为List即可。\n回调的核心就是回调方将本身即this传递给调用方，调用方接着调用回调方的方法告诉它想要知道的信息。回调是一种思想、是一种机制，至于具体如何实现，如何通过代码将回调实现得优雅、实现得可扩展性比较高，一看开发者的个人水平，二看开发者对业务的理解程度。  同步回调与异步回调 上述的例子是一个典型的同步回调的示例。同步回调顾名思义就是A()调用B()之后，等待B()执行完成并且调用A()的回调函数，程序再继续执行。\n异步回调就是在A()调用B()的过程中，开启一个新线程，不等待B()方法执行完成并回调之后再执行后续操作。\n修改上例子中的A类中的方法，将其修改为异步回调\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public class Teacher implements Callback { /** * 接口作为属性字段,便于扩展 */ private Student student; public Teacher(Student student) { this.student = student; } /** * askQuestion() 方法用于调用B类的方法 */ public void askQuestion() { // 异步回调  new Thread(new Runnable() { @Override public void run() { student.resolveAnswer(Teacher.this); } }).start(); } @Override public void tellAnswer(Student student , int a) { System.out.println(\u0026#34;知道了,\u0026#34;+student.getName()+\u0026#34; 完成任务花了 \u0026#34; + a + \u0026#34; 秒\u0026#34;); } }   同步回调和异步回调的选择要结合具体的业务场景，比如充值服务，要将充值的结果返回给用户，调用充值服务之后必须要等待充值接口的返回；但是如果是批量的处理（如退订业务），这时候可以用异步回调，主程序完成之后（或者页面app先返回数据给用户），后台业务逻辑继续执行，最后才业务执行的结果，可以作异步处理；\n","description":"本文介绍了回调模式的基本概念，给出了在Java中使用回调的简单示例。","id":53,"section":"posts","tags":["回调模式"],"title":"Java接口回调","uri":"http://wangy325.top/zh/posts/java/design_pattern/java%E6%8E%A5%E5%8F%A3%E5%9B%9E%E8%B0%83/"},{"content":"trim标记是一个格式化的标记，可以完成set或者是where标记的功能\n样例一 　select * from user \u0026lt;trim prefix=\u0026quot;WHERE\u0026quot; prefixoverride=\u0026quot;AND |OR\u0026quot;\u0026gt; \u0026lt;if test=\u0026quot;name != null and name.length()\u0026gt;0\u0026quot;\u0026gt; AND name=#{name}\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;gender != null and gender.length()\u0026gt;0\u0026quot;\u0026gt; AND gender=#{gender}\u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; 假如说name和gender的值都不为null的话打印的SQL为：select * from user where name = 'xx' and gender = 'xx'\n在红色标记的地方是不存在第一个and的，上面两个属性的意思如下：\n prefix：前缀\nprefixoverride：去掉第一个and或者是or\n 样例二 　update user \u0026lt;trim prefix=\u0026quot;set\u0026quot; suffixoverride=\u0026quot;,\u0026quot; suffix=\u0026quot; where id = #{id} \u0026quot;\u0026gt; \u0026lt;if test=\u0026quot;name != null and name.length()\u0026gt;0\u0026quot;\u0026gt; name=#{name} , \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;gender != null and gender.length()\u0026gt;0\u0026quot;\u0026gt; gender=#{gender} , \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; 假如说name和gender的值都不为null的话打印的SQL为：update user set name='xx' , gender='xx' where id='x'\n在红色标记的地方不存在逗号，而且自动加了一个set前缀和where后缀，上面三个属性的意义如下，其中prefix意义如上：\n suffixoverride：去掉最后一个逗号（也可以是其他的标记，就像是上面前缀中的and一样）\nsuffix：后缀\n 实例:\ninsert into yd_submit_fail \u0026lt;trim prefix=\u0026quot;(\u0026quot; suffix=\u0026quot;)\u0026quot; suffixOverrides=\u0026quot;,\u0026quot; \u0026gt; \u0026lt;if test=\u0026quot;id != null\u0026quot; \u0026gt; id, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;createTime != null\u0026quot; \u0026gt; createTime, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;updateTime != null\u0026quot; \u0026gt; updateTime, \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; \u0026lt;trim prefix= \u0026quot;values (\u0026quot; suffix =\u0026quot;)\u0026quot; suffixOverrides=\u0026quot;,\u0026quot;\u0026gt; \u0026lt;if test=\u0026quot;id != null\u0026quot; \u0026gt; {#id}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;createTime != null\u0026quot; \u0026gt; {#createTime}, \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;updateTime != null\u0026quot; \u0026gt; {#updateTime}, \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; ","description":"mybatis的基础知识。","id":54,"section":"posts","tags":["orm"],"title":"MyBatis的trim标签","uri":"http://wangy325.top/zh/posts/java/sql/mybatis%E4%B8%ADtrim%E6%A0%87%E7%AD%BE%E5%8A%A8%E6%80%81%E6%8B%BC%E6%8E%A5sql/"},{"content":"本文介绍了mysql的几个方便的字符串处理函数，通常用于简单的查询结果处理。适用在mapper.xml的语句标签中对数据库字段数据进行简单的处理。\nSUBSTRING_INDEX(str,delim,count)  根据索引获取子字符串\n@param str 待处理字符串\n@delim 关键字\n@count 关键字出现的次数\n 1 2 3 4 5  SELECT SUBSTRING_INDEX(\u0026#39;www.google.com/welcome\u0026#39;,\u0026#39;/\u0026#39;,1); -- www.google.com SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(\u0026#39;www.google.com/welcome\u0026#39;,\u0026#39;/\u0026#39;,1),\u0026#39;.\u0026#39;,-2); -- google.com -- 当count为负数的时候,从尾部开始计算   SUBSTRING(str,pos,len)  获取指定长度的字串\n@str 原字符串\n@pos 开始截取的位置(包含)\n@len 子串长度\n 1 2 3  SELECT SUBSTRING(\u0026#34;www.google.com\u0026#34;, 5, 6); SELECT SUBSTRING(\u0026#34;www.google.com\u0026#34; FROM 5 FOR 6); -- google   此方法还有一些重载方法\nREPLACE(str,from_str,to_str)  替换字符串的内容 @str 原字符串\n@from_str 目标字符串(子串)\n@to_str 替换的字符串\n 1 2  SELECT REPLACE(\u0026#39;www.google.com\u0026#39;,\u0026#39;google\u0026#39;,\u0026#39;baidu\u0026#39;); -- www.baidu.com   ALTER 新增字段 (ADD)  在某张表中添加字段使用ADD关键字\n支持批量添加\n如果要在某个字段之后添加字段,可使用 AFTER 关键字\n 1 2 3  ALTER TABLE TABLE_NAME ADD (COL_NAME DATATYPE [UNSIGNED DEFAULT NOT NULL COMMENT],COLNAME2 DATATYPE,...); ALTER TABLE TABLE_NAME ADD COL_NAME DATATYPE AFTER `col_name`;   修改字段 (MODIFY CHANGE)  修改字段属性(数据类型,默认值,非空约束等)使用 MODIFY\n修改字段名字以及数据类型,默认值,非空约束等使用 CHANGE\n 1 2 3 4  -- 修改字段属性 ALTER TABLE t1 MODIFY col1 BIGINT UNSIGNED DEFAULT 1 COMMENT \u0026#39;my column\u0026#39;; -- 修改字段名字和属性 ALTER TABLE t1 CHANGE a b INT(11) DEFAULT 0 NOT NULL COMMENT \u0026#39;comment\u0026#39;;   ","description":"本文介绍了mysql的几个方便的字符串处理函数，通常用于简单的查询结果处理。","id":55,"section":"posts","tags":null,"title":"MySQL中的几个字符串处理函数","uri":"http://wangy325.top/zh/posts/java/sql/mysql%E7%9A%84%E5%87%A0%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86%E5%87%BD%E6%95%B0/"},{"content":"git fetch 与 git pull\n 此文的操作背景在本次工作空间的master分支下, 并且追踪远程master分支\n部分内容引用自yibai.com\n 前文说到, git版本控制的基本原型与操作逻辑. 如果出现两台机器(比如公司和家)上同时更改\u0026rsquo;本地仓库\u0026rsquo;内容并且push到远程库中,那么必然会导致另一个版本库中的文件低于远程库,如果是有效的改动, 必然涉及到本地库和远程库同步的问题, 这涉及到3个关键词: fetch, merge, pull\ngit fetch  从一个或多个其他存储库中获取分支和/或标签(统称为“引用”)以及完成其历史所必需的对象\n 通俗地讲, 如果想将远程仓库master分支的版本信息下载(同步)到本地仓库, 就可以简单地使用\n$ git fetch origin master 命令. git fetch 命令会默认拉取所有分支信息. 但是仅仅这样, 本地的文件并没有更新, 因为这一操作仅仅\u0026rsquo;检查到有可用更新', 要\u0026rsquo;更新\u0026rsquo;本地仓库工作空间的文件,还需要另一个命令: git merge\ngit merge  命令用于将两个或两个以上的开发历史加入(合并)一起\n 实际上, 在执行了git fetch origin master 之后, 再执行git branch, 会出现两个分支信息:\n$ git fetch origin master Warning: Permanently added the RSA host key for IP address '52.74.223.119' to the list of known hosts. Enter passphrase for key '/c/Users/mayn/.ssh/id_rsa': remote: Enumerating objects: 19, done. remote: Counting objects: 100% (19/19), done. remote: Compressing objects: 100% (3/3), done. remote: Total 10 (delta 5), reused 10 (delta 5), pack-reused 0 Unpacking objects: 100% (10/10), done. From github.com:wangy325/demoLite * branch master -\u0026gt; FETCH_HEAD 276f33d..78beaa6 master -\u0026gt; origin/master $ git branch -a * master remotes/origin/master 其中master分支是当前工作分支, 而remotes/origin/master是执行fetch命令之后下载的版本信息. 如果想将版本库中的分支合并到当前工作分支,可以使用命令:\n$ git merge origin/master  注意：上述命令会自动将合并后的结果提交(commit), 如果想要对合并进行进一步更改时, 可以使用 --no-commit 选项\n git pull  取回远程主机某个分支的更新(fetch)，再与本地的指定分支合并(merge)\n 因此, pull可以看作是fetch和merge命令的集合, 如果想要将远程master分支与本地master分支合并, 可使用如下命令:\n$ git pull origin master:master 如果当前工作分支是master分支, 那么命令也可以简写为:\n$ git pull origin master 实际上我们发现, 以上命令相当于先取回origin/master分支, 再将其与当前分支合并, 这是一个先做git fetch, 后做git merge操作的过程:\n$ git fetch origin master $ git merge origin/master 分支追踪关系 一般地, Git会自动在本地分支和远程分支之间建立一种追踪关系(tracking). 建立追踪关系的分支之间可以建立更加简便的操作.\n 比如，在git clone的时候，所有本地分支默认与远程主机的同名分支，建立追踪关系，也就是说，本地的master分支自动”追踪”origin/master分支\n 可以通过 git branch -vv 查看当前本地分支与远程分支的追踪关系:\n$ git branch -vv * master 78beaa6 [origin/master] revise code 也可以手动建立追踪关系:\n// 将本地master分支与远程master分支建立追踪关系 $ git branch --set-upstream master origin/master 建立追踪关系之后, git pull 就可以省略远程名, git 自动从当前分支追踪的远程分支中获取更新并且拉取到本地工作空间\n// 现在自动从远程仓库(origin)中拉取当前分支追踪的远程分支的更新 $ git pull origin // 若当前分支只有一个追踪分支, 甚至可以省略主机名 $ git pull git fetch和git pull的区别  git fetch : 从远程获取最新的版本到本地, 但是不会自动合并 git pull : 从远程获取最新版本并且合并到本地  // 从远程origin的master分支拉取最新版本到origin/master分支 $ git fetch origin master // 比较本地master和origin/master分支的区别 $ git log -p master.. origin/master // 合并 origin/master 到当前分支(master) $ git merge origin/master 上述过程可以更加简便地表述为\n$ git fetch origin master:tmp $ git diff tmp $ git merge tmp ","description":"","id":56,"section":"posts","tags":[""],"title":"Git入门2","uri":"http://wangy325.top/zh/posts/vc/git%E5%85%A5%E9%97%A82/"},{"content":"本文简单介绍了Git本地仓库的构建，与远程仓库的关联\n安装 ubuntu下安装：\nsudo apt install git windows 下安装，需下载安装包\nGit 本地仓库的创建 通俗地讲，本地任何一个目录都可以是本地仓库。只需要启动Terminal(ubuntu)或Git Bash(windows)，cd进入指定目录，运行\ngit init 即可以初始化一个空的本地仓库。此时，该目录下会多出一个.git子目录，它是Git用来跟踪管理版本库的。当然，如果你想取消版本管理，删除这个目录即可。\nGit 不同于 Subversion 的地方在于，Git是分布式的版本管理系统，没有中央服务器。这大概解释了Git可以创建本地仓库的原因，而Subversion的使用必须要借助互联网。\n关于集中式与分布式的讨论，此处不作多的说明，没有使用经验支撑，那些优劣列出来，没有什么意义。\nGit 关联GitHub远程仓库 Git支持基于SSH和https关联远程仓库，但推荐使用SSH方式，它更加安全。在本地仓库要想和GitHub远程仓库关联，首先需要在GitHub中配置SSH and GPG keys。\n通过\nssh-keygen -t rsa -C \u0026quot;wangy325@qq.com\u0026quot; 获取ssh密钥文件，操作过程中会提示确认保存文件的位置以及要求输入密码，以下是命令输出(windows 平台)。\nGenerating public/private rsa key pair. Enter file in which to save the key (/c/Users/mayn/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /c/Users/mayn/.ssh/id_rsa. Your public key has been saved in /c/Users/mayn/.ssh/id_rsa.pub. The key fingerprint is: SHA256:Yy7sS0KnY+iaQDLldwI43znocIboZhDbD5ZPwjzMybU wangy325@qq.com The key's randomart image is: +---[RSA 2048]----+ | | | . | |+ o . | |./ B o | |O.^ E o S | |=B @ B o . | |.+o B + . | |+o . = . | |o.. o. | +----[SHA256]-----+ 命令执行完成之后，会在 c/Users/mayn/ 下生成一个.ssh目录，里面包含了密钥信息。\n然后在GitHub页面添加新的ssh key，配置完成以后，便可以将本地仓库和远程仓库关联，并将本地文件上传到远程（通常，你需要先add并且commit文件到本地版本库）：\ngit remote add origin git@github.com:wangy325/repositoryName.git git push -u origin master Git的工作模式简单介绍  工作区(workspace)：即当前工作目录 暂存区(stage/index):.log目录下的的index文件中，暂存区域保存的是本地已add但未commit的改动 版本库(local repository):本地版本库，commit之后文件信息变保存在其中 远程仓库(remote repository):远程版本库，push推送本地文件到远程版本库，fetch从远程版本库拉取 资源 版本信息，pull从远程版本库中拉取资源  ![imLgtx.png](/img/git_stage.png) Git本地工作区，暂存区，版本库的概念，图引自易百教程\n  Git本地工作区，暂存区，版本库的概念，图引自[易百教程](https://www.yiibai.com/git/)   -- Git 版本控制的一些主要概念：\n 3个步骤：  add命令只添加文件到暂存区 commit命令将文件添加到本地版本库 push命令将本地版本库的内容推送到远程仓库   4个区：  workingAera：当前工作空间 stage：暂存区，已修改并add的文件在此区 local repository：本地仓库 remote repository：远程仓库   5种状态  origin：被git追踪但未作任何修改 modified：已修改但未add到暂存区 staged：已修改并add到暂存区 committed：已提交到本地仓库 pushed：已推送到远程仓库    常用命令  git command --help 可以打开帮助文档\ngit config --global credential.helper store 保存用户凭证，避免每次push/pull都需要输入密码\n 添加文件到暂存区 git add file1 ... 提交文件到仓库之前，需要配置用户名和电子邮件\ngit config --global user.name \u0026quot;wangy325\u0026quot; git config --global user.email \u0026quot;wangy325@qq.com\u0026quot; 提交文件到仓库 git commit -m \u0026quot;commit comment\u0026quot; 查看当前仓库的状态 $ git status On branch master Your branch is up to date with 'origin/master'. Changes not staged for commit: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) modified: readme.md Untracked files: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to include in what will be committed) Main.java no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) 查看某个文件的差异信息   git diff\n查看暂未add到暂存区的改动，也就是状态为modified的文件，如果文件已经staged，则此命令不会显示差异信息\n  git diff --cached\n查看已经add到暂存区的改动，也就是状态为staged的文件，如果文件处于modified状态，则此命令不会显示差异信息\n  git diff HEAD\n查看已暂存和未暂存的所有改动\n  git diff --stat\n显示差异的摘要信息\n  git diff master origin/master\n显示本地仓库和远程仓库之间的文件的差异信息，即committed和pushed两个状态之间的差异\n  git diff versionCode1 versionCode2\n显示两个版本(号)之间的差异信息，less打开\n  1 2 3 4 5 6 7 8 9 10 11 12 13  $ git diff readme.md warning: LF will be replaced by CRLF in readme.md. The file will have its original line endings in your working directory. diff --git a/readme.md b/readme.md index bb8298f..222e2da 100644 --- a/readme.md +++ b/readme.md @@ -6,3 +6,5 @@ - Java的回调机制 - idea的多线程调试 - 拦截器 + +\u0026gt; you can\u0026#39;t live your life based on other people\u0026#39;s point of view.   查看版本更新日志 git log [--pretty=oneline] --可选参数显示简略信息 $ git log commit cf3d291b043457536f5851c3517c94f6f50d4c94 (HEAD -\u0026gt; master, origin/master) Author: wangy325 \u0026lt;wangy325@qq.com\u0026gt; Date: Wed Sep 19 12:11:13 2018 +0800 update readme.md commit 7daa43936419202cfd6c0e58988001577cb61e73 Author: wangy325 \u0026lt;wangy325@qq.com\u0026gt; Date: Wed Sep 19 12:10:30 2018 +0800 upload files 上面的日志显示 HEAD 的版本号为cf3d291b043457536f5851c3517c94f6f50d4c94，括号内显示，本地仓库和远程仓库的文件是一致的（最新的），以下是commit但是没有push到远程仓库的日志记录：\ncommit f67ec47c9df0f0f8351413ef64494e908d7183a0 (HEAD -\u0026gt; master) Author: wangy325 \u0026lt;wangy325@qq.com\u0026gt; Date: Thu Sep 20 17:29:09 2018 +0800 add motto commit cf3d291b043457536f5851c3517c94f6f50d4c94 (origin/master) Author: wangy325 \u0026lt;wangy325@qq.com\u0026gt; Date: Wed Sep 19 12:11:13 2018 +0800 update readme.md commit 7daa43936419202cfd6c0e58988001577cb61e73 Author: wangy325 \u0026lt;wangy325@qq.com\u0026gt; Date: Wed Sep 19 12:10:30 2018 +0800 upload files 上面的日志显示，本地HEAD最新的版本号和远程仓库的版本号不一致，暗示本地仓库的改动还未提交到远程仓库\n撤销修改  modified 状态撤回   git checkout\n 从工作区和索引中删除文件  git rm [-f | \u0026ndash;force] [-n] [-r] [\u0026ndash;cached] [\u0026ndash;ignore-unmatch] [\u0026ndash;quiet] [\u0026ndash;] …\n 1 git rm \u0026lt;file\u0026gt;\n从当前工作目录中删除文件，这个文件将会从工作空间物理删除，然后commit，版本库中的改文件信息会被删除\n$ git rm text2.md rm 'text2.md' $ git status On branch master Your branch is ahead of 'origin/master' by 5 commits. (use \u0026quot;git push\u0026quot; to publish your local commits) Changes to be committed: (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) deleted: text2.md $ git commit -m \u0026quot;aaa\u0026quot; [master d0ba06d] aaa 1 file changed, 1 deletion(-) delete mode 100644 text2.md 2 git rm -f \u0026lt;file\u0026gt;\n如果当前文件已经在暂存区，则将其从暂存区和工作空间中移除（移除版本信息），commit 之后，其将不在版本库中\n$ git add t3.md warning: LF will be replaced by CRLF in t3.md. The file will have its original line endings in your working directory. $ git rm t3.md error: the following file has changes staged in the index: t3.md (use --cached to keep the file, or -f to force removal) $ git rm -f t3.md rm 't3.md' $ git status On branch master Your branch is ahead of 'origin/master' by 6 commits. (use \u0026quot;git push\u0026quot; to publish your local commits) nothing to commit, working tree clean 3 git rm --cached \u0026lt;file\u0026gt;\n如果当前文件改动已经add到暂存区，使用该命令从暂存区中移除版本信息，但是工作空间中还存在，commit之后，其将不在版本库中\n$ git add t3.md warning: LF will be replaced by CRLF in t3.md. The file will have its original line endings in your working directory. $ git rm --cached t3.md rm 't3.md' $ ls me/ readme.md t3.md $ git status On branch master Your branch is ahead of 'origin/master' by 7 commits. (use \u0026quot;git push\u0026quot; to publish your local commits) Changes to be committed: (use \u0026quot;git reset HEAD \u0026lt;file\u0026gt;...\u0026quot; to unstage) deleted: t3.md Untracked files: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to include in what will be committed) t3.md  首次创建时间 2018/09/19 09:34 ","description":"","id":57,"section":"posts","tags":[""],"title":"Git入门1","uri":"http://wangy325.top/zh/posts/vc/git%E5%85%A5%E9%97%A81/"},{"content":"这是一个约束文档\n鉴于长时间地接触javaSE，java WEB，SQL 等相关内容，然而停留的层面还是相当基础， 好些东西似是而非，更多的内容则只是泛泛了解，这样的成长速度是远远不够的，未知黑洞使我感到惶恐\n同样地，linux的接触时间也很长了，以兴趣为第一驱动到后来确实有些乏力，linux的操作也仅仅停留在基本的命令而已，还远未涉及到系统层面，更加不要妄谈什么 system administrator 了\n所以决定写此约定文档\n我希望，这个文档的内容逐渐变多的时候，我能在以下地方找到一些蛛丝马迹：\n  我希望看得到一些学习笔记，踩坑心得，工作上自学均可 我希望看得见一些代码片段，更希望看见的是有完整的demo上传到github上面 我希望看见系统的学习记录，网络固然可以查询到很多东西，同样，网络上查到的对于知识的解读是相当模糊的，如果想真正学好知识，啃书是最难也是最有效的方式，所以我希望能看见一些书摘   之前认为慕课网上面，不管是java入门还是linux入门，有些视频都很不错，现在决定重新抽时间梳理知识点，其上的视频还可以拿来回顾一下。至于书籍，我希望能够慢慢地、系统地提供完成一本书籍的阅读，以我阅读linux私房菜的经历来看，这其实是很难的一件事，难在于每天一段时间去做固定的事情，比如啃书。\nALL BOOKD NEED TO READ IN 1 YEAR\n TIC （重新回顾java核心基础知识体系） 数据结构与算法分析：java语言描述 （学点数据结构） Java RESTful Web Service 实战 （面向企业搭建小型web服务） 深入分析 Java Web 技术内幕 Java 多线程编程核心技术  以上书籍主要涉及三块内容：\n java基础 数据结构 java Web(主流框架技术)  如有空，尚可去LCTT找点开源相关的文章练习一下，顺便了解下开源的最新动态\nwangy325\n2018.09.06\n","description":"","id":58,"section":"posts","tags":[],"title":"约束","uri":"http://wangy325.top/zh/posts/z/restrict/"},{"content":"   站点的logo取自 Pink Floyd 2014年的专辑封面，这是我第一次接触Pink Floyd，也是我第一次接触计算机技术，准确点说，是接触Ubuntu。Pink Floyd我想我会一直听，技术之路，也会一直走。\n和Ubuntu的关系维持到16年开始着手毕业论文，这一段时间回想起来是非常失败的。究其原因，仅仅是把Ubuntu作为兴趣，止步于猎奇而未深究，就连鸟叔的课文也才看了一半。这也是我长期以来缺乏规划和长远思考的必然结果。\n回头想想自己，缺乏的是高屋建瓴的思考，往往想学而不知如何开始，而又觉得要学的东西太多而萌生放弃的想法——放弃的念头一起，那力量就很强大。我最终还是放弃了Ubuntu，留下了打印出来剩下一半未看的资料，不是我要放弃，是我发现，盯着linux系统的书籍看，可能几年都没有工作了。我当时的想法是，要转计算机，那至少得会一高级编程语言。\n这个想法其实是正确的。可一旦这样，意味着我放弃了我所有的教育履历，和千千万万想进入互联网行业的人一样，从0开始。\n行么？\n读书以来，靠着完全的“自我管理”，混到了一个华南某985的硕士学历。现在回头看看，我的自我管理是在是太糟糕了，就像是没有脑子的圈养动物一样。\n18年是我自我剥削的第一年，像教徒般虔诚，加班到深夜，将知识运用到生产中的快感使我满足，我喜欢这样的感觉。但同时我也一度抑郁，这种抑郁来自于行业的隔阂，匆忙学到的那点知识，我深知离科班生太远了。\n“得益”于求学期间糟糕的自我管理，我不得不重头开始。\n这个博客是19年搭建的，可能较多的内容类似于学习笔记，毕竟还是打基础的阶段，此目的在于系统化知识体系；其次在于记录一些问题，简单则寥寥数语，复杂则深入剖析；再次用于记录平淡的生活感悟。\n望持之以恒。\n","description":"Hugo, the world’s fastest framework for building websites","id":59,"section":"","tags":null,"title":"关于","uri":"http://wangy325.top/zh/about/"}]